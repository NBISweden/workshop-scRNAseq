
---
title: "{{< meta st_title >}}"
subtitle: "{{< meta subtitle_scanpy >}}"
description: "{{< meta st_description >}}"
format: html
engine: jupyter
---

::: {.callout-note}
Code chunks run Python commands unless it starts with `%%bash`, in which case, those chunks run shell commands.
:::

Adapted from tutorials by Giovanni Palla
(https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html)
and Carlos Talavera-LÃ³pez
(https://docs.scvi-tools.org/en/latest/tutorials/notebooks/stereoscope_heart_LV_tutorial.html)

{{< meta st_1 >}}

## {{< meta st_prep >}}

{{< meta st_prep_1 >}}

```{python}
import scanpy as sc
import anndata as an
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import scanorama
import warnings
import os

warnings.simplefilter(action="ignore", category=Warning)

sc.set_figure_params(facecolor="white", figsize=(8, 8))
sc.settings.verbosity = 3
```

{{< meta st_prep_2 >}}

The function `datasets.visium_sge()` downloads the dataset from 10x genomics and returns an AnnData object that contains counts, images and spatial coordinates. We will calculate standards QC metrics with
`pp.calculate_qc_metrics()` and visualize them.

When using your own Visium data, use Scanpy's read_visium() function to import it.

```{python}
# download pre-computed data if missing or long compute
fetch_data = True

# url for source and intermediate data
path_data = "https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq"

if not os.path.exists("./data/spatial/visium"):
    os.makedirs("./data/spatial/visium")
```

```{python}
adata_anterior = sc.datasets.visium_sge(
    sample_id="V1_Mouse_Brain_Sagittal_Anterior"
)
adata_posterior = sc.datasets.visium_sge(
    sample_id="V1_Mouse_Brain_Sagittal_Posterior"
)
```

```{python}
adata_anterior.var_names_make_unique()
adata_posterior.var_names_make_unique()
```

To make sure that both images are included in the merged object, use uns_merge="unique".

```{python}
# merge into one dataset
library_names = ["V1_Mouse_Brain_Sagittal_Anterior", "V1_Mouse_Brain_Sagittal_Posterior"]

adata = adata_anterior.concatenate(
    adata_posterior,
    batch_key="library_id",
    uns_merge="unique",
    batch_categories=library_names
)

adata
```

As you can see, we now have the slot spatial in obsm, which contains the spatial information from the Visium platform.

## {{< meta st_qc >}}

{{< meta st_qc_1 >}}

```{python}
# add info on mitochondrial and hemoglobin genes to the objects.
adata.var['mt'] = adata.var_names.str.startswith('mt-') 
adata.var['hb'] = adata.var_names.str.contains(("^Hb.*-"))

sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','hb'], percent_top=None, log1p=False, inplace=True)

sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_hb'], jitter=0.4, groupby = 'library_id', rotation= 45)
```

{{< meta st_qc_2 >}}

In scanpy, this is a bit tricky when you have multiple sections, as you would have to subset and plot them separately.

```{python}
# need to plot the two sections separately and specify the library_id
for library in library_names:
    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = ["total_counts", "n_genes_by_counts",'pct_counts_mt', 'pct_counts_hb'])
```

{{< meta st_qc_3 >}}

### {{< meta st_qc_filter >}}

{{< meta st_qc_filter_1 >}}

```{python}
keep = (adata.obs['pct_counts_hb'] < 20) & (adata.obs['pct_counts_mt'] < 25) & (adata.obs['n_genes_by_counts'] > 1000)
print(sum(keep))

adata = adata[keep,:]
```

And replot onto tissue sections.

```{python}
for library in library_names:
    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = ["total_counts", "n_genes_by_counts",'pct_counts_mt', 'pct_counts_hb'])
```

### {{< meta st_qc_top >}}

{{< meta st_qc_top_1 >}}

```{python}
sc.pl.highest_expr_genes(adata, n_top=20)
```

{{< meta st_qc_top_2 >}}

### {{< meta st_qc_filterg >}}

{{< meta st_qc_filterg_1 >}}

```{python}
mito_genes = adata.var_names.str.startswith('mt-')
hb_genes = adata.var_names.str.contains('^Hb.*-')

remove = np.add(mito_genes, hb_genes)
remove[adata.var_names == "Bc1"] = True
keep = np.invert(remove)
print(sum(remove))

adata = adata[:,keep]

print(adata.n_obs, adata.n_vars)
```

## {{< meta st_analysis >}}

{{< meta st_analysis_1 >}}

As we have two sections, we will select variable genes with batch_key="library_id" and then take the union of variable genes for further analysis. The idea is to avoid including batch specific genes in the analysis.

```{python}
# save the counts to a separate object for later, we need the normalized counts in raw for DEG dete
counts_adata = adata.copy()

sc.pp.normalize_total(adata, inplace=True)
sc.pp.log1p(adata)
# take 1500 variable genes per batch and then use the union of them.
sc.pp.highly_variable_genes(adata, flavor="seurat", n_top_genes=1500, inplace=True, batch_key="library_id")

# subset for variable genes
adata.raw = adata
adata = adata[:,adata.var.highly_variable_nbatches > 0]

# scale data
sc.pp.scale(adata)
```

{{< meta st_analysis_2 >}}

```{python}
for library in library_names:
    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = ["Ttr", "Hpca"])
```

### {{< meta st_analysis_dimred >}}

{{< meta st_analysis_dimred_1 >}}

```{python}
sc.pp.neighbors(adata)
sc.tl.umap(adata)
sc.tl.leiden(adata, key_added="clusters")
```

{{< meta st_analysis_dimred_2 >}}

```{python}
sc.pl.umap(
    adata, color=["clusters", "library_id"], palette=sc.pl.palettes.default_20
)
```

As we are plotting the two sections separately, we need to make sure that they get the same colors by fetching cluster colors from a dict.

```{python}
clusters_colors = dict(
    zip([str(i) for i in range(len(adata.obs.clusters.cat.categories))], adata.uns["clusters_colors"])
)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))

for i, library in enumerate(
    ["V1_Mouse_Brain_Sagittal_Anterior", "V1_Mouse_Brain_Sagittal_Posterior"]
):
    ad = adata[adata.obs.library_id == library, :].copy()
    sc.pl.spatial(
        ad,
        img_key="hires",
        library_id=library,
        color="clusters",
        size=1.5,
        palette=[
            v
            for k, v in clusters_colors.items()
            if k in ad.obs.clusters.unique().tolist()
        ],
        legend_loc=None,
        show=False,
        ax=axs[i],
    )

plt.tight_layout()
```

### {{< meta st_analysis_int >}}

{{< meta st_analysis_int_1 >}}

We will do a similar integration as in the Data Integration lab, here we will use Scanorama for integration.

```{python}
adatas = {}
for batch in library_names:
    adatas[batch] = adata[adata.obs['library_id'] == batch,]

adatas 
```

```{python}
import scanorama

#convert to list of AnnData objects
adatas = list(adatas.values())

# run scanorama.integrate
scanorama.integrate_scanpy(adatas, dimred = 50)

# Get all the integrated matrices.
scanorama_int = [ad.obsm['X_scanorama'] for ad in adatas]

# make into one matrix.
all_s = np.concatenate(scanorama_int)
print(all_s.shape)

# add to the AnnData object
adata.obsm["Scanorama"] = all_s

adata
```

{{< meta st_analysis_int_2 >}}

```{python}
sc.pp.neighbors(adata, use_rep="Scanorama")
sc.tl.umap(adata)
sc.tl.leiden(adata, key_added="clusters")

sc.pl.umap(
    adata, color=["clusters", "library_id"], palette=sc.pl.palettes.default_20
)
```

As we have new clusters, we again need to make a new dict for cluster colors

```{python}
clusters_colors = dict(
    zip([str(i) for i in range(len(adata.obs.clusters.cat.categories))], adata.uns["clusters_colors"])
)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))

for i, library in enumerate(
    ["V1_Mouse_Brain_Sagittal_Anterior", "V1_Mouse_Brain_Sagittal_Posterior"]
):
    ad = adata[adata.obs.library_id == library, :].copy()
    sc.pl.spatial(
        ad,
        img_key="hires",
        library_id=library,
        color="clusters",
        size=1.5,
        palette=[
            v
            for k, v in clusters_colors.items()
            if k in ad.obs.clusters.unique().tolist()
        ],
        legend_loc=None,
        show=False,
        ax=axs[i],
    )

plt.tight_layout()
```

:::{.callout-note title="Discuss"}
{{< meta st_analysis_int_3 >}}
:::

### {{< meta st_analysis_svg >}}

{{< meta st_analysis_svg_1 >}}

```{python}
# run t-test 
sc.tl.rank_genes_groups(adata, "clusters", method="wilcoxon")
# plot as heatmap for cluster5 genes
sc.pl.rank_genes_groups_heatmap(adata, groups="5", n_genes=10, groupby="clusters")
```

```{python}
# plot onto spatial location
top_genes = sc.get.rank_genes_groups_df(adata, group='5',log2fc_min=0)['names'][:3]

for library in ["V1_Mouse_Brain_Sagittal_Anterior", "V1_Mouse_Brain_Sagittal_Posterior"]:
    sc.pl.spatial(adata[adata.obs.library_id == library,:], library_id=library, color = top_genes)
```

Spatial transcriptomics allows researchers to investigate how gene expression trends varies in space, thus identifying spatial patterns of gene expression. For this purpose there are multiple methods, such as SpatailDE, SPARK, Trendsceek, HMRF and Splotch.

We use SpatialDE Svensson et al., a Gaussian process-based statistical framework that aims to identify spatially variable genes.

::: {.callout-caution}

This is a slow compute intensive step, we will not run this now and instead use a pre-computed file in the step below.

```{python}
# | results: hide
# this code is not executed

if not fetch_data:
    import NaiveDE
    import SpatialDE

    counts = sc.get.obs_df(adata, keys=list(adata.var_names), use_raw=True)
    total_counts = sc.get.obs_df(adata, keys=["total_counts"])
    norm_expr = NaiveDE.stabilize(counts.T).T
    resid_expr = NaiveDE.regress_out(
        total_counts, norm_expr.T, "np.log(total_counts)").T
    results = SpatialDE.run(adata.obsm["spatial"], resid_expr)

    import pickle
    with open('data/spatial/visium/scanpy_spatialde.pkl', 'wb') as file:
        pickle.dump(results, file)
```

:::

Download precomputed file.

```{python}
# | results: hide

path_file = "data/spatial/visium/scanpy_spatialde.pkl"
if fetch_data and not os.path.exists(path_file):
    import urllib.request
    file_url = os.path.join(
        path_data, "spatial/visium/results/scanpy_spatialde.pkl")
    urllib.request.urlretrieve(file_url, path_file)
```

```{python}
# | results: hide

import pickle
with open('data/spatial/visium/scanpy_spatialde.pkl', 'rb') as file:
    results = pickle.load(file)
```

```{python}
# | results: hide
# | eval: false
# skip for now.

# We concatenate the results with the DataFrame of annotations of variables: `adata.var`.
results.index = results["g"]
adata.var = pd.concat(
    [adata.var, results.loc[adata.var.index.values, :]], axis=1)
adata.write_h5ad('./data/spatial/visium/adata_processed_sc.h5ad')

# Then we can inspect significant genes that varies in space and visualize them with `sc.pl.spatial` function.
results.sort_values("qval").head(10)
```

## {{< meta st_ss >}}

{{< meta st_ss_1 >}}

Conveniently, you can also download the pre-processed dataset in h5ad format.

```{python}
import urllib.request
import os

path_file = "data/spatial/visium/allen_cortex.h5ad"
if not os.path.exists(path_file):
    file_url = os.path.join(
        path_data, "spatial/visium/allen_cortex.h5ad")
    urllib.request.urlretrieve(file_url, path_file)
```

```{python}
adata_cortex = sc.read_h5ad("data/spatial/visium/allen_cortex.h5ad")
adata_cortex
```

Here is the metadata for the cell annotation:

```{python}
adata_cortex.obs
```

There is an issue with the raw matrix in this object that the gene names are not in the index, so we will put them back in.

```{python}
adata_cortex.raw.var.index = adata_cortex.raw.var._index
adata_cortex.raw.var
```

Then we run the regular pipline with normalization and dimensionality reduction.

```{python}
sc.pp.normalize_total(adata_cortex, target_sum=1e5)
sc.pp.log1p(adata_cortex)
sc.pp.highly_variable_genes(adata_cortex, min_mean=0.0125, max_mean=3, min_disp=0.5)
sc.pp.scale(adata_cortex, max_value=10)
sc.tl.pca(adata_cortex, svd_solver='arpack')
sc.pp.neighbors(adata_cortex, n_pcs=30)
sc.tl.umap(adata_cortex)
sc.pl.umap(adata_cortex, color="subclass", legend_loc='on data')
```

```{python}
adata_cortex.obs.subclass.value_counts()
```

{{< meta st_ss_2 >}}

```{python}
target_cells = 200

adatas2 = [adata_cortex[adata_cortex.obs.subclass == clust] for clust in adata_cortex.obs.subclass.cat.categories]

for dat in adatas2:
    if dat.n_obs > target_cells:
          sc.pp.subsample(dat, n_obs=target_cells)

adata_cortex = adatas2[0].concatenate(*adatas2[1:])

adata_cortex.obs.subclass.value_counts()
```

```{python}
sc.pl.umap(
    adata_cortex, color=["class", "subclass", "genotype", "brain_region"], palette=sc.pl.palettes.default_28
)
```

```{python}
sc.pl.umap(adata_cortex, color="subclass", legend_loc = 'on data')
```

## {{< meta st_sub >}}

{{< meta st_sub_1 >}}

For deconvolution we will need the counts data, so we will subset from the counts_adata object that we created earlier.

```{python}
lib_a = "V1_Mouse_Brain_Sagittal_Anterior"

counts_adata.obs['clusters'] = adata.obs.clusters

adata_anterior_subset = counts_adata[
    (counts_adata.obs.library_id == lib_a) 
    & (counts_adata.obsm["spatial"][:, 1] < 6000), :
].copy()

# select also the cortex clusters
adata_anterior_subset = adata_anterior_subset[adata_anterior_subset.obs.clusters.isin(['3','5','6']),:]

# plot to check that we have the correct regions

sc.pl.spatial(
    adata_anterior_subset,
    img_key="hires",
    library_id = lib_a,
    color=['clusters'],
    size=1.5
)
```

## {{< meta st_deconv >}}

{{< meta st_deconv_1 >}}

Here, we will use deconvolution with Stereoscope implemented in the SCVI-tools package. To read more about Stereoscope please check out this github page (https://github.com/almaan/stereoscope)

### {{< meta st_deconv_genes >}}

{{< meta st_deconv_genes_1 >}}

```{python}
sc.tl.rank_genes_groups(adata_cortex, 'subclass', method = "t-test", n_genes=100, use_raw=False)
sc.pl.rank_genes_groups_dotplot(adata_cortex, n_genes=3)
```

```{python}
sc.tl.filter_rank_genes_groups(adata_cortex, min_fold_change=1)

genes = sc.get.rank_genes_groups_df(adata_cortex, group = None)
genes
```

```{python}
deg = genes.names.unique().tolist()
print(len(deg))
# check that the genes are also present in the ST data

deg = np.intersect1d(deg,adata_anterior_subset.var.index).tolist()
print(len(deg))
```

### Train the model

First, train the model using scRNAseq data.

Stereoscope requires the data to be in counts, earlier in this tutorial we saved the spatial counts in a separate object counts_adata.

In the single cell data we have the raw counts in the `raw.X` matrix so that one will be used. So here we create a new object with all the correct slots for scVI. 


```{python}
sc_adata = adata_cortex.copy()
sc_adata.X = adata_cortex.raw.X.copy()
```

Setup the anndata, the implementation requires the counts matrix to be in the "counts" layer as a copy.

```{python}

import scvi
# from scvi.data import register_tensor_from_anndata
from scvi.external import RNAStereoscope, SpatialStereoscope

# add counts layer
sc_adata.layers["counts"] = sc_adata.X.copy()

# subset for the selected genes
sc_adata = sc_adata[:, deg].copy()

# create stereoscope object
RNAStereoscope.setup_anndata(sc_adata, layer="counts", labels_key="subclass")
```

```{python}

# the model is saved to a file, so if is slow to run, you can simply reload it from disk by setting train = False

train = True
if train:
    sc_model = RNAStereoscope(sc_adata)
    sc_model.train(max_epochs=300)
    sc_model.history["elbo_train"][10:].plot()
    sc_model.save("./data/spatial/visium/scanpy_scmodel", overwrite=True)
else:
    sc_model = RNAStereoscope.load("./data/spatial/visium/scanpy_scmodel", sc_adata)
    print("Loaded RNA model from file!")
```

### Predict proportions on the spatial data

First create a new st object with the correct genes and counts as a layer.

```{python}

st_adata = adata_anterior_subset.copy()

st_adata.layers["counts"] = st_adata.X.copy()
st_adata = st_adata[:, deg].copy()

SpatialStereoscope.setup_anndata(st_adata, layer="counts")
```

```{python}

train = True
if train:
    spatial_model = SpatialStereoscope.from_rna_model(st_adata, sc_model)
    spatial_model.train(max_epochs = 3000)
    spatial_model.history["elbo_train"][10:].plot()
    spatial_model.save("./data/spatial/visium/scanpy_stmodel", overwrite = True)
else:
    spatial_model = SpatialStereoscope.load("./data/spatial/visium/scanpy_stmodel", st_adata)
    print("Loaded Spatial model from file!")
```

Get the results from the model, also put them in the .obs slot.

```{python}

st_adata.obsm["deconvolution"] = spatial_model.get_proportions()

# also copy to the obsm data frame
for ct in st_adata.obsm["deconvolution"].columns:
    st_adata.obs[ct] = st_adata.obsm["deconvolution"][ct]
```

We are then able to explore how cell types in the scRNA-seq dataset are predicted onto the visium dataset. Let's first visualize the neurons cortical layers.

```{python}

sc.pl.spatial(
    st_adata,
    img_key="hires",
    color=["L2/3 IT", "L4", "L5 PT", "L6 CT"],
    library_id=lib_a,
    size=1.5,
    ncols=2
)
```

We can go ahead an visualize astrocytes and oligodendrocytes as well.

```{python}

sc.pl.spatial(
    st_adata, img_key="hires", color=["Oligo", "Astro"], size=1.5, library_id=lib_a
)
```

{{< meta st_2 >}}

```{python}

sc.pl.violin(st_adata, ["L2/3 IT", "L6 CT","Oligo","Astro"],
            jitter=0.4, groupby = 'clusters', rotation= 45)
```

:::{.callout-note title="Discuss"}
{{< meta st_3 >}}

```{python}

lib_p = "V1_Mouse_Brain_Sagittal_Posterior"

adata_subregion = adata[
    (adata.obs.library_id == lib_p)
    & (adata.obsm["spatial"][:, 0] > 6500),
    :,
].copy()

sc.pl.spatial(
    adata_subregion,
    img_key="hires",
    library_id=lib_p,
    color=['n_genes_by_counts'],
    size=1.5
)
```

:::

## {{< meta session >}}

<details>
  <summary>Click here</summary>

```{python}
sc.logging.print_versions()
```

</details>
