---
title: "{{< meta qc_title >}}"
subtitle: "{{< meta subtitle_scanpy >}}"
description: "{{< meta qc_description >}}"
format: html
engine: jupyter
---

::: {.callout-note}
Code chunks run Python commands unless it starts with `%%bash`, in which case, those chunks run shell commands.
:::

## {{< meta qc_data >}}

{{< meta qc_data_1 >}}

```{python}
import os

# download pre-computed annotation
fetch_annotation = False

path_data = "https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq"

path_covid = "./data/covid"
if not os.path.exists(path_covid):
    os.makedirs(path_covid, exist_ok=True)

path_results = "data/covid/results"
if not os.path.exists(path_results):
    os.makedirs(path_results, exist_ok=True)
```

```{python}
import urllib.request

file_list = [
    "normal_pbmc_13.h5", "normal_pbmc_14.h5", "normal_pbmc_19.h5", "normal_pbmc_5.h5",
    "ncov_pbmc_15.h5", "ncov_pbmc_16.h5", "ncov_pbmc_17.h5", "ncov_pbmc_1.h5"
]

for i in file_list:
    path_file = os.path.join(path_covid, i)
    if not os.path.exists(path_file):
        file_url = os.path.join(path_data, "covid", i)
        urllib.request.urlretrieve(file_url, path_file)
```

{{< meta qc_data_2 >}}

```{python}
import numpy as np
import pandas as pd
import scanpy as sc
import warnings

warnings.simplefilter(action='ignore', category=Warning)

# verbosity: errors (0), warnings (1), info (2), hints (3)
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80)
```

{{< meta qc_data_3 >}}

In Scanpy we read them into an Anndata object with the the function `read_10x_h5`

```{python}
data_cov1 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_1.h5'))
data_cov1.var_names_make_unique()
data_cov15 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_15.h5'))
data_cov15.var_names_make_unique()
data_cov16 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_16.h5'))
data_cov16.var_names_make_unique()
data_cov17 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_17.h5'))
data_cov17.var_names_make_unique()
data_ctrl5 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_5.h5'))
data_ctrl5.var_names_make_unique()
data_ctrl13 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_13.h5'))
data_ctrl13.var_names_make_unique()
data_ctrl14 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_14.h5'))
data_ctrl14.var_names_make_unique()
data_ctrl19 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_19.h5'))
data_ctrl19.var_names_make_unique()
```

## {{< meta qc_collate >}}

{{< qc_collate_1 >}}

```{python}
# add some metadata
data_cov1.obs['type']="Covid"
data_cov1.obs['sample']="covid_1"
data_cov15.obs['type']="Covid"
data_cov15.obs['sample']="covid_15"
data_cov16.obs['type']="Covid"
data_cov16.obs['sample']="covid_16"
data_cov17.obs['type']="Covid"
data_cov17.obs['sample']="covid_17"
data_ctrl5.obs['type']="Ctrl"
data_ctrl5.obs['sample']="ctrl_5"
data_ctrl13.obs['type']="Ctrl"
data_ctrl13.obs['sample']="ctrl_13"
data_ctrl14.obs['type']="Ctrl"
data_ctrl14.obs['sample']="ctrl_14"
data_ctrl19.obs['type']="Ctrl"
data_ctrl19.obs['sample']="ctrl_19"

# merge into one object.
adata = data_cov1.concatenate(data_cov15, data_cov16, data_cov17, data_ctrl5, data_ctrl13, data_ctrl14, data_ctrl19)

# and delete individual datasets to save space
del(data_cov1, data_cov15, data_cov16, data_cov17)
del(data_ctrl5, data_ctrl13, data_ctrl14, data_ctrl19)
```

You can print a summary of the datasets in the Scanpy object, or a summary of the whole object.

```{python}
print(adata.obs['sample'].value_counts())
adata
```

## {{< meta qc_calqc >}}

{{< meta qc_calqc_1 >}}

{{< meta qc_calqc_2 >}}

First, let Scanpy calculate some general qc-stats for genes and cells with the function `sc.pp.calculate_qc_metrics`, similar to `calculateQCmetrics()` in Scater. It can also calculate proportion of counts for specific gene populations, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.

```{python}
# mitochondrial genes
adata.var['mt'] = adata.var_names.str.startswith('MT-') 
# ribosomal genes
adata.var['ribo'] = adata.var_names.str.startswith(("RPS","RPL"))
# hemoglobin genes.
adata.var['hb'] = adata.var_names.str.contains(("^HB[^(P|E|S)]"))

adata.var
```

```{python}
sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','ribo','hb'], percent_top=None, log1p=False, inplace=True)
```

{{< meta qc_calqc_3 >}}

Another opition to using the `calculate_qc_metrics` function is to calculate the values on your own and add to a metadata slot. An example for mito genes can be found below:

```{python}
mito_genes = adata.var_names.str.startswith('MT-')
# for each cell compute fraction of counts in mito genes vs. all genes
# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)
adata.obs['percent_mt2'] = np.sum(
    adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1
# add the total counts per cell as observations-annotation to adata
adata.obs['n_counts'] = adata.X.sum(axis=1).A1

adata
```

## {{< meta qc_plotqc >}}

{{< meta qc_plotqc_1 >}}

```{python}
sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation= 45)
```

{{< meta qc_plotqc_2 >}}

```{python}
#| fig-height: 5
#| fig-width: 5
sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color="sample")
```

:::{.callout-note title="Discuss"}
{{< meta qc_plotqc_3 >}}
:::

## {{< meta qc_filter >}}

### {{< meta qc_filter_detect >}}

{{< meta qc_filter_detect_1 >}}

```{python}
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

print(adata.n_obs, adata.n_vars)
```

{{< meta qc_filter_detect_3 >}}

```{python}
# skip for now as we are doing doublet prediction
#keep_v2 = (adata.obs['n_genes_by_counts'] < 2000) & (adata.obs['n_genes_by_counts'] > 500) & (adata.obs['lib_prep'] == 'v2')
#print(sum(keep_v2))

# filter for gene detection for v3
#keep_v3 = (adata.obs['n_genes_by_counts'] < 4100) & (adata.obs['n_genes_by_counts'] > 1000) & (adata.obs['lib_prep'] != 'v2')
#print(sum(keep_v3))

# keep both sets of cells
#keep = (keep_v2) | (keep_v3)
#print(sum(keep))
#adata = adata[keep, :]

#print("Remaining cells %d"%adata.n_obs)
```

{{< meta qc_filter_detect_4 >}}

```{python}
#| fig-height: 6
#| fig-width: 6
sc.pl.highest_expr_genes(adata, n_top=20)
```

{{< meta qc_filter_detect_5 >}}

### {{< meta qc_filter_mr >}}

{{< meta qc_filter_mr_1 >}}

```{python}
# filter for percent mito
adata = adata[adata.obs['pct_counts_mt'] < 20, :]

# filter for percent ribo > 0.05
adata = adata[adata.obs['pct_counts_ribo'] > 5, :]

print("Remaining cells %d"%adata.n_obs)
```

{{< meta qc_filter_mr_2 >}}

### {{< meta qc_filter_plot >}}

{{< meta qc_filter_plot_1 >}}

```{python}
sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation = 45)
```

### {{< meta qc_filter_genes >}}

{{< meta qc_filter_genes_1 >}}

```{python}
malat1 = adata.var_names.str.startswith('MALAT1')
# we need to redefine the mito_genes since they were first 
# calculated on the full object before removing low expressed genes.
mito_genes = adata.var_names.str.startswith('MT-')
hb_genes = adata.var_names.str.contains('^HB[^(P|E|S)]')

remove = np.add(mito_genes, malat1)
remove = np.add(remove, hb_genes)
keep = np.invert(remove)

adata = adata[:,keep]

print(adata.n_obs, adata.n_vars)
```

## {{< meta qc_sex >}}

{{< meta qc_sex_1 >}}

To get choromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline
as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. Hence, we will use biomart to fetch chromosome information.

```{python}
# requires pybiomart
if not fetch_annotation:
    annot = sc.queries.biomart_annotations("hsapiens", ["ensembl_gene_id", "external_gene_name", "start_position", "end_position", "chromosome_name"], ).set_index("external_gene_name")
    # adata.var[annot.columns] = annot
```

{{< meta qc_sex_3 >}}

```{python}
chrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == "Y"])
chrY_genes

adata.obs['percent_chrY'] = np.sum(
    adata[:, chrY_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100
```

{{< meta qc_sex_4 >}}

```{python}
#| fig-height: 5
#| fig-width: 5

# color inputs must be from either .obs or .var, so add in XIST expression to obs.
adata.obs["XIST-counts"] = adata.X[:,adata.var_names.str.match('XIST')].toarray()

sc.pl.scatter(adata, x='XIST-counts', y='percent_chrY', color="sample")
```

{{< meta qc_sex_5 >}}

```{python}
#| fig-height: 5
#| fig-width: 10

sc.pl.violin(adata, ["XIST-counts", "percent_chrY"], jitter=0.4, groupby = 'sample', rotation= 45)
```

{{< meta qc_sex_6 >}}

## {{< meta qc_cellcycle >}}

{{< meta qc_cellcycle_1 >}}

First read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. We first download the file.

```{python}
path_file = os.path.join(path_results, 'regev_lab_cell_cycle_genes.txt')
if not os.path.exists(path_file):
    urllib.request.urlretrieve(os.path.join(path_data, 'regev_lab_cell_cycle_genes.txt'), path_file)
```

```{python}
cell_cycle_genes = [x.strip() for x in open('./data/covid/results/regev_lab_cell_cycle_genes.txt')]
print(len(cell_cycle_genes))

# Split into 2 lists
s_genes = cell_cycle_genes[:43]
g2m_genes = cell_cycle_genes[43:]

cell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]
print(len(cell_cycle_genes))
```

Before running cell cycle we have to normalize the data. In the scanpy object, the data slot will be overwritten with the normalized data. So first, save the raw data into the slot `raw`. Then run normalization, log transformation and scale the data.

```{python}
# save normalized counts in raw slot.
adata.raw = adata

# normalize to depth 10 000
sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)

# logaritmize
sc.pp.log1p(adata)

# scale
sc.pp.scale(adata)
```

We here perform cell cycle scoring. The function is actually a wrapper to sc.tl.score_gene_list, which is launched twice, to score separately S and G2M phases. Both sc.tl.score_gene_list and sc.tl.score_cell_cycle_genes are a port from Seurat and are supposed to work in a very similar way. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.

```{python}
sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)
```

{{< meta qc_cellcycle_2 >}}

```{python}
#| fig-height: 5
#| fig-width: 10

sc.pl.violin(adata, ['S_score', 'G2M_score'], jitter=0.4, groupby = 'sample', rotation=45)
```

{{< meta qc_cellcycle_3 >}}

Scanpy does an automatic prediction of cell cycle phase with a default cutoff of the scores at zero. As you can see this does not fit this data very well, so be cautios with using these predictions. Instead we suggest that you look at the scores.


```{python}
#| fig-height: 8
#| fig-width: 10

sc.pl.scatter(adata, x='S_score', y='G2M_score', color="phase")
```

## {{< meta qc_doublet >}}

{{< meta qc_doublet_1 >}}


For doublet detection, we will use the package `Scrublet`, so first we need to get the raw counts from `adata.raw.X` and run scrublet with that matrix. Then we add in the doublet prediction info into our anndata object.

Doublet prediction should be run for each dataset separately, so first we need to split the adata object into 6 separate objects, one per sample and then run scrublet on each of them.

```{python}
import scrublet as scr

# split per batch into new objects.
batches = adata.obs['sample'].cat.categories.tolist()
alldata = {}
for batch in batches:
    tmp = adata[adata.obs['sample'] == batch,]
    print(batch, ":", tmp.shape[0], " cells")
    scrub = scr.Scrublet(tmp.raw.X)
    out = scrub.scrub_doublets(verbose=False, n_prin_comps = 20)
    alldata[batch] = pd.DataFrame({'doublet_score':out[0],'predicted_doublets':out[1]},index = tmp.obs.index)
    print(alldata[batch].predicted_doublets.sum(), " predicted_doublets")
```

```{python}
# add predictions to the adata object.
scrub_pred = pd.concat(alldata.values())
adata.obs['doublet_scores'] = scrub_pred['doublet_score'] 
adata.obs['predicted_doublets'] = scrub_pred['predicted_doublets'] 

sum(adata.obs['predicted_doublets'])
```

{{< meta qc_doublet_3 >}}

```{python}
#| fig-height: 5
#| fig-width: 5

# add in column with singlet/doublet instead of True/Fals
%matplotlib inline

adata.obs['doublet_info'] = adata.obs["predicted_doublets"].astype(str)
sc.pl.violin(adata, 'n_genes_by_counts', jitter=0.4, groupby = 'doublet_info', rotation=45)
```

Now, lets run PCA and UMAP and plot doublet scores onto UMAP to check the doublet predictions.

```{python}
#| fig-height: 4
#| fig-width: 12

sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)
adata = adata[:, adata.var.highly_variable]
sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])
sc.pp.scale(adata, max_value=10)
sc.tl.pca(adata, svd_solver='arpack')
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata)
sc.pl.umap(adata, color=['doublet_scores','doublet_info','sample'])
```

{{< meta qc_doublet_4 >}}

```{python}
# also revert back to the raw counts as the main matrix in adata
adata = adata.raw.to_adata() 

adata = adata[adata.obs['doublet_info'] == 'False',:]
print(adata.shape)
```

## {{< meta qc_save >}}

{{< meta qc_save_1 >}}

```{python}
adata.write_h5ad('data/covid/results/scanpy_covid_qc.h5ad')
```

## {{< meta session >}}

<details>
  <summary>Click here</summary>

```{python}
sc.logging.print_versions()
```

</details>