---
output: html_document
editor_options:
  chunk_output_type: console
---

#CSS_ALL:author: "Åsa Björklund  &  Paulo Czarnewski"
#CSS_ALL:date: '`r format(Sys.Date(), "%B %d, %Y")`'
#CSS_ALL:output:
#CSS_ALL:  html_document:
#CSS_ALL:    self_contained: true
#CSS_ALL:    highlight: tango
#CSS_ALL:    df_print: paged
#CSS_ALL:    toc: yes
#CSS_ALL:    toc_float:
#CSS_ALL:      collapsed: false
#CSS_ALL:      smooth_scroll: true
#CSS_ALL:    toc_depth: 3
#CSS_ALL:    keep_md: yes
#CSS_ALL:    fig_caption: true
#CSS_ALL:  html_notebook:
#CSS_ALL:    self_contained: true
#CSS_ALL:    highlight: tango
#CSS_ALL:    df_print: paged
#CSS_ALL:    toc: yes
#CSS_ALL:    toc_float:
#CSS_ALL:      collapsed: false
#CSS_ALL:      smooth_scroll: true
#CSS_ALL:    toc_depth: 3


#CHUNK_OPT:```{r setup, include=FALSE}
#CHUNK_OPT:knitr::opts_chunk$set(message=FALSE, warning=FALSE, result='hold',fig.width=12,tidy=TRUE)
#CHUNK_OPT:knitr::opts_knit$set(progress=TRUE,verbose=TRUE)
#CHUNK_OPT:```
#CHUNK_OPT:<style>
#CHUNK_OPT:h1, .h1, h2, .h2, h3, .h3, h4, .h4 { margin-top: 50px }
#CHUNK_OPT:p.caption {font-size: 0.9em;font-style: italic;color: grey;margin-right: 10%;margin-left: 10%;text-align: justify}
#CHUNK_OPT:</style>


#define path to this script (wherever it is)
```{r setup, include=FALSE}
initial.options <- commandArgs(trailingOnly = FALSE)
script_path <- dirname(sub("--file=","",initial.options[grep("--file=",initial.options)]))
setwd(script_path)

dir.create("compiled/seurat",recursive = T, showWarnings = F)
dir.create("compiled/scater",recursive = T, showWarnings = F)
dir.create("compiled/scanpy",recursive = T, showWarnings = F)
```






#------------------#
#   SESSION INFO   #
#------------------#
#SESSION_INFO:### Session Info
#SESSION_INFO:***
#-----------



#----------------------------#
#   GET LIBRARIES AND DATA   #
#----------------------------#
#DATA_TITLE:# Get data

#DATA_ALL1:In this tutorial, we will run all tutorials with a set of 6 PBMC 10x datasets from 3 covid-19 patients and 3 healthy controls, the samples have been subsampled to 1500 cells per sample. They are part of the github repo and if you have cloned the repo they should be available in folder: `labs/data/covid_data_GSE149689`. Instructions on how to download them can also be found in the Precourse material.

#DATA_ALL2:With data in place, now we can start loading libraries we will use in this tutorial.

#DATA_ALL3:We can first load the data individually by reading directly from HDF5 file format (.h5).

#DATA_SEURAT:
#DATA_SCRAN:
#DATA_SCRANPY:
#-----------




#-------------------#
#   CREATE OBJECT   #
#-------------------#
#OBJ_TITLE:# Create one merged object
#OBJ_ALL1:We can now load the expression matricies into objects and then merge them into a single merged object. Each analysis workflow (Seurat, Scater, Scranpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column `Chemistry` in the metadata for plotting later on.

#OBJ_ALL1.1:Once you have created the merged Seurat object, the count matrices and individual count matrices and objects are not needed anymore. It is a good idea to remove them and run garbage collect to free up some memory.

#OBJ_ALL2: Here it is how the count matrix and the metatada look like for every cell.

#OBJ_SEURAT:
#OBJ_SCRAN:
#OBJ_SCRANPY: You can print a summary of the datasets in the Scanpy object, or a summary of the whole object.
#-----------



#--------#
#   QC   #
#--------#
#QC_TITLE:# Calculate QC

#QC_ALL1:Having the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitocondrial and ribosomal genes per cell and add to the metadata. This will be helpfull to visualize them across different metadata parameteres (i.e. datasetID and chemistry version). There are several ways of doing this, and here manually calculate the proportion of mitochondrial reads and add to the metadata table.

#QC_ALL1.1:Citing from "Simple Single Cell" workflows (Lun, McCarthy & Marioni, 2017): "High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane."

#QC_1_SCANPY: First, let Scanpy calculate some general qc-stats for genes and cells with the function `sc.pp.calculate_qc_metrics`, similar to `calculateQCmetrics` in Scater. It can also calculate proportion of counts for specific gene populations, so first we need to define which genes are mitochondrial, ribosomal and hemoglogin.

#QC_1.1_SCANPY: Here is an example on how to calculate proportion mitochondria in another way:

#QC_1_SCATER: First, let Scran calculate some general qc-stats for genes and cells with the function `perCellQCMetrics`. It can also calculate proportion of counts for specific gene subsets, so first we need to define which genes are mitochondrial, ribosomal and hemoglogin.

#QC_1.1_SCATER: Here is an example on how to calculate proportion mitochondria in another way:


#QC_ALL2:In the same manner we will calculate the proportion gene expression that comes from ribosomal proteins.

#QC_2_SCANPY: Now you can see that we have additional data in the scanpy `obs` slot.

#QC_ALL2.2:And finally, with the same method we will calculate proportion hemoglobin genes, which can give an indication of red blood cell contamination.

#QC_TITLE2:# Plot QC

#QC_ALL3:Now we can plot some of the QC-features as violin plots.

#QC_ALL4:As you can see, there is quite some difference in quality for the 4 datasets, with for instance the covid_15 sample having fewer cells with many detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. And we can plot the different QC-measures as scatter plots.

#QC_ALL4.4:### TASK: Plot scatterplots
#QC_ALL4.4:Plot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?

#-----------



#---------------#
#   FILTERING   #
#---------------#
#FILTERING_TITLE:# Filtering

#FILTERING_TITLE1:## Detection-based filtering

#FILTERING_SCATER0:In scran, we can use the function `quickPerCellQC` to filter out outliers from distributions of qc stats, such as dected genes, gene subsets etc. But in this case, we will take one setting at a time and run through the steps of filtering cells.

#FILTERING_ALL0:A standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.

#FILTERING_ALL3: Extremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. <br>In these datasets, there is also a clear difference between the v2 vs v3 10x chemistry with regards to gene detection, so it may not be fair to apply the same cutoffs to all of them. Also, in the protein assay data there is a lot of cells with few detected genes giving a bimodal distribution. This type of distribution is not seen in the other 2 datasets. Considering that they are all PBMC datasets it makes sense to regard this distribution as low quality libraries. Filter the cells with high gene detection (putative doublets) with cutoffs 4100 for v3 chemistry and 2000 for v2. <br>Here, we will filter the cells with low gene detection (low quality libraries) with less than 1000 genes for v2 and < 500 for v2.

#FILTERING_ALL01:Additionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.

#FILTERING_SCATER01:In scater, you can also use the function `plotHighestExprs()` to plot the gene contribution, but the function is quite slow.

#FILTERING_ALL02:As you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.


#FILTERING_TITLE2:## Mito/Ribo filtering

<<<<<<< HEAD
#FILTERING_ALL1:We also have quite a lot of cells with high proportion of mitochondrial and low proportion ofribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. <br>Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. <br>A third option would be to just regress out the `percent_mito` variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. <br>Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.
=======
#FILTERING_ALL1:We also have quite a lot of cells with high proportion of mitochondrial and low proportion ofribosomal reads. It could be wise to remove those cells, if we have enough cells left after filtering. <br>Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. <br>A third option would be to just regress out the `percent_mito` variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. <br>Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 25% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.
>>>>>>> f1af9cf54168235f13c95a4586e6d1d0f1763225

#FILTERING_ALL2: As you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in `percent_mito`, so it will have to be dealt with in the data analysis step. We can also notice that the `percent_ribo` are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.



#FILTERING_TITLE4:## Plot filtered QC

#FILTERING_ALL5:Lets plot the same QC-stats another time.
#-----------

#FILTERING_TITLE5:## Filter genes

#FILTERING_ALL6:As the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset bofore any further analysis.

#FILTERING_ALL7:## Save data

#FILTERING_ALL8:Save the filtered dataset to a file for use in later labs.

#----------------#
#   CELL CYCLE   #
#----------------#
#CELLCYCLE_TITLE:# Calculate cell-cycle scores

#CELLCYCLE_ALL1:We here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.

#CELLCYCLE_1_SCANPY:First read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. Cell cycle genes were retrieved from the scanpy_usage github site via web browser at [RegevLab Github repo](https://github.com/theislab/scanpy_usage/blob/master/180209_cell_cycle/data/regev_lab_cell_cycle_genes.txt).

#CELLCYCLE_2_SCANPY: Before running cell cycle we have to normalize the data. In the scanpy object, the data slot will be overwritten with the normalized data. So first, save the raw data into the slot `raw`.  <br><br>Then run normalization, logarimize and scale the data.


#CELLCYCLE_3_SCANPY:We here perform cell cycle scoring. The function is actually a wrapper to sc.tl.score_gene_list, which is launched twice, to score separately S and G2M phases. Both sc.tl.score_gene_list and sc.tl.score_cell_cycle_genes are a port from Seurat and are supposed to work in a very similar way. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.

#CELLCYCLE_ALL2:We can now plot a violin plot for the cell cycle scores as well.

#CELLCYCLE_ALL3:In this case it looks like we only have a few cycling cells in the datasets.

#CELLCYCLE_SCATER3:Cyclone predicts most cells as G1, but also quite a lot of cells with high S-Phase scores. Compare to results with Seurat and Scanpy and see how different predictors will give clearly different results.

#----------------#
#   DOUBLET      #
#----------------#
#DOUBLET_TITLE:# Predict doublets

#DOUBLET_ALL1:Doublets/Mulitples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods whith overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As  indicated from the Chromium user guide, doublet rates are about as follows:
#DOUBLET_ALL1:![](../../figs/10x_doublet_rate.png)

#DOUBLET_ALL1:Most doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the orignial datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.

#DOUBLET_ALL1:OBS! Ideally doublet prediction should be run on each sample separately, especially if your different samples have different proportions of celltypes. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs so it is okay to run them together.

#DOUBLET_SEURAT1.1:Here, we will use `DoubletFinder` to predict doublet cells. But before doing doublet detection we need to run scaling, variable gene selection and pca, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.

#DOUBLET_SEURAT1.2:Then we run doubletFinder, selecting first 10 PCs and a pK value of 0.9. To optimize the parameters, you can run the `paramSweep` function in the package.

#DOUBLET_SCANPY1:For doublet detection, we will use the package `Scrublet`, so first we need to get the raw counts from `adata.raw.X` and run scrublet with that matrix. Then we add in the doublet prediction info into our anndata object.


DOUBLET_SCATER1:There is a method to predict if a cluster consists of mainly doublets `findDoubletClusters()`, but we can also predict individual cells based on simulations using the function `computeDoubletDensity()` which we will do here.

DOUBLET_SCATER1:Doublet detection will be performed using PCA, so we need to first normalize the data and run variable gene detection, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.

#DOUBLET_ALL1.1:We should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.

#DOUBLET_SCANPY1.3:Now, lets run PCA and UMAP and plot doublet scores onto umap to check the doublet predictions.

#DOUBLET_ALL2:Now, lets remove all predicted doublets from our data.


#DOUBLET_ALL3:# Save data
#DOUBLET_ALL3:Finally, lets save the QC-filtered data for further analysis. Create output directory `results` and save data to that folder.


#-----------
```{r setup, include=FALSE}
for( pipeline in c("seurat","scater")){
  lab <- readLines(paste0(script_path,"/",pipeline,"/",pipeline,"_01_qc.Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_01_qc.Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_01_qc.Rmd"))
}
```



#------------------------------#
#   DIMENSIONALITY REDUCTION   #
#------------------------------#

#DIMRED_MAIN:# Dimensionality reduction
#DIMRED_MAIN:
#DIMRED_MAIN:Paulo Czarnewski

#DIMRED_TITLE:## Data preparation
#DIMRED_TITLE:***

#DIMRED_ALL1:First, let's load all necessary libraries and the QC-filtered dataset from the previous step.

#DIMRED_ALL1.1:### Feature selection

#DIMRED_1_SCANPY: Before variable gene selection we need to normalize and logaritmize the data. Then  store the full matrix in the `raw`  slot before doing variable gene selection.

#DIMRED_ALL2:Next, we first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.

#DIMRED_ALL3:### Z-score transformation

#DIMRED_ALL4:Now that the data is prepared, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling is called Z-score normalization it is very useful for PCA, clustering and plotting heatmaps. <br>Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as `cell cycle`, `sequencing depth`, `percent mitocondria`. This is achieved by doing a generalized linear regression using these parameters as covariates in the model. Then the residuals of the model are taken as the "regressed data". Although perhaps not in the best way, batch effect regression can also be done here.

#DIMRED_SCATER4:By default variables are scaled in the PCA step and is not done separately. But it could be acheieved by running the commads below:

#DIMRED_SCATER1:However, unlike the Seurat, this step is implemented inside the PCA function below. Here we will show you how to add the scaledData back to the object.

#---------#
#   PCA   #
#---------#
#PCA_TITLE:## PCA
#PCA_TITLE:***
#PCA_ALL1:Performing PCA has many useful applications and interpretations, which much depends on the data used. In the case of life sciences, we want to segregate samples based on gene expression patterns in the data.
#PCA_SEURAT:To run PCA you can use the function `RunPCA()`.
#PCA_SCRAN:As said above, we use the `logcounts` and then set `scale_features` to TRUE in order to scale each gene.
#PCA_SCANPY:To run PCA, you can use the function `pca()`.
#PCA_ALL2:We then plot the first principal components.
#PCA_ALL3:To identify which genes (Seurat) or metadata paramters (Scater/Scran) contribute the most to each PC, one can retreive the loading matrix information. Unfortunatelly this is not implemented in Scater/Scran, so you will need to compute PCA using `logcounts`.
#PCA_3_SCANPY:To identify genes that contribute most to each PC, one can retreive the loading matrix information.
#PCA_4_SCANPY:The function to plot loading genes only plots genes on the positive axes. Instead plot as a heatmaps, with genes on both postive and negative side, one per pc, and plot their expression amongst cells ordered by their position along the pc.

#PCA_ALL5:We can also plot the amount of variance explained by each PC.
#PCA_ALL6:Based on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain pregressivelly less. However, it is still advisable to use more PCs since they might contain informaktion about rare cell types (such as platelets and DCs in this dataset)

#----------#
#   tSNE   #
#----------#
#tSNE_TITLE:## tSNE
#tSNE_TITLE:***
#tSNE_ALL1:We can now run [BH-tSNE](https://arxiv.org/abs/1301.3342).

#tSNE_ALL2:We can now plot the tSNE colored per dataset. We can clearly see the effect of batches present in the dataset.

#----------#
#   UMAP   #
#----------#
#UMAP_TITLE:## UMAP
#UMAP_TITLE:***
#UMAP_ALL1:We can now run [UMAP](https://arxiv.org/abs/1802.03426) for cell embeddings.

#UMAP_1_SCANPY:### Calculate neighborhood graph
#UMAP_1.1_SCANPY:The UMAP implementation in SCANPY uses a neighborhood graph as the distance matrix, so we need to first calculate the graph.

#UMAP_2_SCANPY:Now we can run UMAP.

#UMAP_ALL1.1:### TASK: Test settings
#UMAP_ALL1.1:We have now done Variable gene selection, PCA and UMAP with the settings we chose. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding.

#UMAP_ALL2:Another usefullness of UMAP is that it is not limitted by the number of dimensions the data cen be reduced into (unlike tSNE). We can simply reduce the dimentions altering the `n.components` parameter.
#UMAP_ALL2.1:We can now plot the UMAP colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.
#UMAP_ALL2.2:We can now plot PCA, UMAP and tSNE side by side for comparison. Here, we can conclude that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.


#DIMRED_TITLE2:## Using ScaledData and graphs for DR
#DIMRED_TITLE2:***
#DIMRED_ALL5:Althought running a sencond dimmensionality reduction (i.e tSNE or UMAP) on PCA would be a standard approach (because it allows higher computation efficiency), the options are actually limiteless. Below we will show a couple of other common options such as running directly on the scaled data (which was used for PCA) or on a graph built from scaled data. We will show from now on only UMAP, but the same applies for tSNE.

#DIMRED_ALL5.0:### Using ScaledData for UMAP
#DIMRED_ALL5.1:To run tSNE or UMAP on the scaled data, one firts needs to select the number of variables to use. This is because including dimentions that do contribute to the separation of your cell types will in the end mask those differences. Another reason for it is because running with all genes/features also will take longer or might be computationally unfeasible. Therefore we will use the scaled data of the highly variable genes.

#DIMRED_ALL5.2.1:### Using a Graph for UMAP
#DIMRED_ALL5.2:To run tSNE or UMAP on the a graph, we first need to build a graph from the data. In fact, both tSNE and UMAP first build a graph from the data using a specified distance metrix and then optimize the embedding. Since a graph is just a matrix containing distances from cell to cell and as such, you can run either UMAP or tSNE using any other distance metric desired. Euclidean and Correlation are ususally the most commonly used.
#DIMRED_ALL5.3:We can now plot the UMAP comparing both on PCA vs ScaledSata vs Graph.

#DIMRED_TITLE3:## Ploting genes of interest
#DIMRED_TITLE3:***
#DIMRED_ALL6:Let's plot some marker genes for different celltypes onto the embedding. Some genes are:
#MARKER_TABLE:Markers	| Cell Type
#MARKER_TABLE:--- | ---
#MARKER_TABLE:CD3E	| T cells
#MARKER_TABLE:CD3E CD4	| CD4+ T cells
#MARKER_TABLE:CD3E CD8A	| CD8+ T cells
#MARKER_TABLE:GNLY, NKG7	| NK cells
#MARKER_TABLE:MS4A1	| B cells
#MARKER_TABLE:CD14, LYZ, CST3, MS4A7	| CD14+ Monocytes
#MARKER_TABLE:FCGR3A, LYZ, CST3, MS4A7	| FCGR3A+  Monocytes
#MARKER_TABLE:FCER1A, CST3 | DCs

#MARKER_1_SCANPY: The default is to plot gene expression in the normalized and log-transformed data. You can also plot it on the scaled and corrected data by using `use_raw=False`. However, not all of these genes are included in the variable gene set so we first need to filter them.

#DIMRED_ALL7:We can finally save the object for use in future steps.

#DIMRED_ALL8:### TASK: Plot QC stats.
#DIMRED_ALL8:Select some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?


```{r setup, include=FALSE}
for( pipeline in c("seurat","scater")){
  lab <- readLines(paste0(script_path,"/",pipeline,"/",pipeline,"_02_dim_reduction.Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_02_dim_reduction_compiled.Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_02_dim_reduction_compiled.Rmd"))
}
```
#-----------











#----------------------#
#   DATA INTEGRATION   #
#----------------------#

#INTEG_TITLE:# Dataset integration
#INTEG_TITLE:
#INTEG_TITLE:Paulo Czarnewski

#INTEG_ALL1:In this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore two different methods to correct for batch effects across datasets. We will also look at a quantitative measure to assess the quality of the integrated data. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of the most recent methods for single data integration:

#INTEG_TABLE:Markdown | Language | Library | Ref
#INTEG_TABLE:--- | --- | --- | ---
#INTEG_TABLE:CCA | R | Seurat | [Cell](https://www.sciencedirect.com/science/article/pii/S0092867419305598?via%3Dihub)
#INTEG_TABLE:MNN | R/Python | Scater/Scanpy | [Nat. Biotech.](https://www.nature.com/articles/nbt.4091)
#INTEG_TABLE:Conos | R | conos | [Nat. Methods](https://www.nature.com/articles/s41592-019-0466-z?error=cookies_not_supported&code=5680289b-6edb-40ad-9934-415dac4fdb2f)
#INTEG_TABLE:Scanorama | Python | scanorama | [Nat. Biotech.](https://www.nature.com/articles/s41587-019-0113-3)

#INTEG_ALL2:Let's first load necessary libraries and the data saved in the previous lab.



#INTEG_ALL3:We split the combined object into a list, with each dataset as an element. We perform standard preprocessing (log-normalization), and identify variable features individually for each dataset based on a variance stabilizing transformation ("vst").

#INTEG_SEURAT1:We identify anchors using the FindIntegrationAnchors function, which takes a list of Seurat objects as input.
#INTEG_SEURAT2:We then pass these anchors to the IntegrateData function, which returns a Seurat object.
#INTEG_SEURAT3:We can observe that a new assay slot is now created under the name `CCA`.
#INTEG_SEURAT4:After running IntegrateData, the Seurat object will contain a new Assay with the integrated (or ‘batch-corrected’) expression matrix. Note that the original (uncorrected values) are still stored in the object in the “RNA” assay, so you can switch back and forth. We can then use this new integrated matrix for downstream analysis and visualization. Here we scale the integrated data, run PCA, and visualize the results with UMAP and TSNE. The integrated datasets cluster by cell type, instead of by technology.


#INTEG_SCRAN1:The mutual nearest neighbors (MNN) approach within the scran package utilizes a novel approach to adjust for batch effects. The `fastMNN()` function returns a representation of the data with reduced dimensionality, which can be used in a similar fashion to other lower-dimensional representations such as PCA. In particular, this representation can be used for downstream methods such as clustering. The BNPARAM can be used to specify the specific nearest neighbors method to use from the BiocNeighbors package. Here we make use of the [Annoy library](https://github.com/spotify/annoy) via the `BiocNeighbors::AnnoyParam()` argument. We save the reduced-dimension MNN representation into the reducedDims slot of our sce object.
#INTEG_SCRAN2:**NOTE**: `fastMNN()` does not produce a batch-corrected expression matrix.
#INTEG_SCRAN3:We can observe that a new assay slot is now created under the name `MNN`.
#INTEG_SCRAN4:Thus, the result from `fastMNN()` should solely be treated as a reduced dimensionality representation, suitable for direct plotting, TSNE/UMAP, clustering, and trajectory analysis that relies on such results.

#INTEG_1_SCANPY:As the stored AnnData object contains scaled data based on variable genes, we need to make a new object with the logtransformed normalized counts. The new variable gene selection should not be performed on the scaled data matrix.

#INTEG_2_SCANPY:### Detect variable genes

#INTEG_3_SCANPY:Variable genes can be detected across the full dataset, but then we run the risk of getting many batch-specific genes that will drive a lot of the variation. Or we can select variable genes from each batch separately to get only celltype variation. In the dimensionality reduction exercise, we already selected variable genes, so they are already stored in `adata.var.highly_variable`

#INTEG_5_SCANPY:Detect variable genes in each dataset separately using the `batch_key` parameter.
#INTEG_6_SCANPY: Compare overlap of variable genes with batches or with all data.
#INTEG_7_SCANPY:### Data integration
#INTEG_8_SCANPY:First we need to create individual AnnData objects from each of the datasets.
#INTEG_8_SCANPY:Then perform batch correction with MNN.
#INTEG_9_SCANPY:*OBS!* To run mnn, the package mnnpy needs to be installed with `pip install mnnpy`.
#INTEG_10_SCANPY:The mnn_correct function returns a tuple with the AnnData object, list of cell pairs and of angles.Hence, cdata[0] is the new AnnData object. <br> We get corrected expression values for all genes even though only the selected genes were used for finding neighbor cells. For later analysis we want to do dimensionality reduction etc. on the variable genes only, so we will subset the data to only include the variable genes.
#INTEG_11_SCANPY:Now lets run dimensionality reduction on the new integrated object. tSNE and UMAP is run on the new embeddings created by MNN.

#INTEG_12_SCANPY:##Extra exercises
#INTEG_12_SCANPY:###Combat
#INTEG_13_SCANPY:Batch correction can also be performed with combat.<br>Note that ComBat batch correction requires a dense matrix format as input (which is already the case in this example).
#INTEG_14_SCANPY: Variable gene selection, pca and umap with combat data.

#INTEG_15_SCANPY:###Scanorama
#INTEG_16_SCANPY:Try out [Scanorama](https://github.com/brianhie/scanorama) for data integration as well.
#INTEG_16_SCANPY:To run Scanorama, you need to install python-annoy (already included in conda environment) and scanorama with pip.
#INTEG_16_SCANPY:We can run scanorama to get a corrected matrix with the `correct` function, or to just get the data projected onto a new common dimension with the function `integrate`. Or both with the `correct_scanpy` and setting `return_dimred=True`. For now, run with just integration.


#INTEG_ALL4:We can now plot the un-integrated and the integrated space reduced dimensions.

#INTEG_ALL5:Finally, lets save the integrated data for further analysis.

```{r setup, include=FALSE}
for( pipeline in c("seurat","scater")){
  lab <- readLines(paste0(script_path,"/",pipeline,"/",pipeline,"_03_integration.Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_03_integration_compiled.Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_03_integration_compiled.Rmd"))
}
```

#-----------











#----------------#
#   CLUSTERING   #
#----------------#
#CLUST_TITLE:# Clustering
#CLUST_TITLE:
#CLUST_ALL:In this tutorial we will continue the analysis of the integrated dataset. We will use the integrated PCA to perform the clustering. First we will construct a $k$-nearest neighbour graph in order to perform a clustering on the graph. We will also show how to perform hierarchical clustering and k-means clustering on PCA space.

#CLUST_1_SCANPY:In this tutorial we will continue the analysis of the integrated dataset. We will use the scanpy enbedding to perform the clustering using graph community detection algorithms.

#CLUST_ALL2:Let's first load all necessary libraries and also the integrated dataset from the previous step.


#----------------------#
#   Graph clustering   #
#----------------------#
#CLUST_TITLE2:## Graph clustering
#CLUST_TITLE2:***
#CLUST_ALL3:The procedure of clustering on a Graph can be generalized as 3 main steps:
#CLUST_ALL3:
#CLUST_ALL3:1) Build a kNN graph from the data
#CLUST_ALL3:
#CLUST_ALL3:2) Prune spurious connections from kNN graph (optional step). This is a SNN graph.
#CLUST_ALL3:
#CLUST_ALL3:3) Find groups of cells that maximizes the connections within the group compared other groups.



#CLUST_TITLE2.1:### Building kNN / SNN graph
#CLUST_TITLE2.1:

#CLUST_ALL4:The first step into graph clustering is to construct a k-nn graph, in case you don't have one. For this, we will use the PCA space. Thus, as done for dimensionality reduction, we will use ony the top *N* PCA dimensions for this purpose (the same used for computing UMAP / tSNE).
#CLUST_SEURAT:As we can see above, the **Seurat** function `FindNeighbors` already computes both the KNN and SNN graphs, in which we can control the minimal percentage of shared neighbours to be kept. See `?FindNeighbors` for additional options.
#CLUST_2.1_SCANPY:If you recall from the integration, we already constructed a knn graph before running UMAP. Hence we do not need to do it again, and can run the community detection right away.

#CLUST_ALL4.1:We can take a look at the kNN graph. It is a matrix where every connection between cells is represented as $1$s. This is called a **unweighted** graph (default in Seurat). Some cell connections can however have more importance than others, in that case the scale of the graph from $0$ to a maximum distance. Usually, the smaller the distance, the closer two points are, and stronger is their connection. This is called a **weighted** graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (> 100k cells).


#CLUST_SCATER2:As you can see, the way Scran computes the SNN graph is different to Seurat. It gives edges to all cells that shares a neighbor, but weights the edges by how similar the neighbors are. Hence, the SNN graph has more edges than the KNN graph.

#CLUST_TITLE2.2:### Clustering on a graph
#CLUST_TITLE2.2:
#CLUST_ALL4.2:Once the graph is built, we can now perform graph clustering. The clustering is done respective to a resolution which can be interpreted as how coarse you want your cluster to be. Higher resolution means higher number of clusters.
#CLUST_SEURAT2:In **Seurat**, the function `FindClusters` will do a graph-based clustering using "Louvain" algorithim by default (`algorithm = 1`). TO use the leiden algorithm, you need to set it to `algorithm = 4`. See `?FindClusters` for additional options.
#CLUST_ALL4.3:We can now use the `clustree` package to visualize how cells are distributed between clusters depending on resolution.
#CLUST_2_SCANPY:The modularity optimization algoritm in Scanpy are *Leiden* and *Louvain*. Lets test both and see how they compare.
#CLUST_3_SCANPY:###Leiden
#CLUST_4_SCANPY:Plot the clusters, as you can see, with increased resolution, we get higher granularity in the clustering.
#CLUST_5_SCANPY: Once we have done clustering, the relationships between clusters can be calculated as correlation in PCA space and we also visualize some of the marker genes that we used in the Dim Reduction lab onto the clusters.

#CLUST_6_SCANPY:###Louvain



#------------------------#
#   K-means clustering   #
#------------------------#
#CLUST_TITLE3:## K-means clustering
#CLUST_TITLE3:***
#CLUST_ALL7:K-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).




#-----------------------------#
#   Hierarchical clustering   #
#-----------------------------#
#CLUST_TITLE4:## Hierarchical clustering
#CLUST_TITLE4:***
#CLUST_ALL8:Hierarchical clustering is another generic form of clustering that can be applied also to scRNA-seq data. As K-means, it is typically applied to a reduced dimension representation of the data. Hierarchical clustering returns an entire hierarchy of partitionings (a dendrogram) that can be cut at different levels. Hierarchical clustering is done in two steps:
#CLUST_ALL8:
#CLUST_ALL8:* Step1: Define the distances between samples. The most common are Euclidean distance (a.k.a. straight line between two points) or correlation coefficients.
#CLUST_ALL8:* Step2: Define a measure of distances between clusters, called *linkage* criteria. It can for example be average distances between clusters. Commonly used methods are `single`, `complete`, `average`, `median`, `centroid` and `ward`.
#CLUST_ALL8:* Step3: Define the dendrogram among all samples using **Bottom-up** or **Top-down** approach. **Bottom-up** is where samples start with their own cluster which end up merged pair-by-pair until only one cluster is left. **Top-down** is where samples start all in the same cluster that end up being split by 2 until each sample has its own cluster.


#CLUST_TITLE4.1:### Defining distance between cells
#CLUST_ALL8.1:The base R `stats` package already contains a function `dist` that calculates distances between all pairs of samples. Since we want to compute distances between samples, rather than among genes, we need to transpose the data before applying it to the `dist` function. This can be done by simply adding the transpose function `t()` to the data. The distance methods available  in `dist` are: "euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski".

#CLUST_ALL8.2:As you might have realized, correlation is not a method implemented in the `dist` function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the `cor` function.

#CLUST_ALL8.2:As you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. **adjacency**):
#CLUST_ALL8.2:
#CLUST_ALL8.2:\[adj = \frac{1- cor}{2}\]
#CLUST_ALL8.2:
#CLUST_ALL8.2:Once we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using `as.dist` function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.


#CLUST_SCANPY8.2: The function `AgglomerativeClustering` has the option of running with disntance metrics “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed". However, with ward linkage only euklidean distances works. Here we will try out euclidean distance and ward linkage calculated in PCA space.



#CLUST_TITLE4.2:### Clustering cells
#CLUST_ALL8.3:After having calculated the distances between samples calculated, we can now proceed with the hierarchical clustering per-se. We will use the function `hclust` for this purpose, in which we can simply run it with the distance objects created above. The methods available are: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median" or "centroid". It is possible to plot the dendrogram for all cells, but this is very time consuming and we will omit for this tutorial.

#CLUST_ALL8.4: Once your dendrogram is created, the next step is to define which samples belong to a particular cluster. After identifying the dendrogram, we can now literally cut the tree at a fixed threshold (with `cutree`) at different levels to define the clusters. We can either define the number of clusters or decide on a height. We can simply try different clustering levels.

#CLUST_ALL9:Finally, lets save the integrated data for further analysis.

#CLUST_ALL10:###TASK: Check QC-stats
#CLUST_ALL10:By now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads.
#CLUST_ALL10:Then, check carefully if there is any bias in how your data is separated due to quality metrics. Could it be explained biologically, or could you have technical bias there?



#--------------------------------------#
#   K-means + Hierachical clustering   #
#--------------------------------------#
#CLUST_TITLE5:### K-means + Hierachical clustering
#CLUST_TITLE5:***




#------------------------------------#
#   Testing Clustering robusteness   #
#------------------------------------#
#CLUST_TITLE6:### Testing Clustering robusteness
#CLUST_TITLE6:***



```{r setup, include=FALSE}
for( pipeline in c("seurat","scater")){
  lab <- readLines(paste0(script_path,"/",pipeline,"/",pipeline,"_04_clustering.Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_04_clustering_compiled.Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_04_clustering_compiled.Rmd"))
}
```

#-----------








#----------------------------------#
#   Differential gene expression   #
#----------------------------------#
#DGE_TITLE:# Differential gene expression
#DGE_ALL:In this tutorial we will cover about Differetial gene expression, which comprises an extensive range of topics and methods. In single cell, differential expresison can have multiple functionalities such as of identifying marker genes for cell populations, as well as differentially regulated genes across conditions (healthy vs control). We will also exercise on how to account the batch information in your test.
#DGE_ALL2:We can first load the data from the clustering session. Moreover, we can already decide which clustering resolution to use. First let's define using the `louvain` clustering to identifying differentially expressed genes.  


#DGE_TITLE1:## Cell marker genes
#DGE_TITLE1:***

#DGE_ALL3:Let us first compute a ranking for the highly differential genes in each cluster. There are many different tests and parameters to be chosen that can be used to refine your results. When looking for marker genes, we want genes that are positivelly expressed in a cell type and possibly not expressed in the others.

#DGE_ALL4:We can now select the top 25 up regulated genes for plotting.

#DGE_ALL4.1:We can visualize them as a heatmap. Here we are selecting the top 5.

#DGE_ALL4.2:Another way is by representing the overal group expression and detection rates in a dot-plot.

#DGE_ALL4.3:We can also plot a violin plot for each gene.

#DGE_ALL5:<style>
#DGE_ALL5:div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
#DGE_ALL5:</style>
#DGE_ALL5:<div class = "blue">
#DGE_ALL5:**Your turn**
#DGE_ALL5:
#DGE_ALL5:Take a screen shot of those results and re-run the same code above with another test: "wilcox" (Wilcoxon Rank Sum test), "bimod" (Likelihood-ratio test), "roc" (Identifies 'markers' of gene expression using ROC analysis),"t" (Student's t-test),"negbinom" (negative binomial generalized linear model),"poisson" (poisson generalized linear model), "LR" (logistic regression), "MAST" (hurdle model), "DESeq2" (negative binomial distribution).
#DGE_ALL5:</div>

#DGE_TITLE2:## Differential expression across conditions
#DGE_TITLE2:***

#DGE_ALL6:The second way of computing differential expression is to answer which genes are differentially expressed within a cluster. For example, in our case we have libraries comming from patients and controls and we would like to know which genes are influenced the most in a particular cell type.
#DGE_ALL6:
#DGE_ALL6:For this end, we will first subset our data for the desired cell cluster, then change the cell identities to the variable of comparison (which now in our case is the "type", e.g. Covid/Ctrl).

#DGE_ALL6.1:We can now plot the expression across the "type".
#DGE_ALL6.1b:We can also plot these genes across all clusters, but split by "type", to check if the genes are also up/downregulated in other celltypes.


#DGE_ALL6.3:<style>
#DGE_ALL6.3:div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
#DGE_ALL6.3:</style>
#DGE_ALL6.3:<div class = "blue">
#DGE_ALL6.3:**Your turn**
#DGE_ALL6.3:
#DGE_ALL6.3:1) Are the differentially expressed genes across `type` different for each cluster, or are they all the same genes? Change the cluster to use above and check.
#DGE_ALL6.3:2) How would you visualize the results from the previous question?
#DGE_ALL6.3:</div>

#DGE_TITLE3:## Gene Set Analysis
#DGE_TITLE3:***

#DGE_TITLE3.1:Hypergeometric enrichment test

#DGE_ALL7:Having a defined list of differentially expressed genes, you can now look for their combined function using hypergeometric test:
#DGE_ALL7.1:
#DGE_ALL7.1:Some databases of interest:
#DGE_ALL7.1:
#DGE_ALL7.1:* `GO_Biological_Process_2017b`
#DGE_ALL7.1:* `KEGG_2019_Human`
#DGE_ALL7.1:* `KEGG_2019_Mouse`
#DGE_ALL7.1:* `WikiPathways_2019_Human`
#DGE_ALL7.1:* `WikiPathways_2019_Mouse`
#DGE_ALL7.1:
#DGE_ALL7.1:You visualize your results using a simple barplot, for example:

#DGE_TITLE3.2:Gene Set Enrichment Analysis (GSEA)

#DGE_ALL7.2:Besides the enrichment using hypergeometric test, we can also perform gene set enrichment analysis (GSEA), which scores ranked genes list (usually based on fold changes) and computes permutation test to check if a particular gene set is more present in the Up-regulated genes, amongthe DOWN_regulated genes or not differentially regulated.


#DGE_ALL7.3: Once our list of genes are sorted, we can proceed with the enrichment itself. We can use the package to get gene set from the Molecular Signature Database (MSigDB) and select KEGG pathways as an example.

#DGE_ALL7.4: Next, we will be using the GSEA. This will result in a table containing information for several pathways. We can then sort and filter those pathways to visualize only the top ones. You can select/filter them by either `p-value` or normalized enrichemnet score (`NES`).


#DGE_ALL8:<style>
#DGE_ALL8:div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
#DGE_ALL8:</style>
#DGE_ALL8:<div class = "blue">
#DGE_ALL8:**Your turn**
#DGE_ALL8:
#DGE_ALL8:Which KEGG pathways are upregulated in this cluster?
#DGE_ALL8:Which KEGG pathways are dowregulated in this cluster?
#DGE_ALL8:Change the pathway source to another gene set (e.g. "CP:WIKIPATHWAYS" or "CP:REACTOME" or "CP:BIOCARTA" or "GO:BP") and check the if you get simmilar results?
#DGE_ALL8:</div>



#DGE_ALL10:Finally, lets save the integrated data for further analysis.





```{r setup, include=FALSE}
for( pipeline in c("seurat","scater")){
  lab <- readLines(paste0(script_path,"/",pipeline,"/",pipeline,"_05_dge.Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_05_dge.Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,"_05_dge.Rmd"))
}
```

#-----------



#-------------------------------------#
#   Celltype			      #
#-------------------------------------#
#CT_TITLE:## Celltype prediction
#CT_TITLE:***

#CT_ALL1: Celltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses know marker genes for each celltype.
#CT_ALL1:
#CT_ALL1:We will select one sample from the Covid data, `ctrl_13` and predict celltype by cell on that sample.
#CT_ALL1:
#CT_ALL1:Some methods will predict a celltype to each cell based on what it is most similar to even if the celltype of that cell is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.

#CT_SEURAT1:Here we will use a reference PBMC dataset from the `scPred` package which is already a Seurat object with counts. And test classification based on label transfer using the function `TransferData` in the Seurat package, the `scPred` method and `singleR` method.


#CT_ALL2:## Load data
#CT_ALL2:First, lets load required libraries and the saved object from the clustering step. Subset for one patient.

#CT_ALL3:Then, load the reference dataset with annotated labels. Also, run all steps of the normal analysis pipeline with normalizaiton, variable gene selection, scaling and dimensionality reduction.

#CT_SEURAT3:Here, we will run all the steps that we did in previous labs in one go using the `magittr` package with the pipe-operator `%>%`.

#CT_ALL4:Run all steps of the analysis for the ctrl sample as well. Use the clustering from the integration lab with resolution 0.3.

#CT_SEURAT4:## Seurat label transfer
#CT_SEURAT4:First we will run label transfer using a similar method as in the integration exercise. But, instad of CCA the default for the 'FindTransferAnchors` function is to use "pcaproject", e.g. the query datset is projected onto the PCA of the reference dataset. Then, the labels of the reference data are predicted.

#CT_SEURAT4.2:Now plot how many cells of each celltypes can be found in each cluster.

#CT_SEURAT5:## scPred
#CT_SEURAT5:scPred will train a classifier based on all principal components. First, `getFeatureSpace` will create a scPred object stored in the `@misc` slot where it extracts the PCs that best separates the different celltypes. Then `trainModel` will do the actual training for each celltype.

#CT_SEURAT5.2:We can then print how well the training worked for the different celltypes by printing the number of PCs used for each, the ROC value and Sensitivity/Specificity. Which celltypes do you think are harder to classify based on this dataset?

#CT_SEURAT5.3:You can optimize parameters for each dataset by chaning parameters and testing different types of models, see more at: https://powellgenomicslab.github.io/scPred/articles/introduction.html. But for now, we will continue with this model.
#CT_SEURAT5.3:
#CT_SEURAT5.3: Now, lets predict celltypes on our data, where scPred will align the two datasets with Harmony and then perform classification.

#CT_SEURAT5.4:Now plot how many	cells of each celltypes	can be found in	each cluster.

#CT_ALL6:## Compare results
#CT_SEURAT6:Now we will compare the output of the two methods using the convenient function in scPred `crossTab` that prints the overlap between two metadata slots.

#CT_ALL7:Do you think that the methods overlap well? Where do you see the most inconsistencies?
#CT_ALL7:
#CT_ALL7:In this case we do not have any ground truth, and we cannot say wich method performs best. You should keep in mind, that any celltype classification method is just a prediction, and you still need to use your common sense and knowledge of the biological system to judge if the results make sense.
#CT_ALL7:
#CT_ALL7:Finally, lets save the data with predictions.


#-----------

#-------------------------------------#
#  Spatial transcriptomicst           #
#-------------------------------------#

#ST_TITLE:# Spatial transcriptomics
#ST_TITLE:***

#ST_ALL1:Spatial transcriptomic data with the Visium platform is in many ways similar to scRNAseq data. It contains UMI counts for 5-20 cells instead of single cells, but is still quite sparse in the same way as scRNAseq data is, but with the additional information about spatial location in the tissue. 
#ST_ALL1:
#ST_ALL1:Here we will first run quality control in a similar manner to scRNAseq data, then QC filtering, dimensionality reduction, integration and clustering. Then we will use scRNAseq data from mouse cortex to run LabelTransfer to predict celltypes in the Visium spots. 

#ST_ALL1:
#ST_ALL1:We will use two **Visium** spatial transcriptomics dataset of the mouse brain (Sagittal), which are publicly available from the [10x genomics website](https://support.10xgenomics.com/spatial-gene-expression/datasets/). Note, that these dataset have already been filtered for spots that does not overlap with the tissue.


#ST_TITLE1:### Load packages

#ST_TITLE2:### Load ST data

#ST_TITLE3:##Quality control
#ST_TITLE3:***

#ST_ALL3:Similar to scRNAseq we use statistics on number of counts, number of features and percent mitochondria for quality control. 
#ST_ALL3.1:We can also plot the same data onto the tissue section.

#ST_ALL3.2:As you can see, the spots with low number of counts/features and high mitochondrial content is mainly towards the edges of the tissue. It is quite likely that these regions are damaged tissue. You may also see regions within a tissue with low quality if you have tears or folds in your section. 
#ST_ALL3.2:
#ST_ALL3.2:But remember, for some tissue types, the amount of genes expressed and proportion mitochondria may also be a biological features, so bear in mind what tissue you are working on and what these features mean.

#ST_TITLE4:### Filter
#ST_ALL4:Select all spots with less than 25% mitocondrial reads, less than 20% hb-reads and 1000 detected genes. You must judge for yourself based on your knowledge of the tissue what are appropriate filtering criteria for your dataset.

#ST_TITLE5:### Top expressed genes
#ST_TITLE5:As for scRNAseq data, we will look at what the top expressed genes are.

#ST_ALL5:As you can see, the mitochondrial genes are among the top expressed. Also the lncRNA gene Bc1 (brain cytoplasmic RNA 1). Also one hemoglobin gene.

#ST_TITLE6:### Filter genes
#ST_TITLE6:We will remove the Bc1 gene, hemoglobin genes (blood contamination) and the mitochondrial genes.

#ST_TITLE7:## Analysis
#ST_TITLE7:***
#ST_TITLE77:We will proceed with the data in a very similar manner to scRNAseq data.

#ST_ALL7:Now we can plot gene expression of individual genes, the gene Hpca is a strong hippocampal marker and Ttr is a marker of the choroid plexus.

#ST_ALL7.1:### Dimensionality reduction and clustering
#ST_ALL7.1:We can then now run dimensionality reduction and clustering using the same workflow as we use for scRNA-seq analysis. 

#ST_ALL7.2:We can then plot clusters onto umap or onto the tissue section.

#ST_TITLE8:## Integration

#ST_ALL8:Quite often there are strong batch effects between different ST sections, so it may be a good idea to integrate the data across sections.
#ST_ALL8.1:Then we run dimensionality reduction and clustering as before.

#ST_ALL8.2:Do you see any differences between the integrated and non-integrated clusering? Judge for yourself, which of the clusterings do you think looks best? 
#ST_ALL8.2:As a reference, you can compare to brain regions in the [Allen brain atlas](https://mouse.brain-map.org/experiment/thumbnails/100042147?image_type=atlas). 


#ST_TITLE9:## Identification of Spatially Variable Features
#ST_ALL9: There are two main workflows to identify molecular features that correlate with spatial location within a tissue. The first is to perform differential expression based on spatially distinct clusters, the other is to find features that are have spatial patterning without taking clusters or spatial annotation into account. 
#ST_ALL9:
#ST_ALL9:First, we will do differential expression between clusters just as we did for the scRNAseq data before.


#ST_ALL9.1:
Spatial transcriptomics allows researchers to investigate how gene expression trends varies in space, thus identifying spatial patterns of gene expression. For this purpose there are multiple methods, such as SpatailDE, SPARK, Trendsceek, HMRF and Splotch.


#ST_TITLE10:## Single cell data

#ST_ALL10:We can also perform data integration between one scRNA-seq dataset and one spatial transcriptomics dataset. Such task is particularly useful because it allows us to transfer cell type labels to the Visium dataset, which were dentified from the scRNA-seq dataset. 
#ST_ALL10:
#ST_ALL10:We will use a reference scRNA-seq dataset of ~14,000 adult mouse cortical cell taxonomy from the Allen Institute, generated with the SMART-Seq2 protocol.

#ST_ALL10.1:For speed, and for a more fair comparison of the celltypes, we will subsample all celltypes to a maximum of 200 cells per class (`subclass`).


#ST_ALL10.1b:### Subset ST for cortex
#ST_ALL10.1b:Since the scRNAseq dataset was generated from the mouse cortex, we will subset the visium dataset in order to select mainly the spots part of the cortex. Note that the integration can also be performed on the whole brain slice, but it would give rise to false positive cell type assignments and and therefore it should be interpreted with more care.



#ST_ALL10.2:### Integrate with scRNAseq

#ST_ALL10.3:We can also visualize the scores per cluster in ST data

#ST_ALL10.4:Keep in mind, that the scores are "just" prediction scores, and do not correspond to proportion of cells that are of a certain celltype or similar. It mainly tells you that gene expression in a certain spot is hihgly similar/dissimilar to gene expression of a celltype.
#ST_ALL10.4:
#ST_ALL10.4:If we look at the scores, we see that some spots got really clear predictions by celltype, while others did not have high scores for any of the celltypes.

#ST_ALL11:<style>
#ST_ALL11:div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
#ST_ALL11:</style>
#ST_ALL11:<div class = "blue">
#ST_ALL11:**Your turn:**
#ST_ALL11:
#ST_ALL11:Subset for another region that does not contain cortex cells and check what you get from the label transfer. 
#ST_ALL11:
#ST_ALL11:Suggested region is the right end of the posterial section that you can select like this:
#ST_ALL11:
#ST_ALL11:</div>



#-------------------------------------#
#   Trajectory inference: Slingshot   #
#-------------------------------------#
```{r setup, include=FALSE}
#These steps must be run with the specific Slingshot environment, not the normal one!!!

for( pipeline in c("slingshot")){
  lab <- readLines(paste0(script_path,"/trajectory/",pipeline,".Rmd"))
  lab_text <- readLines(paste0(script_path,"/knit_labs.Rmd"))

  u <- grep("[#].*[_].*[:]",lab,value = T)[ grep("[#].*[_].*[:]",lab,value = T) %in% sub(":.*",":",grep("[#].*[_].*[:]",lab_text,value = T)) ]

  t_lab <- lab
  for( i in u ){
    j <- grep(i,t_lab)
    temp2 <- sub(i,"",lab_text[grepl(i,lab_text)])
    t_lab <- c( t_lab[1:(j-1)] , temp2 , t_lab[(j+1):length(t_lab)] )
  }

  PATH <- paste0(script_path,"/compiled/",pipeline)
  if(!dir.exists(PATH)){dir.create(PATH, recursive = T)}
  writeLines(t_lab,paste0(script_path,"/compiled/",pipeline,"/",pipeline,".Rmd"))
  rmarkdown::render(paste0(script_path,"/compiled/",pipeline,"/",pipeline,".Rmd"))
}
```

#-----------
