{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "description: Grouping individual cells with similar gene expression\n",
        "  profiles to uncover distinct cell populations and their functional\n",
        "  characteristics.\n",
        "subtitle:  Scanpy Toolkit\n",
        "title:  Clustering\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> Code chunks run Python commands unless it starts with `%%bash`, in\n",
        "> which case, those chunks run shell commands.\n",
        "\n",
        "</div>\n",
        "\n",
        "In this tutorial we will continue the analysis of the integrated\n",
        "dataset. We will use the scanpy enbedding to perform the clustering\n",
        "using graph community detection algorithms.\n",
        "\n",
        "Let's first load all necessary libraries and also the integrated dataset\n",
        "from the previous step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=Warning)\n",
        "\n",
        "# verbosity: errors (0), warnings (1), info (2), hints (3)\n",
        "sc.settings.verbosity = 3\n",
        "sc.settings.set_figure_params(dpi=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# download pre-computed data if missing or long compute\n",
        "fetch_data = True\n",
        "\n",
        "# url for source and intermediate data\n",
        "path_data = \"https://export.uppmax.uu.se/naiss2023-23-3/workshops/workshop-scrnaseq\"\n",
        "\n",
        "path_results = \"data/covid/results\"\n",
        "if not os.path.exists(path_results):\n",
        "    os.makedirs(path_results, exist_ok=True)\n",
        "\n",
        "path_file = \"data/covid/results/scanpy_covid_qc_dr_int.h5ad\"\n",
        "if fetch_data and not os.path.exists(path_file):\n",
        "    urllib.request.urlretrieve(os.path.join(\n",
        "        path_data, 'covid/results/scanpy_covid_qc_dr_int.h5ad'), path_file)\n",
        "\n",
        "adata = sc.read_h5ad(path_file)\n",
        "adata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph clustering\n",
        "\n",
        "The procedure of clustering on a Graph can be generalized as 3 main\n",
        "steps:\\\n",
        "- Build a kNN graph from the data.\\\n",
        "- Prune spurious connections from kNN graph (optional step). This is a\n",
        "SNN graph.\\\n",
        "- Find groups of cells that maximizes the connections within the group\n",
        "compared other groups.\n",
        "\n",
        "In Scanpy we do not build an SNN graph, instead the community detection\n",
        "is done on the KNN graph which we construct using the command\n",
        "`sc.pp.neighbors()`.\n",
        "\n",
        "The main options to consider are:\n",
        "\n",
        "-   **n_pcs** - the number of dimensions from the initial reduction to\n",
        "    include when calculating distances between cells.\n",
        "-   **n_neighbors** - the number of neighbors per cell to include in the\n",
        "    KNN graph.\n",
        "\n",
        "In this case, we will use the integrated data using Harmony. If you\n",
        "recall, we stored the harmony reduction in `X_pca_harmony` in the\n",
        "previous lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.pp.neighbors(adata, n_neighbors=20, n_pcs=30, use_rep='X_pca_harmony')\n",
        "\n",
        "# We will also set the default umap to the one created with harmony\n",
        "# so that sc.pl.umap selects that embedding.\n",
        "adata.obsm[\"X_umap\"] = adata.obsm[\"X_umap_harmony\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The modularity optimization algoritm in Scanpy is *Leiden*. Previously\n",
        "ther was also *Louvain*, but since the Louvain algorithm is no longer\n",
        "maintained, using Leiden is recommended by the Scanpy community.\n",
        "\n",
        "### Leiden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# default resolution is 1.0, but we will try a few different values.\n",
        "sc.tl.leiden(adata, resolution = 0.4, key_added = \"leiden_0.4\")\n",
        "sc.tl.leiden(adata, resolution = 0.6, key_added = \"leiden_0.6\")\n",
        "sc.tl.leiden(adata, resolution = 1.0, key_added = \"leiden_1.0\")\n",
        "sc.tl.leiden(adata, resolution = 1.4, key_added = \"leiden_1.4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the clusters, as you can see, with increased resolution, we get\n",
        "higher granularity in the clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.pl.umap(adata, color=['leiden_0.4', 'leiden_0.6', 'leiden_1.0','leiden_1.4'], legend_fontsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have done clustering, the relationships between clusters can be\n",
        "calculated as correlation in PCA space and we also visualize some of the\n",
        "marker genes that we used in the Dim Reduction lab onto the clusters. If\n",
        "we set `dendrogram=True` the clusters are ordered by the dendrogram in\n",
        "the dotplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.tl.dendrogram(adata, groupby = \"leiden_0.6\")\n",
        "sc.pl.dendrogram(adata, groupby = \"leiden_0.6\")\n",
        "\n",
        "genes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"FCGR3A\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR1A\"]\n",
        "sc.pl.dotplot(adata, genes, groupby='leiden_0.6', dendrogram=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-means clustering\n",
        "\n",
        "K-means is a generic clustering algorithm that has been used in many\n",
        "application areas. In R, it can be applied via the `kmeans()` function.\n",
        "Typically, it is applied to a reduced dimension representation of the\n",
        "expression data (most often PCA, because of the interpretability of the\n",
        "low-dimensional distances). We need to define the number of clusters in\n",
        "advance. Since the results depend on the initialization of the cluster\n",
        "centers, it is typically recommended to run K-means with multiple\n",
        "starting configurations (via the `nstart` argument)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "# extract pca coordinates\n",
        "X_pca = adata.obsm['X_pca_harmony'] \n",
        "\n",
        "# kmeans with k=5\n",
        "kmeans = KMeans(n_clusters=5, random_state=0).fit(X_pca) \n",
        "adata.obs['kmeans5'] = kmeans.labels_.astype(str)\n",
        "\n",
        "# kmeans with k=10\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(X_pca) \n",
        "adata.obs['kmeans10'] = kmeans.labels_.astype(str)\n",
        "\n",
        "# kmeans with k=15\n",
        "kmeans = KMeans(n_clusters=15, random_state=0).fit(X_pca)\n",
        "adata.obs['kmeans15'] = kmeans.labels_.astype(str)\n",
        "\n",
        "sc.pl.umap(adata, color=['kmeans5', 'kmeans10', 'kmeans15'])\n",
        "\n",
        "adata.obsm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hierarchical clustering\n",
        "\n",
        "Hierarchical clustering is another generic form of clustering that can\n",
        "be applied also to scRNA-seq data. As K-means, it is typically applied\n",
        "to a reduced dimension representation of the data. Hierarchical\n",
        "clustering returns an entire hierarchy of partitionings (a dendrogram)\n",
        "that can be cut at different levels. Hierarchical clustering is done in\n",
        "these steps:\n",
        "\n",
        "1.  Define the distances between samples. The most common are Euclidean\n",
        "    distance (a.k.a. straight line between two points) or correlation\n",
        "    coefficients.\n",
        "2.  Define a measure of distances between clusters, called *linkage*\n",
        "    criteria. It can for example be average distances between clusters.\n",
        "    Commonly used methods are `single`, `complete`, `average`, `median`,\n",
        "    `centroid` and `ward`.\n",
        "3.  Define the dendrogram among all samples using **Bottom-up** or\n",
        "    **Top-down** approach. **Bottom-up** is where samples start with\n",
        "    their own cluster which end up merged pair-by-pair until only one\n",
        "    cluster is left. **Top-down** is where samples start all in the same\n",
        "    cluster that end up being split by 2 until each sample has its own\n",
        "    cluster.\n",
        "\n",
        "As you might have realized, correlation is not a method implemented in\n",
        "the `dist()` function. However, we can create our own distances and\n",
        "transform them to a distance object. We can first compute sample\n",
        "correlations using the `cor` function.\\\n",
        "As you already know, correlation range from -1 to 1, where 1 indicates\n",
        "that two samples are closest, -1 indicates that two samples are the\n",
        "furthest and 0 is somewhat in between. This, however, creates a problem\n",
        "in defining distances because a distance of 0 indicates that two samples\n",
        "are closest, 1 indicates that two samples are the furthest and distance\n",
        "of -1 is not meaningful. We thus need to transform the correlations to a\n",
        "positive scale (a.k.a. **adjacency**):\\\n",
        "$$adj = \\frac{1- cor}{2}$$\\\n",
        "Once we transformed the correlations to a 0-1 scale, we can simply\n",
        "convert it to a distance object using `as.dist()` function. The\n",
        "transformation does not need to have a maximum of 1, but it is more\n",
        "intuitive to have it at 1, rather than at any other number.\n",
        "\n",
        "The function `AgglomerativeClustering` has the option of running with\n",
        "disntance metrics \"euclidean\", \"l1\", \"l2\", \"manhattan\", \"cosine\", or\n",
        "\"precomputed\". However, with ward linkage only euklidean distances\n",
        "works. Here we will try out euclidean distance and ward linkage\n",
        "calculated in PCA space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
        "adata.obs['hclust_5'] = cluster.fit_predict(X_pca).astype(str)\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=10, linkage='ward')\n",
        "adata.obs['hclust_10'] = cluster.fit_predict(X_pca).astype(str)\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=15, linkage='ward')\n",
        "adata.obs['hclust_15'] = cluster.fit_predict(X_pca).astype(str)\n",
        "\n",
        "sc.pl.umap(adata, color=['hclust_5', 'hclust_10', 'hclust_15'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, lets save the clustered data for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "adata.write_h5ad('./data/covid/results/scanpy_covid_qc_dr_int_cl.h5ad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution of clusters\n",
        "\n",
        "Now, we can select one of our clustering methods and compare the\n",
        "proportion of samples across the clusters.\n",
        "\n",
        "Select the \"leiden_0.6\" and plot proportion of samples per cluster and\n",
        "also proportion covid vs ctrl.\n",
        "\n",
        "Plot proportion of cells from each condition per cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['type'], normalize='index')\n",
        "tmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1), loc='upper right')\n",
        "\n",
        "tmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['sample'], normalize='index')\n",
        "tmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1),loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case we have quite good representation of each sample in each\n",
        "cluster. But there are clearly some biases with more cells from one\n",
        "sample in some clusters and also more covid cells in some of the\n",
        "clusters.\n",
        "\n",
        "We can also plot it in the other direction, the proportion of each\n",
        "cluster per sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tmp = pd.crosstab(adata.obs['sample'],adata.obs['leiden_0.6'], normalize='index')\n",
        "tmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1), loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "\n",
        "> **Discuss**\n",
        ">\n",
        "> By now you should know how to plot different features onto your data.\n",
        "> Take the QC metrics that were calculated in the first exercise, that\n",
        "> should be stored in your data object, and plot it as violin plots per\n",
        "> cluster using the clustering method of your choice. For example, plot\n",
        "> number of UMIS, detected genes, percent mitochondrial reads. Then,\n",
        "> check carefully if there is any bias in how your data is separated by\n",
        "> quality metrics. Could it be explained biologically, or could there be\n",
        "> a technical bias there?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, groupby = 'leiden_0.6', rotation= 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some clusters that are clearly defined by higher number of genes and\n",
        "counts. These are either doublets or a larger celltype. And some\n",
        "clusters with low values on these metrics that are either low quality\n",
        "cells or a smaller celltype. You will have to explore these clusters in\n",
        "more detail to judge what you believe them to be.\n",
        "\n",
        "## Subclustering of T and NK-cells\n",
        "\n",
        "It is common that the subtypes of cells within a cluster is not so well\n",
        "separated when you have a heterogeneous dataset. In such a case it could\n",
        "be a good idea to run subclustering of individual celltypes. The main\n",
        "reason for subclustering is that the variable genes and the first\n",
        "principal components in the full analysis are mainly driven by\n",
        "differences between celltypes, while with subclustering we may detect\n",
        "smaller differences between subtypes within celltypes.\n",
        "\n",
        "So first, lets find out where our T-cell and NK-cell clusters are. We\n",
        "know that T-cells express CD3E, and the main subtypes are CD4 and CD8,\n",
        "while NK-cells express GNLY."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# check with the lowest resolution\n",
        "fig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\n",
        "sc.pl.umap(adata, color=\"leiden_0.4\", ax=axs[0,0], show=False, legend_loc = \"on data\")\n",
        "sc.pl.umap(adata, color=\"CD3E\", ax=axs[0,1], show=False)\n",
        "sc.pl.umap(adata, color=\"CD4\", ax=axs[0,2], show=False)\n",
        "sc.pl.umap(adata, color=\"CD8A\", ax=axs[1,0], show=False)\n",
        "sc.pl.umap(adata, color=\"GNLY\", ax=axs[1,1], show=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can clearly see what clusters are T-cell clusters, so lets subset the\n",
        "data for those cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tcells = adata[adata.obs[\"leiden_0.4\"].isin(['1','2','4']),:]\n",
        "tcells.obs[\"sample\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ideally we should rerun all steps of integration with that subset of\n",
        "cells instead of just taking the joint embedding. If you have too few\n",
        "cells per sample in the celltype that you want to cluster it may not be\n",
        "possible. We will start with selecting a new set of genes that better\n",
        "reflecs the variability within this celltype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.pp.highly_variable_genes(tcells, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
        "\n",
        "\n",
        "print(\"Full data:\" , sum(adata.var.highly_variable ))\n",
        "print(\"Tcells:\" , sum(tcells.var.highly_variable))\n",
        "print(\"Intersection:\" , sum(tcells.var.highly_variable & adata.var.highly_variable))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We clearly have a very different geneset now, so hopefully it should\n",
        "better capture the variability within T-cells.\n",
        "\n",
        "Now we have to run the full pipeline with scaling, pca, integration and\n",
        "clustering on this subset of cells, using the new set of variable genes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import scanpy.external as sce \n",
        "import harmonypy as hm \n",
        "\n",
        "tcells.raw = tcells\n",
        "tcells = tcells[:, tcells.var.highly_variable]\n",
        "sc.pp.regress_out(tcells, ['total_counts', 'pct_counts_mt'])\n",
        "sc.pp.scale(tcells, max_value=10)\n",
        "sc.tl.pca(tcells, svd_solver='arpack')\n",
        "sce.pp.harmony_integrate(tcells, 'sample')\n",
        "sc.pp.neighbors(tcells, n_neighbors=10, n_pcs=30, use_rep='X_pca_harmony')\n",
        "sc.tl.leiden(tcells, resolution = 0.6, key_added = \"tcells_0.6\")\n",
        "sc.tl.umap(tcells)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\n",
        "sc.pl.umap(tcells, color=\"sample\", title=\"Tcell umap\", ax=axs[0,0], show=False)\n",
        "sc.pl.embedding(tcells, 'X_umap_harmony', color=\"sample\", title=\"Full umap\", ax=axs[1,0], show=False)\n",
        "sc.pl.umap(tcells, color=\"leiden_0.6\", title=\"Tcell umap, full clust\", ax=axs[0,1], show=False)\n",
        "sc.pl.embedding(tcells, 'X_umap_harmony', color=\"leiden_0.6\", title=\"Full umap, full clust\", ax=axs[1,1], show=False)\n",
        "sc.pl.umap(tcells, color=\"tcells_0.6\", title=\"Tcell umap, tcell clust\", ax=axs[0,2], show=False)\n",
        "sc.pl.embedding(tcells, 'X_umap_harmony', color=\"tcells_0.6\", title=\"Full umap, tcell clust\", ax=axs[1,2], show=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, we do have some new clusters that did not stand out\n",
        "before. But in general the separation looks very similar.\n",
        "\n",
        "We can plot the subtype genes again. If you try plotting the genes with\n",
        "`use_raw=False` you will notice that some of the genes are not in the\n",
        "`adata.X` matrix. Since they are no longer included in the variable\n",
        "genes. So now we have to plot with `use_raw=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\n",
        "sc.pl.umap(tcells, color=\"CD3E\", ax=axs[0,0], show=False, use_raw=True)\n",
        "sc.pl.umap(tcells, color=\"CD4\", ax=axs[0,1], show=False, use_raw=True)\n",
        "sc.pl.umap(tcells, color=\"CD8A\", ax=axs[1,0], show=False, use_raw=True)\n",
        "sc.pl.umap(tcells, color=\"GNLY\", ax=axs[1,1], show=False, use_raw=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Session info\n",
        "\n",
        "```{=html}\n",
        "<details>\n",
        "```\n",
        "```{=html}\n",
        "<summary>\n",
        "```\n",
        "Click here\n",
        "```{=html}\n",
        "</summary>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sc.logging.print_versions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{=html}\n",
        "</details>\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}