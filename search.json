[
  {
    "objectID": "lectures/gsa/index.html#what-is-gene-set-analysis",
    "href": "lectures/gsa/index.html#what-is-gene-set-analysis",
    "title": "Gene set analysis",
    "section": "What is gene set analysis?",
    "text": "What is gene set analysis?\n\n\nGene-level data -&gt; Gene set data\n\n\nWe focus on transcriptomics and DGE, but in principle applies to any genome-wide data\n\nMany different kinds of genome wide analyses such differential gene expression, differential binding (chip-seq), differential methylation etc. could all end up here at functional analysis."
  },
  {
    "objectID": "lectures/gsa/index.html#why-gene-set-analysis",
    "href": "lectures/gsa/index.html#why-gene-set-analysis",
    "title": "Gene set analysis",
    "section": "Why gene set analysis?",
    "text": "Why gene set analysis?\n  \nPredict the functional changes of cells based on differential gene expression analysis\n\nMake sense of a long list of DEGs\n\nWhat is the function of those genes?\nWhat is the biological consequence of over/under expression of genes?\n\nConnect your DEGs and thereby your experiment to pathway activity\nSmall differences in many genes may have a bigger impact than large differences in one genes\nLess sensitive to false positive DEGs"
  },
  {
    "objectID": "lectures/gsa/index.html#requirements",
    "href": "lectures/gsa/index.html#requirements",
    "title": "Gene set analysis",
    "section": "Requirements",
    "text": "Requirements\n  \n\nDE results\n+\nGene set(s) (list(s) of genes)\n+\nStatistical test"
  },
  {
    "objectID": "lectures/gsa/index.html#where-to-get-gene-sets",
    "href": "lectures/gsa/index.html#where-to-get-gene-sets",
    "title": "Gene set analysis",
    "section": "Where to get gene sets?",
    "text": "Where to get gene sets?\n\nDatabases\n\nGene Ontology\nKEGG\nReactome\nMSigDB\n…\n\nPrevious studies\n\nMarkers of a population of interest\nTargets of a transcription factor of interest\nDE genes from another analysis"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-ontology",
    "href": "lectures/gsa/index.html#gene-ontology",
    "title": "Gene set analysis",
    "section": "Gene ontology",
    "text": "Gene ontology\n\n\n\n\n\n\nNetwork graph, loosely hierarchical\nThree ontologies\n\nBiological process (e.g. Neutrophil Chemotaxis, Cell proliferation)\nMolecular Function (e.g. Histone acetylation, Phosphorylation)\nCellular compartment (e.g. Nucleus, Cytoplasm, Plasma membrane)\n\nGenes can belong to multiple terms"
  },
  {
    "objectID": "lectures/gsa/index.html#kegg",
    "href": "lectures/gsa/index.html#kegg",
    "title": "Gene set analysis",
    "section": "Kegg",
    "text": "Kegg\n\n\n\n\nFewer and smaller ontology\nHighly curated\n\n\nPathview"
  },
  {
    "objectID": "lectures/gsa/index.html#overrepresentation-analysis-ora",
    "href": "lectures/gsa/index.html#overrepresentation-analysis-ora",
    "title": "Gene set analysis",
    "section": "Overrepresentation analysis (ORA)",
    "text": "Overrepresentation analysis (ORA)\n\n\nHypergeometric test (Fisher’s exact test)"
  },
  {
    "objectID": "lectures/gsa/index.html#overrepresentation-analysis-ora-1",
    "href": "lectures/gsa/index.html#overrepresentation-analysis-ora-1",
    "title": "Gene set analysis",
    "section": "Overrepresentation analysis (ORA)",
    "text": "Overrepresentation analysis (ORA)\n\nBackground can be all genes or all genes expressed in your cell population\nRequires arbitrary cut-off\nOmits actual gene-level statistics\nComputationally fast\nGenerally works for few genes with strong effects"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea",
    "href": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea",
    "title": "Gene set analysis",
    "section": "Gene set enrichment analysis (GSEA)",
    "text": "Gene set enrichment analysis (GSEA)\n\nSubramanian et al. (2005)"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea-1",
    "href": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea-1",
    "title": "Gene set analysis",
    "section": "Gene set enrichment analysis (GSEA)",
    "text": "Gene set enrichment analysis (GSEA)\n\n\n\n\n\nEnrichment score (ES)\nNormalized enrichment score (NES)\nNo need for cut-offs\nTakes gene-level stats into account\nMore sensitive to subtle changes\n\nGSEA User Guide"
  },
  {
    "objectID": "lectures/gsa/index.html#tools",
    "href": "lectures/gsa/index.html#tools",
    "title": "Gene set analysis",
    "section": "Tools",
    "text": "Tools\nOnline\n\nEnrichr\nGorilla\nWebgestalt\n\nCode\n\nfgsea (R)\nclusterProfiler (R)\nmsigdbr (R)\ngseapy (Python)"
  },
  {
    "objectID": "lectures/gsa/index.html#considerations",
    "href": "lectures/gsa/index.html#considerations",
    "title": "Gene set analysis",
    "section": "Considerations",
    "text": "Considerations\n\nBias in curation - highly researched topics will be over-represented\nGene set names can be misleading\nSpecific vs general gene sets\nMultifunctional genes\nTranslation of gene ids\nDatabases change\nCuration is organism-specific\nCritical evaluation is required"
  },
  {
    "objectID": "lectures/gsa/index.html#references",
    "href": "lectures/gsa/index.html#references",
    "title": "Gene set analysis",
    "section": "References",
    "text": "References\n\n\nSubramanian, A., Tamayo, P., Mootha, V. K., Mukherjee, S., Ebert, B. L., Gillette, M. A., Paulovich, A., Pomeroy, S. L., Golub, T. R., Lander, E. S., et al. (2005). Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences, 102(43), 15545–15550. https://www.pnas.org/doi/abs/10.1073/pnas.0506580102"
  },
  {
    "objectID": "lectures/gsa/index.html#acknowledgements",
    "href": "lectures/gsa/index.html#acknowledgements",
    "title": "Gene set analysis",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nAdapted from previous presentations by Leif Wigge, Paulo Czarnewski and Roy Francis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Overview of scRNAseq technologies\nQC, normalization and transformation\nDimensionality reduction and clustering\nDifferential gene expression\nCelltype prediction\nTrajectory analysis\nSeurat, Bioconductor and Scanpy toolkits\n\n\n\nUpdated: 05-11-2025 at 21:30:03."
  },
  {
    "objectID": "index.html#single-cell-rna-seq-analysis",
    "href": "index.html#single-cell-rna-seq-analysis",
    "title": "",
    "section": "",
    "text": "Overview of scRNAseq technologies\nQC, normalization and transformation\nDimensionality reduction and clustering\nDifferential gene expression\nCelltype prediction\nTrajectory analysis\nSeurat, Bioconductor and Scanpy toolkits\n\n\n\nUpdated: 05-11-2025 at 21:30:03."
  },
  {
    "objectID": "home_contents.html",
    "href": "home_contents.html",
    "title": "Contents",
    "section": "",
    "text": "You can run the labs either using SciLifeLab Serve applications (recommended during course) or using Docker locally on your system. Instructions on running the labs are provided here\nA short description of the data used in the tutorials is provided here."
  },
  {
    "objectID": "home_contents.html#toolkit-comparisons",
    "href": "home_contents.html#toolkit-comparisons",
    "title": "Contents",
    "section": "Toolkit comparisons",
    "text": "Toolkit comparisons\nBelow are a few reports where the results from the 3 toolkits and multiple methods in the toolkits are analysed. OBS! Several of these scripts requires additional packages that are not available in the Docker containers used for the exercises.\n\nGeneral comparison of the main steps of the pipelines:  \nComparison of Variable gene selection methods:  \nDifferential gene expression detection:  \nNormalization methods:"
  },
  {
    "objectID": "home_contents.html#previous-course-iterations",
    "href": "home_contents.html#previous-course-iterations",
    "title": "Contents",
    "section": "Previous course iterations",
    "text": "Previous course iterations\n\nscRNAseq 2024 \nscRNAseq 2023 \nRecorded videos of lectures (from 2022) are available on Youtube \n\nNB: Seurat exercises in previous courses used Seurat v4"
  },
  {
    "objectID": "home_contents.html#useful-resources",
    "href": "home_contents.html#useful-resources",
    "title": "Contents",
    "section": "Useful resources",
    "text": "Useful resources\n\nThe github repository for this course \nSingle Cell Glossary \nSingle cell RNA-seq course at from Hemberg lab \nSingle cell RNA-seq course in Python \nSingle cell RNA-seq course at Broad \nRepository listing many scRNA-seq tools \nSingleCellExperiment objects for many datasets \nConquer datasets - many different datasets based on a salmon pipeline \nThe Human Cell Atlas project"
  },
  {
    "objectID": "home_info.html",
    "href": "home_info.html",
    "title": "Practical Info",
    "section": "",
    "text": "Online\n\n\nOnline meeting links are sent to participants by email."
  },
  {
    "objectID": "home_info.html#location",
    "href": "home_info.html#location",
    "title": "Practical Info",
    "section": "",
    "text": "Online\n\n\nOnline meeting links are sent to participants by email."
  },
  {
    "objectID": "home_info.html#contact",
    "href": "home_info.html#contact",
    "title": "Practical Info",
    "section": "Contact",
    "text": "Contact\nThis workshop is run by the National Bioinformatics Infrastructure Sweden (NBIS). NBIS is a platform at SciLifeLab (Science For Life Laboratory) and the Swedish node of Elixir.\nIf you would like to get in touch with us regarding this workshop, please contact us at edu.sc [at] nbis.se."
  },
  {
    "objectID": "home_precourse.html",
    "href": "home_precourse.html",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Quarto/Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_precourse.html#fa-book-coding",
    "href": "home_precourse.html#fa-book-coding",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Quarto/Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_precourse.html#fa-brands-slack-slack",
    "href": "home_precourse.html#fa-brands-slack-slack",
    "title": "Precourse",
    "section": " Slack",
    "text": "Slack\nWe will use Slack for communication, troubleshooting and group discussions. Please install Slack. All accepted students will receive an invitation link via email to join the course workspace. Please add this workspace to your Slack application on your desktop rather than using it in the browser.\nOnce you are in the workspace, please join the following channels:\n\n#general for general questions about the workshop\n#precourse for questions related to precourse preparation\n\n\n\n\n\n\n\nNote\n\n\n\nPlease post your question in the channel and NOT directly to the teacher. Any participant that knows the answer to any problem is encouraged to help too."
  },
  {
    "objectID": "home_precourse.html#fa-server-scilifelab-serve",
    "href": "home_precourse.html#fa-server-scilifelab-serve",
    "title": "Precourse",
    "section": " Scilifelab Serve",
    "text": "Scilifelab Serve\nWe will use the Scilifelab Serve compute resources for the workshop. You will need to create an account if you don’t already have one. See instructions here."
  },
  {
    "objectID": "home_precourse.html#fa-brands-docker-docker",
    "href": "home_precourse.html#fa-brands-docker-docker",
    "title": "Precourse",
    "section": " Docker",
    "text": "Docker\nIn addition to ScilifeLab Serve, the lab environments are available as Docker images. These will be useful as backups in case Serve does not work, and will be necessary for the BYOD session. For this, you will need to install Docker: Instructions are here."
  },
  {
    "objectID": "home_precourse.html#fa-circle-question-faq",
    "href": "home_precourse.html#fa-circle-question-faq",
    "title": "Precourse",
    "section": " FAQ",
    "text": "FAQ\nPlease refer to the FAQ for troubleshooting common issues."
  },
  {
    "objectID": "home_schedule.html",
    "href": "home_schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nInstructor\n\n\n\n\n31-Mar-2025Monzoom\n\n\n09:00 - 09:30\nWelcome and General introduction \nÅB, SR, JF\n\n\n09:30 - 10:30\nLecture: scRNAseq methods and NGI \nHenrik Gezelius\n\n\n10:30 - 11:00\nBreak\n\n\n\n11:00 - 12:00\nLecture: Quality control \nÅsa Björklund\n\n\n12:00 - 13:00\nLunch\n\n\n\n13:00 - 13:30\nIntro to Exercises \nÅsa Björklund\n\n\n13:30 - 15:00\nLab: Quality control \nÅsa Björklund\n\n\n15:00 - 15:30\nBreak\n\n\n\n15:30 - 16:30\nLecture: Data normalization \nÅsa Björklund\n\n\n16:30 - 17:00\nWrap Up\nÅB, SR, JF\n\n\n01-Apr-2025Tuezoom\n\n\n09:00 - 10:00\nLecture: Dimensionality reduction \nNikolay Oskolkov\n\n\n10:00 - 10:30\nBreak\n\n\n\n10:30 - 12:00\nLab: Dimensionality reduction \nJennifer Fransson\n\n\n12:00 - 13:00\nLunch\n\n\n\n13:00 - 14:00\nLecture: Batch correction + Integration \nNikolay Oskolkov\n\n\n14:00 - 15:00\nLab: Data integration \nÅsa Björklund\n\n\n15:00 - 15:30\nBreak\n\n\n\n15:30 - 16:30\nLecture: Clustering \nÅsa Björklund\n\n\n16:30 - 17:00\nWrap Up\nÅB, SR, JF\n\n\n02-Apr-2025Wedzoom\n\n\n09:00 - 10:00\nLab: Clustering \nÅsa Björklund\n\n\n10:00 - 10:30\nBreak\n\n\n\n10:30 - 11:30\nLecture: Differential Gene Expression  \nJennifer Fransson\n\n\n11:30 - 12:00\nLecture: Gene set analysis  \nJennifer Fransson\n\n\n12:00 - 13:00\nLunch\n\n\n\n13:00 - 14:00\nLecture: Single Cell Epigenetics \nJakub Westholm\n\n\n14:00 - 14:30\nLab: Differential expression \nJennifer Fransson\n\n\n14:30 - 15:00\nBreak\n\n\n\n15:00 - 16:30\nLab: Differential expression \nJennifer Fransson\n\n\n16:30 - 17:00\nWrap Up\nÅB, SR, JF\n\n\n03-Apr-2025Thuzoom\n\n\n09:00 - 10:00\nLecture: Celltype prediction \nFariba Roshanzamir\n\n\n10:00 - 10:30\nBreak\n\n\n\n10:30 - 12:00\nLab: Celltype prediction \nFariba Roshanzamir\n\n\n12:00 - 13:00\nLunch\n\n\n\n13:00 - 14:00\nLecture: Trajectory inference \nPaulo Czarnewski\n\n\n14:00 - 15:30\nLab: Trajectory inference \nÅsa Björklund\n\n\n15:30 - 16:00\nBreak\n\n\n\n16:00 - 16:30\nWorkshop summary \nÅB, SR, JF\n\n\n16:30 - 17:00\nInformation about BYOD \nÅB, SR, JF\n\n\n10-Apr-2025Thuzoom\n\n\n09:00 - 09:15\nIntro to BYOD \nÅB, SR, JF\n\n\n09:15 - 09:30\nIntro to Data Management \n\n\n\n09:30 - 12:00\nBYOD\nÅB, SR, JF\n\n\n12:00 - 13:00\nLunch\n\n\n\n13:00 - 14:30\nBYOD\nÅB, SR, JF\n\n\n14:30 - 16:00\nPresentation of projects\nÅB, SR, JF\n\n\n16:00 - 16:30\nBYOD summary\nÅB, SR, JF\n\n\n\n\n\n\n\n   Date    Venue    Slides    Lab    Form    Video"
  },
  {
    "objectID": "home_syllabus.html",
    "href": "home_syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "SyllabusWho can apply?Entry requirements\n\n\nThis workshop will cover the basic steps in single cell RNAseq (scRNAseq) processing and data analysis, with lectures and practical exercises.\nTopics covered will include:\n\nOverview of the current scRNAseq technologies\nRaw reads into expression values\nQuality control of scRNAseq data\nDimensionality reduction and clustering techniques\nData normalization\nDifferential gene expression for scRNAseq data\nCelltype prediction\nTrajectory analysis\nComparison of sc analysis toolkits: Seurat, Bioconductor and Scanpy\n\n\n\n\nThis is a national workshop open for PhD students, postdocs, group leaders and core facility staff within all Swedish universities. We do accept application from other countries, but priority is given to applicants from Swedish universities prior to applicants from industry and academics from other countries.\n\nPlease note that NBIS training events do not provide any formal university credits. The training content is estimated to correspond to a certain number of credits, however the estimated credits are just guidelines. If formal credits are crucial, the student needs to confer with the home department before submitting a workshop application in order to establish whether the workshop is valid for formal credits or not.\n\nWe cannot invoice private individuals, therefore an affiliation is required.\n\n\n\nPractical exercises can be performed using R or Python, so we only accept students with previous experience in one of those programming languages.\n\nBasic knowledge in R/Python and command line (bash).\nBe able to use your own computer with R or Python installed for the practical computational exercises. Instructions on installation will be sent by email to accepted participants.\nProgramming/scripting experience is required (in R or python).\nBasic understanding of NGS technologies and RNA-sequencing data.\nDesirable: Previous experience with RNA-seq analysis and/or participation in NGS/RNA-seq workshop is an advantage.\n\nDue to limited space the workshop can accommodate maximum of 25 participants. If we receive more applications, participants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the workshop as well as gender and geographical balance."
  },
  {
    "objectID": "other/uppmax.html",
    "href": "other/uppmax.html",
    "title": "UPPMAX Account Guide",
    "section": "",
    "text": "Caution\n\n\n\nDo these steps well in advance as it can take up to 2 weeks for UPPMAX accounts to be approved. If this is incomplete, you may not be able to follow the labs during the workshop.\nThese are the basic steps in this process:"
  },
  {
    "objectID": "other/uppmax.html#create-an-account-in-supr.",
    "href": "other/uppmax.html#create-an-account-in-supr.",
    "title": "UPPMAX Account Guide",
    "section": "1 ​Create an account in SUPR.",
    "text": "1 ​Create an account in SUPR.\n​If you already have a SUPR account, please continue to the next step.\n​Go to​ https://supr.naiss.se/​ and click Register New Person at the bottom of the first page. Complete the registration process, preferably using SWAMID, and login. If you for some reason can’t use SWAMID to login, you will have to send physical (not electronic) copy of your ID to a place in Gothenburg for manual approval. Do this as ​soon as possible​, as this process can take ​more than 2 weeks.\n\n\n\nSUPR login screen"
  },
  {
    "objectID": "other/uppmax.html#apply-for-membership",
    "href": "other/uppmax.html#apply-for-membership",
    "title": "UPPMAX Account Guide",
    "section": "2 ​Apply for membership",
    "text": "2 ​Apply for membership\n​Log in using your SUPR account. ​Under the Projects heading, go to Request Membership in Project. ​Search for the following project IDs:\n\n\nnaiss2023-22-1345, naiss2023-23-648\n\n\nRequest membership to both projects. The first project is to run computations and the second project is for storage.\n\n\n\nRequest to join a project in SUPR"
  },
  {
    "objectID": "other/uppmax.html#accept-naiss-user-agreement",
    "href": "other/uppmax.html#accept-naiss-user-agreement",
    "title": "UPPMAX Account Guide",
    "section": "3 ​Accept NAISS User Agreement",
    "text": "3 ​Accept NAISS User Agreement\n​In SUPR, click on the link Personal Information in the left sidebar. You will have to accept the NAISS User Agreement to be able to get an UPPMAX account."
  },
  {
    "objectID": "other/uppmax.html#apply-for-uppmax-account",
    "href": "other/uppmax.html#apply-for-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "4 Apply for UPPMAX account",
    "text": "4 Apply for UPPMAX account\n​In SUPR, click on the link Accounts in the left sidebar and apply for an UPPMAX account under the heading Account Requests."
  },
  {
    "objectID": "other/uppmax.html#uppmax-account-details",
    "href": "other/uppmax.html#uppmax-account-details",
    "title": "UPPMAX Account Guide",
    "section": "5 UPPMAX account details",
    "text": "5 UPPMAX account details\n​Within about 2 working days you should get an email with instructions. ​Please, follow these instructions carefully. ​A while later you will get an email with your user name, and another email with a link to your password.\n\n\n\n\n\n\nCaution\n\n\n\nThe link is only valid for ​1​ visit or 7 days​, so if you click the link you better save the password, because you will not be able to use the link again. Do this before 7 days have passed, otherwise the link will no longer be valid."
  },
  {
    "objectID": "other/uppmax.html#login-with-new-uppmax-account",
    "href": "other/uppmax.html#login-with-new-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "6 Login with new UPPMAX account",
    "text": "6 Login with new UPPMAX account\n​Open your terminal program (Terminal in OSX and Linux, otherwise download MobaXterm​ (portable edition) if you have Windows).\n​Type this command in your terminal program: ssh username@rackham.uppmax.uu.se ​You will be asked for your password now, and you will not see any response in the terminal while typing your password. This is to hide the length of your password, i.e. normal. Just press enter when you have typed it in and you should log in.\n​If it is the first time you log in, it will ask you to change your LDAP password (the password you just typed). It will directly ask you for your password again, so type it once more. After that it will ask you for your new password, so make up a new one and press enter. After that it will ask you to confirm the new password. When the password change is completed you will be disconnected and you will have to connect again, using your new password to log in this time."
  },
  {
    "objectID": "other/uppmax.html#create-a-folder",
    "href": "other/uppmax.html#create-a-folder",
    "title": "UPPMAX Account Guide",
    "section": "7 ​Create a folder",
    "text": "7 ​Create a folder\n\n\n\n\n\n\nCaution\n\n\n\n​After having received information that your membership is approved, ​wait 24 h before continuing, as it takes up to 24 h for SUPR to sync with UPPMAX. Else, you might get the message Permission denied when writing files or folders.\n\n\nCreate a directory for you to work in. Replace &lt;username&gt; with your actual user name.\n\n\n\n\nbash\n\nmkdir /proj/​naiss2023-23-648/nobackup/&lt;username&gt;\n\n\n\n​Unless you got some kind of error message. you should now be finished. To make sure the folder was created you can type\n\n\n\n\nbash\n\nls /proj/​naiss2023-23-648/nobackup/\n\n\n\n​It should list all directories along with the one you created. ​If you get an error message, contact us in Slack."
  },
  {
    "objectID": "other/scilifelab-serve.html",
    "href": "other/scilifelab-serve.html",
    "title": "Using Scilifelab Serve",
    "section": "",
    "text": "In order to be able to access the lab notebooks for this course you need to have access to SciLifeLab Serve.\nPlease register with your university email address. In the registration form there is a field called “Do you require support?”, in here please write that you are registering to take part in the course SCRNASEQ_V25. Do not forget to also confirm your e-mail address by clicking on a link in the activation email. This needs to be done before Monday 24th March so that the SciLifeLab Serve admins can set up your account in the way that is required by the course."
  },
  {
    "objectID": "other/scilifelab-serve.html#apply-for-an-account",
    "href": "other/scilifelab-serve.html#apply-for-an-account",
    "title": "Using Scilifelab Serve",
    "section": "",
    "text": "In order to be able to access the lab notebooks for this course you need to have access to SciLifeLab Serve.\nPlease register with your university email address. In the registration form there is a field called “Do you require support?”, in here please write that you are registering to take part in the course SCRNASEQ_V25. Do not forget to also confirm your e-mail address by clicking on a link in the activation email. This needs to be done before Monday 24th March so that the SciLifeLab Serve admins can set up your account in the way that is required by the course."
  },
  {
    "objectID": "other/scilifelab-serve.html#launching-practicals",
    "href": "other/scilifelab-serve.html#launching-practicals",
    "title": "Using Scilifelab Serve",
    "section": "2 Launching practicals",
    "text": "2 Launching practicals\nFor launching practicals please follow the instructions here."
  },
  {
    "objectID": "other/docker.html",
    "href": "other/docker.html",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Macs with Apple Silicon, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#install-docker",
    "href": "other/docker.html#install-docker",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Macs with Apple Silicon, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#test-installation",
    "href": "other/docker.html#test-installation",
    "title": "Docker Set Up",
    "section": "2 Test installation",
    "text": "2 Test installation\nFrom the terminal, type:\ndocker --version\nand then run your first image by typing:\ndocker run hello-world\nIf both work as expected, you successfully installed Docker Desktop!"
  },
  {
    "objectID": "other/docker.html#allocate-resources",
    "href": "other/docker.html#allocate-resources",
    "title": "Docker Set Up",
    "section": "3 Allocate resources",
    "text": "3 Allocate resources\nOpen the Docker Dashboard when Docker Desktop starts and go to Settings ( in the top-right) &gt; Resources to allocate the following resources:\n\nCPU limit: 8\n\nMemory limit: 12 GB\n\nSwap: 2 GB\n\nOn Windows, if WSL engine is used, you might not be able to change resources directly."
  },
  {
    "objectID": "other/containers.html",
    "href": "other/containers.html",
    "title": "Run labs in container",
    "section": "",
    "text": "Note\n\n\n\nThree different toolkits, namely Seurat (R/RStudio), Bioconductor (R/RStudio) and Scanpy (Python/Jupyter) are available to perform the scRNAseq analysis. The labs can be run on SciLifeLab Serve or on your local machine using Docker. Both options provide the necessary environment to run the analysis.\nIf you use SciLifeLab Serve, you do not need any local installation or setup on your system but you need a SciLifeLab Serve account. If you use Docker, you will need to set up and run Docker yourself."
  },
  {
    "objectID": "other/containers.html#option-a-run-labs-on-scilifelab-serve-recommended",
    "href": "other/containers.html#option-a-run-labs-on-scilifelab-serve-recommended",
    "title": "Run labs in container",
    "section": "1 Option A: Run labs on SciLifeLab Serve (Recommended)",
    "text": "1 Option A: Run labs on SciLifeLab Serve (Recommended)\n\nLog in with your university email account to SciLifeLab Serve.\n\n\n\n\n\n\n\nImportant\n\n\n\nThis step requires that you are registered, and your account was given access to the course materials. If you did not register yet, please follow the precourse information and send an email to serve@scilifelab.se and let them know that you completed the registration.\n\n\n\nSelect My projects from the main menu. You should see a project called SCRNASEQ_VT25. Click Open.\n\n\n\n\n\n\n\nIn the SCRNASEQ_VT25 project, you can create an RStudio (for Seurat/Bioconductor) or JupyterLab (for Scanpy) notebook server instance, depending on which toolkit you choose to work with, by clicking the Create button.\n\n\n\n\n\n\n\nYou will now see a form to configure a notebook server. Under Name put the name of your choice, e.g. the toolkit. Leave the rest of the fields unchanged. Now click Submit.\n\n\n\n\n\n\n\nThe notebook server will now be created for you. Wait a few minutes to see the status Running in green. You can now click on its name to open it in a new tab.\n\n\n\n\n\n\n\nNote\n\n\n\nFor JupyterLab you will need to use the password scrnaseq.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the status does not turn to Running within 5 minutes click on the three dots under Actions and then Delete. Wait a few minutes until you see the status Deleted. Now you can refresh the page and create a new instance starting from step 3.\nIn rare cases it may happen that your notebook server suddenly restarts. This could be due to an error that affected the notebook globally (for example, it ran out of temporary memory). You will see this on the page where you are working. A new notebook will start for you at the same URL within a few minutes.\n\n\nIn the case of both JupyterLab and RStudio you have access to persistent storage. This is mounted to the folder /home/jovyan/work. Files stored in this folder (NB: only in this folder) will be available even if a notebook suddenly restarts. You can also view, download these files or upload other files that will become visible in your instance through a File Manager that can be launched from the bottom of the Project overview page.\n\nInside the notebook server the script download-labs.sh is provided that will download the corresponding labs. It creates a labs folder with .qmd files (Seurat/Bioconductor) or .ipynb files (Scanpy). In the terminal, run any of the usage examples below:\n\n\nSeurat\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"seurat\" \"work/labs\"\n\nBioconductor\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"bioc\" \"work/labs\"\n\nScanpy\n\nconda activate scanpy\n~/work/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"scanpy\" \"work/labs\"\n\n\n\n\n\n\nImportant\n\n\n\nRemember that data is only saved inside the /home/jovyan/work folder. If you run the labs outside this folder, all the labs and data files will be lost in case the JupyterLab server restarts or gets deleted (this can happen e.g. if it runs out of memory). It is recommended that at the end of each session you save the notebooks locally. You can do this by dowloading them through the File Manager interface available at the bottom of the project dashboard.\n\n\n\nWhen you are done with a particular notebook server, you need to delete it before you can create a new one. Click on the three dots under Actions, and then click on Delete. Wait a few minutes until you see the status Deleted. Now you can refresh the page and start over."
  },
  {
    "objectID": "other/containers.html#option-b-run-docker-locally",
    "href": "other/containers.html#option-b-run-docker-locally",
    "title": "Run labs in container",
    "section": "2 Option B: Run Docker Locally",
    "text": "2 Option B: Run Docker Locally\n\n2.1 Local Setup\nIf you don’t have Docker installed locally, please follow these instructions.\n\n\n2.2 Images\nSeparate Docker images are made available for Seurat/Bioconductor and Scanpy toolkits. Below you find an overview of the available docker images. Note the space requirements!\n\n\n\n\n\n\n\n\nTopic\nImage\nSize (GB)\n\n\n\n\nSeurat/Bioconductor\nghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\n13.1GB\n\n\nScanpy\nghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\n16.9GB\n\n\n\n\n\n2.3 Seurat/Bioconductor\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\ndocker run --platform=linux/amd64 --rm -p 8787:8787 -v ${PWD}:/home/jovyan/work ghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\nDo not close the terminal! In the browser, go to localhost:8787.\nInside RStudio, the script download-scripts-lab.sh is provided that will download the corresponding labs. It creates a labs folder with .qmd files. In the terminal, run the commands below:\n\nSeurat\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"seurat\" \"work/labs\"\n\nBioconductor\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"bioc\" \"work/labs\"\nNavigate to /home/jovyan/work/labs/ and open the .qmd files.\n\n\n2.4 Scanpy\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/work/work ghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\nDo not close the terminal! In the browser, go to localhost:8888. Use the following credentials to log in to the JupyterLab server:\n\nPassword: scrnaseq\n\nInside JupyterLab, the script download-scripts-lab.sh is provided that will download the corresponding labs. It creates a labs folder with .ipynb files. In the terminal, run the commands below:\nconda activate scanpy\n~/work/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"scanpy\" \"work/labs\"\nNavigate to /home/jovyan/work/labs/ and open the .ipynb files."
  },
  {
    "objectID": "other/containers-spatial.html",
    "href": "other/containers-spatial.html",
    "title": "Run labs in container",
    "section": "",
    "text": "Important\n\n\n\nThe docker containers are not tested on Microsoft Windows OS.\n\n\n\n\nCreate a new directory at a suitable location. Now you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs to work on labs.\ngit clone --depth 1 --single-branch --branch master https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\nIf the git command is not available, you can simply go to https://github.com/NBISweden/workshop-scRNAseq and download the repo as a zip file and unzip it in a suitable location.\n\n\n\nSeparate Docker images to run the spatial analysis are made available for Seurat, Bioconductor and Scanpy toolkits. All images follow the registry/username/image:tag convention. The image is always ghcr.io/nbisweden/workshop-scrnaseq. Add the appropriate tag based on the lab you are running.\nAn overview of the available docker images. Note the space requirements.\n\n\n\nTopic\nImage Tag\nSize (GB)\n\n\n\n\nSeurat spatial\n2024-seurat_spatial-r4.3.0\n6.85\n\n\nBioconductor spatial\n2024-bioconductor_spatial-r4.3.0\n6.47\n\n\nScanpy spatial\n2024-scanpy_spatial-py3.10\n3.68\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8788:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8788.\nUse the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\nRStudio login screen\n\n\n\n\n\nRStudio preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8789:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8789. Use the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\nDo not close the terminal. At the end of the prompt, you will see a URL that starts with http://127.0.0.1, similar to the one below:\nhttp://127.0.0.1:8888/lab?token=0a1d9ec51b91528a1d1fe2ad2c74f59ecb94c47070c2911d\nNote that your token value will be different. Copy the entire URL (with the token) and paste it in your browser.\n\n\n\n\n\nJupyterLab home\n\n\n\n\n\nJupyterLab preview"
  },
  {
    "objectID": "other/containers-spatial.html#run-docker-locally",
    "href": "other/containers-spatial.html#run-docker-locally",
    "title": "Run labs in container",
    "section": "",
    "text": "Important\n\n\n\nThe docker containers are not tested on Microsoft Windows OS.\n\n\n\n\nCreate a new directory at a suitable location. Now you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs to work on labs.\ngit clone --depth 1 --single-branch --branch master https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\nIf the git command is not available, you can simply go to https://github.com/NBISweden/workshop-scRNAseq and download the repo as a zip file and unzip it in a suitable location.\n\n\n\nSeparate Docker images to run the spatial analysis are made available for Seurat, Bioconductor and Scanpy toolkits. All images follow the registry/username/image:tag convention. The image is always ghcr.io/nbisweden/workshop-scrnaseq. Add the appropriate tag based on the lab you are running.\nAn overview of the available docker images. Note the space requirements.\n\n\n\nTopic\nImage Tag\nSize (GB)\n\n\n\n\nSeurat spatial\n2024-seurat_spatial-r4.3.0\n6.85\n\n\nBioconductor spatial\n2024-bioconductor_spatial-r4.3.0\n6.47\n\n\nScanpy spatial\n2024-scanpy_spatial-py3.10\n3.68\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8788:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8788.\nUse the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\nRStudio login screen\n\n\n\n\n\nRStudio preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8789:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8789. Use the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\nDo not close the terminal. At the end of the prompt, you will see a URL that starts with http://127.0.0.1, similar to the one below:\nhttp://127.0.0.1:8888/lab?token=0a1d9ec51b91528a1d1fe2ad2c74f59ecb94c47070c2911d\nNote that your token value will be different. Copy the entire URL (with the token) and paste it in your browser.\n\n\n\n\n\nJupyterLab home\n\n\n\n\n\nJupyterLab preview"
  },
  {
    "objectID": "other/faq.html",
    "href": "other/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#command-line-developer-tools-not-found",
    "href": "other/faq.html#command-line-developer-tools-not-found",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "href": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "title": "FAQ",
    "section": "2 Error: umap-learn not found, or other python packages",
    "text": "2 Error: umap-learn not found, or other python packages\n\nIf your R does not find the correct python version, it will complain that umap-learn is not installed and ask you to install it. Here are some tips on how to find the correct python version that was installed in the conda environment.\nTry selecting the correct conda env in R. In this example the conda environment is named myenv.\nlibrary(reticulate)\nreticulate::use_conda(\"myenv\")\nThen check what python you have in R:\nreticulate::py_config()\n# should read at top:\npython:         /Users/asbj/miniconda3/envs/myenv/bin/python\nIf that still is not right, you may have an r-reticulate python installation as well and need to perform the steps below.\n\nRestart R and select python version\nFirst, find out what path you have to your conda python (in TERMINAL):\n\nwhich python\n/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\n\nThen in R (after restarting):\n\nreticulate::use_python(\"/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\", required=T)\n\nThen check again with py_config if correct version of python is used:\n\nreticulate::py_config()\n\nIf you have the correct version now, you should be able to run UMAP without issues."
  },
  {
    "objectID": "other/faq.html#unable-to-load-stringi.so",
    "href": "other/faq.html#unable-to-load-stringi.so",
    "title": "FAQ",
    "section": "3 Unable to load stringi.so",
    "text": "3 Unable to load stringi.so\n \nYou can install stringi in R using:\ninstall.packages('stringi')"
  },
  {
    "objectID": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "href": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "title": "FAQ",
    "section": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing",
    "text": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing\n\nThis is a problem with the MacOSX compiler, in which conda is unable to find it.\n#Download MacOSX10.9.sdk from Github\ncurl -o MacOSX10.9.sdk.tar.gz \"https://github.com/phracker/MacOSX-SDKs/releases/download/11.3/MacOSX10.9.sdk.tar.xz\"\n\n#extract\nsudo tar -xzf MacOSX10.9.sdk.tar.xz\n\n#copy\nsudo cp -r MacOSX10.9.sdk /opt/\n\n#give executable permissions\nsudo chmod -R a+rX /opt\n\n#Link the path where conda looks to where the file is\nln -s /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk /opt/MacOSX10.9.sdk"
  },
  {
    "objectID": "other/faq.html#error-option-error-has-null-value",
    "href": "other/faq.html#error-option-error-has-null-value",
    "title": "FAQ",
    "section": "5 ERROR: option error has NULL value",
    "text": "5 ERROR: option error has NULL value\n\nThis error happens when running code inline. One possible solution is to restart Rstudio and type.\nif(interactive()) { options(error = utils::recover)}\nPlease try other solutions listed here. If none of those work, you can click on the wheel engine symbol and check Chunk output in console."
  },
  {
    "objectID": "other/faq.html#r-crashes-due-to-memory-issues",
    "href": "other/faq.html#r-crashes-due-to-memory-issues",
    "title": "FAQ",
    "section": "6 R crashes due to memory issues",
    "text": "6 R crashes due to memory issues\n\nIf R crashes due to memory issues, it may be a good idea to increase the vector size R_MAX_VSIZE. Put in the file .Renviron either in your home directory or the folder you are launching Rstudio from:\nR_MAX_VSIZE=70Gb\nOr to whatever value matches your computer, the default size is 16Gb."
  },
  {
    "objectID": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "href": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "title": "FAQ",
    "section": "7 Docker run fails on Mac apple silicon",
    "text": "7 Docker run fails on Mac apple silicon\n\nDocker run on Apple Mac M1/M2/M3 processors experience this error when running docker run ... on an image not built on Apple silicon.\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] 01_set_env: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] 01_set_env: exited 0.\n[cont-init.d] 02_userconf: executing...\n[cont-init.d] 02_userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nTTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\nrserver[1195]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\n\n2023-11-28T14:31:03.943703Z [rserver] ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\nrserver[1199]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: rstudio::core::Error rstudio::core::system::launchChildProcess(std::string, std::string, rstudio::core::system::ProcessConfig, rstudio::core::system::ProcessConfigFilter, PidType*) src/cpp/core/system/PosixSystem.cpp:2195\nIn Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon."
  },
  {
    "objectID": "other/faq.html#open-multiple-files-simultaneously-in-rstudio",
    "href": "other/faq.html#open-multiple-files-simultaneously-in-rstudio",
    "title": "FAQ",
    "section": "8 Open multiple files simultaneously in RStudio",
    "text": "8 Open multiple files simultaneously in RStudio\n\nOpen all qmd files in the current working directory.\n\n\n\nR\n\nlapply(list.files(pattern = \"\\\\.qmd$\"), rstudioapi::documentOpen)"
  },
  {
    "objectID": "other/data.html",
    "href": "other/data.html",
    "title": "Data",
    "section": "",
    "text": "The data we are using in the first 6 tutorials is 10x data of peripheral blood mononuclear cells (PBMCs) from Covid patients and healthy controls from the paper “Immunophenotyping of COVID-19 and influenza highlights the role of type I interferons in development of severe COVID-19” in Science.\nA peripheral blood mononuclear cell (PBMC) is any peripheral blood cell having a round nucleus. These cells consist of lymphocytes (T cells, B cells, NK cells), monocytes and dendritic cells, whereas erythrocytes and platelets have no nuclei, and granulocytes (neutrophils, basophils, and eosinophils) have multi-lobed nuclei.\nData was downloaded from GEO GSE149689 entry. For the tutorials we have selected 4 of the severe patients and 4 controls from that dataset. Each donor was then downsampled to 1500 cells per individual just to speed up the processing times in the labs. The script used to select samples and downsampling can be found in our GitHub repo."
  },
  {
    "objectID": "other/data.html#covid-19-data",
    "href": "other/data.html#covid-19-data",
    "title": "Data",
    "section": "",
    "text": "The data we are using in the first 6 tutorials is 10x data of peripheral blood mononuclear cells (PBMCs) from Covid patients and healthy controls from the paper “Immunophenotyping of COVID-19 and influenza highlights the role of type I interferons in development of severe COVID-19” in Science.\nA peripheral blood mononuclear cell (PBMC) is any peripheral blood cell having a round nucleus. These cells consist of lymphocytes (T cells, B cells, NK cells), monocytes and dendritic cells, whereas erythrocytes and platelets have no nuclei, and granulocytes (neutrophils, basophils, and eosinophils) have multi-lobed nuclei.\nData was downloaded from GEO GSE149689 entry. For the tutorials we have selected 4 of the severe patients and 4 controls from that dataset. Each donor was then downsampled to 1500 cells per individual just to speed up the processing times in the labs. The script used to select samples and downsampling can be found in our GitHub repo."
  },
  {
    "objectID": "other/data.html#hematopoesis-data",
    "href": "other/data.html#hematopoesis-data",
    "title": "Data",
    "section": "2 Hematopoesis data",
    "text": "2 Hematopoesis data\nIn the trajectory exercise we continue with immune cells but to get the full development of the different lineages we need to have bone marrow data. The dataset we are using is an integrated object with bone marrow data from multiple studies.\nThe data was integrated with Harmony and saved as a Seurat object. We already have subsetted the dataset (with 6688 cells and 3585 genes). In addition there was some manual filtering done to remove clusters that are disconnected and cells that are hard to cluster, which can be seen in this script"
  },
  {
    "objectID": "other/data.html#spatial-transcriptomics-data-optional-topic",
    "href": "other/data.html#spatial-transcriptomics-data-optional-topic",
    "title": "Data",
    "section": "3 Spatial transcriptomics data (optional topic)",
    "text": "3 Spatial transcriptomics data (optional topic)\nFor the spatial transcriptomics tutorial we are using public Visium data from the 10x website that has been included in the data resources for the Seurat and Scanpy packages. We are using tow sections of the mouse brain (Sagittal).\nThe single cell data that we are using for mapping of celltypes onto the spatial data is a mouse cortex dataset from Allen brain institute."
  },
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-seurat",
    "href": "labs/index.html#fa-brands-r-project-seurat",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-bioconductor",
    "href": "labs/index.html#fa-brands-r-project-bioconductor",
    "title": "Labs",
    "section": " Bioconductor",
    "text": "Bioconductor\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-python-scanpy",
    "href": "labs/index.html#fa-brands-python-scanpy",
    "title": "Labs",
    "section": " Scanpy",
    "text": "Scanpy\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Trajectory inference using PAGA\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html",
    "href": "labs/seurat/seurat_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_data",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\n# download pre-computed annotation\nfetch_annotation &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_covid &lt;- \"./data/covid/raw\"\nif (!dir.exists(path_covid)) dir.create(path_covid, recursive = T)\n\npath_results &lt;- \"./data/covid/results\"\nif (!dir.exists(path_results)) dir.create(path_results, recursive = T)\n\n\nfile_list &lt;- c(\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n)\n\nfor (i in file_list) {\n    path_file &lt;- file.path(path_covid, i)\n    if (!file.exists(path_file)) {\n        download.file(url = file.path(file.path(path_data, \"covid/raw\"), i),\n              destfile = path_file, method = \"curl\", extra = curl_upass)\n    }\n}\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(Matrix)\n    library(ggplot2)\n    library(patchwork)\n    if (! \"DoubletFinder\" %in% installed.packages()){\n       remotes::install_github(\n        \"https://github.com/chris-mcginnis-ucsf/DoubletFinder@3b420df68b8e2a0cc6ebd4c5c1c7ea170464c97f\",\n          upgrade = FALSE,\n          dependencies = FALSE\n       ) } \n    library(DoubletFinder)\n})\n\n* checking for file ‘/tmp/Rtmp9M6lvn/remotes4475693e4f/chris-mcginnis-ucsf-DoubletFinder-1b244d8/DESCRIPTION’ ... OK\n* preparing ‘DoubletFinder’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building ‘DoubletFinder_2.0.6.tar.gz’\n\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\n\ncov.15 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_15.h5\"),\n    use.names = T\n)\ncov.1 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_1.h5\"),\n    use.names = T\n)\ncov.16 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_16.h5\"),\n    use.names = T\n)\ncov.17 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_17.h5\"),\n    use.names = T\n)\n\nctrl.5 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_5.h5\"),\n    use.names = T\n)\nctrl.13 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_13.h5\"),\n    use.names = T\n)\nctrl.14 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_14.h5\"),\n    use.names = T\n)\nctrl.19 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_19.h5\"),\n    use.names = T\n)"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_collate",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\nWe can now merge them objects into a single object. Each analysis workflow (Seurat, Scater, Scanpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column type in the metadata to define covid and ctrl samples.\nBut first, we need to create Seurat objects using each of the expression matrices we loaded. We define each sample in the project slot, so in each object, the sample id can be found in the metadata slot orig.ident.\n\nsdata.cov1 &lt;- CreateSeuratObject(cov.1, project = \"covid_1\")\nsdata.cov15 &lt;- CreateSeuratObject(cov.15, project = \"covid_15\")\nsdata.cov17 &lt;- CreateSeuratObject(cov.17, project = \"covid_17\")\nsdata.cov16 &lt;- CreateSeuratObject(cov.16, project = \"covid_16\")\nsdata.ctrl5 &lt;- CreateSeuratObject(ctrl.5, project = \"ctrl_5\")\nsdata.ctrl13 &lt;- CreateSeuratObject(ctrl.13, project = \"ctrl_13\")\nsdata.ctrl14 &lt;- CreateSeuratObject(ctrl.14, project = \"ctrl_14\")\nsdata.ctrl19 &lt;- CreateSeuratObject(ctrl.19, project = \"ctrl_19\")\n\n\n# add metadata\nsdata.cov1$type &lt;- \"Covid\"\nsdata.cov15$type &lt;- \"Covid\"\nsdata.cov16$type &lt;- \"Covid\"\nsdata.cov17$type &lt;- \"Covid\"\n\nsdata.ctrl5$type &lt;- \"Ctrl\"\nsdata.ctrl13$type &lt;- \"Ctrl\"\nsdata.ctrl14$type &lt;- \"Ctrl\"\nsdata.ctrl19$type &lt;- \"Ctrl\"\n\n# Merge datasets into one single seurat object\nalldata &lt;- merge(sdata.cov1, c(sdata.cov15, sdata.cov16, sdata.cov17, sdata.ctrl5, sdata.ctrl13, sdata.ctrl14, sdata.ctrl19), add.cell.ids = c(\"covid_1\", \"covid_15\", \"covid_16\", \"covid_17\", \"ctrl_5\", \"ctrl_13\", \"ctrl_14\", \"ctrl_19\"))\n\nIn Seurat v5, merging creates a single object, but keeps the expression information split into different layers for integration. If not proceeding with integration, rejoin the layers after merging.\n\nalldata &lt;- JoinLayers(alldata)\nalldata\n\nAn object of class Seurat \n33538 features across 12000 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\nOnce you have created the merged Seurat object, the count matrices and individual count matrices and objects are not needed anymore. It is a good idea to remove them and run garbage collect to free up some memory.\n\n# remove all objects that will not be used.\nrm(cov.1, cov.15, cov.16, cov.17, ctrl.5, ctrl.13, ctrl.14, ctrl.19, sdata.cov1, sdata.cov15, sdata.cov16, sdata.cov17, sdata.ctrl5, sdata.ctrl13, sdata.ctrl14, sdata.ctrl19)\n# run garbage collect to free up memory\ngc()\n\n           used  (Mb) gc trigger   (Mb)  max used   (Mb)\nNcells  3731356 199.3    7082877  378.3   7082877  378.3\nVcells 33746590 257.5  171763065 1310.5 214697637 1638.1\n\n\nHere is how the count matrix and the metadata look like for every cell.\n\nalldata[[\"RNA\"]]$counts[1:10, 1:4] \n\n10 x 4 sparse Matrix of class \"dgCMatrix\"\n            covid_1_AGGTAGGTCGTTGTTT-1 covid_1_TAGAGTCGTCCTCCAT-1\nMIR1302-2HG                          .                          .\nFAM138A                              .                          .\nOR4F5                                .                          .\nAL627309.1                           .                          .\nAL627309.3                           .                          .\nAL627309.2                           .                          .\nAL627309.4                           .                          .\nAL732372.1                           .                          .\nOR4F29                               .                          .\nAC114498.1                           .                          .\n            covid_1_CCCTGATAGCGAACTG-1 covid_1_TCATCATTCCACGTAA-1\nMIR1302-2HG                          .                          .\nFAM138A                              .                          .\nOR4F5                                .                          .\nAL627309.1                           .                          .\nAL627309.3                           .                          .\nAL627309.2                           .                          .\nAL627309.4                           .                          .\nAL732372.1                           .                          .\nOR4F29                               .                          .\nAC114498.1                           .                          .\n\nhead(alldata@meta.data, 10)"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_calqc",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion of hemoglobin genes can give an indication of red blood cell contamination, but in some tissues it can also be the case that some celltypes have higher content of hemoglobin. This will be helpful to visualize them across different metadata parameters (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\n\n# Mitochondrial\nalldata &lt;- PercentageFeatureSet(alldata, \"^MT-\", col.name = \"percent_mito\")\n\n# Ribosomal\nalldata &lt;- PercentageFeatureSet(alldata, \"^RP[SL]\", col.name = \"percent_ribo\")\n\n# Percentage hemoglobin genes - includes all genes starting with HB except HBP.\nalldata &lt;- PercentageFeatureSet(alldata, \"^HB[^(P|E|S)]\", col.name = \"percent_hb\")\n\n# Percentage for some platelet markers\nalldata &lt;- PercentageFeatureSet(alldata, \"PECAM1|PF4\", col.name = \"percent_plat\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nAlternatively, percentage expression can be calculated manually. Here is an example. Do not run this script now.\n\n# Do not run now!\ntotal_counts_per_cell &lt;- colSums(alldata@assays$RNA@counts)\nmito_genes &lt;- rownames(alldata)[grep(\"^MT-\", rownames(alldata))]\nalldata$percent_mito2 &lt;- colSums(alldata@assays$RNA@counts[mito_genes, ]) / total_counts_per_cell\n\n\n\n\nNow you can see that we have additional data in the metadata slot.\n\nhead(alldata@meta.data)"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_plotqc",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\nfeats &lt;- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\", \"percent_ribo\", \"percent_hb\", \"percent_plat\")\nVlnPlot(alldata, group.by = \"orig.ident\", split.by = \"type\", features = feats, pt.size = 0.1, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLooking at the violin plots, what do you think are appropriate cutoffs for filtering these samples\n\n\nAs you can see, there is quite some difference in quality for these samples, with for instance the covid_15 and covid_16 samples having cells with fewer detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. We can also plot the different QC-measures as scatter plots.\n\nFeatureScatter(alldata, \"nCount_RNA\", \"nFeature_RNA\", group.by = \"orig.ident\", pt.size = .5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_filter",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low number of reads as well as genes that are present in at least a given number of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\n\nselected_c &lt;- WhichCells(alldata, expression = nFeature_RNA &gt; 200)\nselected_f &lt;- rownames(alldata)[Matrix::rowSums(alldata[[\"RNA\"]]$counts) &gt; 3]\n\ndata.filt &lt;- subset(alldata, features = selected_f, cells = selected_c)\ndim(data.filt)\n\n[1] 18877 10656\n\ntable(data.filt$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n    1254     1283     1127     1371     1417     1399     1434     1371 \n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip and run DoubletFinder instead\n# data.filt &lt;- subset(data.filt, cells=WhichCells(data.filt, expression = nFeature_RNA &lt; 4100))\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\n\n# Compute the proportion of counts of each gene per cell\n# Use sparse matrix operations, if your dataset is large, doing matrix devisions the regular way will take a very long time.\n\nC &lt;- data.filt[[\"RNA\"]]$counts\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p)) * 100\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])),\n    cex = 0.1, las = 1, xlab = \"Percent counts per cell\",\n    col = (scales::hue_pal())(20)[20:1], horizontal = TRUE\n)\n\n\n\n\n\n\n\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It would be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\ndata.filt &lt;- subset(data.filt, percent_mito &lt; 20 & percent_ribo &gt; 5)\ndim(data.filt)\n\n[1] 18877  7431\n\ntable(data.filt$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n     900      599      373     1101     1173     1063     1170     1052 \n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats once more.\n\nfeats &lt;- c(\"nFeature_RNA\", \"nCount_RNA\", \"percent_mito\", \"percent_ribo\", \"percent_hb\")\nVlnPlot(data.filt, group.by = \"orig.ident\", features = feats, pt.size = 0.1, ncol = 3) + NoLegend()\n\n\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis. In this case we will also remove the HB genes.\n\ndim(data.filt)\n\n[1] 18877  7431\n\n# Filter MALAT1\ndata.filt &lt;- data.filt[!grepl(\"MALAT1\", rownames(data.filt)), ]\n\n# Filter Mitocondrial\ndata.filt &lt;- data.filt[!grepl(\"^MT-\", rownames(data.filt)), ]\n\n# Filter Ribossomal gene (optional if that is a problem on your data)\n# data.filt &lt;- data.filt[ ! grepl(\"^RP[SL]\", rownames(data.filt)), ]\n\n# Filter Hemoglobin gene (optional if that is a problem on your data)\ndata.filt &lt;- data.filt[!grepl(\"^HB[^(P|E|S)]\", rownames(data.filt)), ]\n\ndim(data.filt)\n\n[1] 18854  7431"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_sex",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain your experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also be a good way to detect if there has been any mislabelling in which case, the sample metadata sex does not agree with the computational predictions.\nTo get chromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. R package biomaRt can be used to fetch annotation information. The code to run biomaRt is provided. As the biomart instances are quite often unresponsive, we will download and use a file that was created in advance.\n\n\n\n\n\n\nTip\n\n\n\n\n\nHere is the code to download annotation data from Ensembl using biomaRt. We will not run this now and instead use a pre-computed file in the step below.\n\n# fetch_annotation is defined at the top of this document\nif (!fetch_annotation) {\n  suppressMessages(library(biomaRt))\n\n  # initialize connection to mart, may take some time if the sites are unresponsive.\n  mart &lt;- useMart(\"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n\n  # fetch chromosome info plus some other annotations\n  genes_table &lt;- try(biomaRt::getBM(attributes = c(\n    \"ensembl_gene_id\", \"external_gene_name\",\n    \"description\", \"gene_biotype\", \"chromosome_name\", \"start_position\"\n  ), mart = mart, useCache = F))\n\n  write.csv(genes_table, file = \"data/covid/results/genes_table.csv\")\n}\n\n\n\n\nDownload precomputed data.\n\n# fetch_annotation is defined at the top of this document\nif (fetch_annotation) {\n  genes_file &lt;- file.path(path_results, \"genes_table.csv\")\n  if (!file.exists(genes_file)) download.file(file.path(path_data, \"covid/results_seurat/genes_table.csv\"), destfile = genes_file,\n                                              method = \"curl\", extra = curl_upass)\n}\n\n\ngenes.table &lt;- read.csv(genes_file)\ngenes.table &lt;- genes.table[genes.table$external_gene_name %in% rownames(data.filt), ]\n\nNow that we have the chromosome information, we can calculate the proportion of reads that comes from chromosome Y per cell.But first we have to remove all genes in the pseudoautosmal regions of chrY that are: * chromosome:GRCh38:Y:10001 - 2781479 is shared with X: 10001 - 2781479 (PAR1) * chromosome:GRCh38:Y:56887903 - 57217415 is shared with X: 155701383 - 156030895 (PAR2)\n\npar1 = c(10001, 2781479)\npar2 = c(56887903, 57217415)\np1.gene = genes.table$external_gene_name[genes.table$start_position &gt; par1[1] & genes.table$start_position &lt; par1[2] & genes.table$chromosome_name == \"Y\"]\np2.gene = genes.table$external_gene_name[genes.table$start_position &gt; par2[1] & genes.table$start_position &lt; par2[2] & genes.table$chromosome_name == \"Y\"]\n\nchrY.gene &lt;- genes.table$external_gene_name[genes.table$chromosome_name == \"Y\"]\nchrY.gene = setdiff(chrY.gene, c(p1.gene, p2.gene))\n\ndata.filt &lt;- PercentageFeatureSet(data.filt, features = chrY.gene, col.name = \"pct_chrY\")\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\nFeatureScatter(data.filt, feature1 = \"XIST\", feature2 = \"pct_chrY\", slot = \"counts\")\n\n\n\n\n\n\n\n\nPlot as violins.\n\nVlnPlot(data.filt, features = c(\"XIST\", \"pct_chrY\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHere, we can see clearly that we have three males and five females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_cellcycle",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in the metadata, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\n# Before running CellCycleScoring the data need to be normalized and logtransformed.\ndata.filt &lt;- NormalizeData(data.filt)\ndata.filt &lt;- CellCycleScoring(\n    object = data.filt,\n    g2m.features = cc.genes$g2m.genes,\n    s.features = cc.genes$s.genes\n)\n\nWe can now create a violin plot for the cell cycle scores as well.\n\nVlnPlot(data.filt, features = c(\"S.Score\", \"G2M.Score\"), group.by = \"orig.ident\", ncol = 3, pt.size = .1)\n\n\n\n\n\n\n\n\nIn this case it looks like we only have a few cycling cells in these datasets.\nSeurat does an automatic prediction of cell cycle phase with a default cutoff of the scores at zero. As you can see this does not fit this data very well, so be cautious with using these predictions. Instead we suggest that you look at the scores.\n\nFeatureScatter(data.filt, \"S.Score\", \"G2M.Score\", group.by = \"Phase\")"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_doublet",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\n\n\n\n\n\n\nCaution\n\n\n\nIdeally doublet prediction should be run on each sample separately, especially if your samples have different proportions of cell types. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs, so it is okay to run them together.\n\n\nHere, we will use DoubletFinder to predict doublet cells. But before doing doublet detection we need to run scaling, variable gene selection and PCA, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.\n\ndata.filt &lt;- FindVariableFeatures(data.filt, verbose = F)\ndata.filt &lt;- ScaleData(data.filt, vars.to.regress = c(\"nFeature_RNA\", \"percent_mito\"), verbose = F)\ndata.filt &lt;- RunPCA(data.filt, verbose = F, npcs = 20)\ndata.filt &lt;- RunUMAP(data.filt, dims = 1:10, verbose = F)\n\nThen we run doubletFinder, selecting first 10 PCs and a pK value of 0.9. To optimize the parameters, you can run the paramSweep function in the package.\n\nsuppressMessages(library(DoubletFinder))\n# Can run parameter optimization with paramSweep\n\n# sweep.res &lt;- paramSweep_v3(data.filt)\n# sweep.stats &lt;- summarizeSweep(sweep.res, GT = FALSE)\n# bcmvn &lt;- find.pK(sweep.stats)\n# barplot(bcmvn$BCmetric, names.arg = bcmvn$pK, las=2)\n\n# define the expected number of doublet cellscells.\nnExp &lt;- round(ncol(data.filt) * 0.04) # expect 4% doublets\ndata.filt &lt;- doubletFinder(data.filt, pN = 0.25, pK = 0.09, nExp = nExp, PCs = 1:10)\n\n[1] \"Creating 2477 artificial doublets...\"\n[1] \"Creating Seurat object...\"\n[1] \"Normalizing Seurat object...\"\n\n\n[1] \"Finding variable genes...\"\n\n\n[1] \"Scaling data...\"\n\n\n[1] \"Running PCA...\"\n[1] \"Calculating PC distance matrix...\"\n[1] \"Computing pANN...\"\n[1] \"Classifying doublets..\"\n\n\n\n# name of the DF prediction can change, so extract the correct column name.\nDF.name &lt;- colnames(data.filt@meta.data)[grepl(\"DF.classification\", colnames(data.filt@meta.data))]\n\nwrap_plots(\n    DimPlot(data.filt, group.by = \"orig.ident\") + NoAxes(),\n    DimPlot(data.filt, group.by = DF.name) + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nWe should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.\n\nVlnPlot(data.filt, features = \"nFeature_RNA\", group.by = DF.name, pt.size = .1)\n\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\ndata.filt &lt;- data.filt[, data.filt@meta.data[, DF.name] == \"Singlet\"]\ndim(data.filt)\n\n[1] 18854  7134\n\n\nTo summarize, lets check how many cells we have removed per sample, we started with 1500 cells per sample. Looking back at the intitial QC plots does it make sense that some samples have much fewer cells now?\n\ntable(alldata$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n    1500     1500     1500     1500     1500     1500     1500     1500 \n\ntable(data.filt$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n     875      549      357     1057     1126      996     1141     1033 \n\n\n\n\n\n\n\n\nDiscuss\n\n\n\n“In this case we ran doublet detection with all samples together since we have very small subsampled datasets. But in a real scenario it should be run one sample at a time. Why is this important do you think?”"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-qc_save",
    "href": "labs/seurat/seurat_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory data/covid/results and save data to that folder. This will be used in downstream labs.\n\nsaveRDS(data.filt, file.path(path_results, \"seurat_covid_qc.rds\"))"
  },
  {
    "objectID": "labs/seurat/seurat_01_qc.html#meta-session",
    "href": "labs/seurat/seurat_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] DoubletFinder_2.0.6 patchwork_1.3.0     ggplot2_3.5.1      \n[4] Matrix_1.6-5        Seurat_5.1.0        SeuratObject_5.0.2 \n[7] sp_2.2-0           \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-4           pbapply_1.7-2          gridExtra_2.3         \n  [4] remotes_2.5.0          rlang_1.1.5            magrittr_2.0.3        \n  [7] RcppAnnoy_0.0.22       spatstat.geom_3.3-5    matrixStats_1.5.0     \n [10] ggridges_0.5.6         compiler_4.3.3         maps_3.4.2.1          \n [13] png_0.1-8              vctrs_0.6.5            reshape2_1.4.4        \n [16] hdf5r_1.3.11           stringr_1.5.1          pkgconfig_2.0.3       \n [19] fastmap_1.2.0          labeling_0.4.3         promises_1.3.2        \n [22] rmarkdown_2.29         ggbeeswarm_0.7.2       bit_4.5.0.1           \n [25] purrr_1.0.2            xfun_0.50              jsonlite_1.8.9        \n [28] goftest_1.2-3          later_1.4.1            spatstat.utils_3.1-2  \n [31] irlba_2.3.5.1          parallel_4.3.3         cluster_2.1.8         \n [34] R6_2.6.1               ica_1.0-3              stringi_1.8.4         \n [37] RColorBrewer_1.1-3     spatstat.data_3.1-4    reticulate_1.40.0     \n [40] parallelly_1.42.0      spatstat.univar_3.1-1  lmtest_0.9-40         \n [43] scattermore_1.2        Rcpp_1.0.14            knitr_1.49            \n [46] fields_16.3            tensor_1.5             future.apply_1.11.3   \n [49] zoo_1.8-12             sctransform_0.4.1      httpuv_1.6.15         \n [52] splines_4.3.3          igraph_2.0.3           tidyselect_1.2.1      \n [55] abind_1.4-5            yaml_2.3.10            spatstat.random_3.3-2 \n [58] codetools_0.2-20       miniUI_0.1.1.1         spatstat.explore_3.3-4\n [61] curl_6.0.1             listenv_0.9.1          lattice_0.22-6        \n [64] tibble_3.2.1           plyr_1.8.9             withr_3.0.2           \n [67] shiny_1.10.0           ROCR_1.0-11            ggrastr_1.0.2         \n [70] evaluate_1.0.3         Rtsne_0.17             future_1.34.0         \n [73] fastDummies_1.7.5      survival_3.8-3         polyclip_1.10-7       \n [76] fitdistrplus_1.2-2     pillar_1.10.1          KernSmooth_2.23-26    \n [79] plotly_4.10.4          generics_0.1.3         RcppHNSW_0.6.0        \n [82] munsell_0.5.1          scales_1.3.0           globals_0.16.3        \n [85] xtable_1.8-4           glue_1.8.0             lazyeval_0.2.2        \n [88] tools_4.3.3            data.table_1.16.4      RSpectra_0.16-2       \n [91] RANN_2.6.2             leiden_0.4.3.1         dotCall64_1.2         \n [94] cowplot_1.1.3          grid_4.3.3             tidyr_1.3.1           \n [97] colorspace_2.1-1       nlme_3.1-167           beeswarm_0.4.0        \n[100] vipor_0.4.7            cli_3.6.4              spatstat.sparse_3.1-0 \n[103] spam_2.11-1            viridisLite_0.4.2      dplyr_1.1.4           \n[106] uwot_0.2.2             gtable_0.3.6           digest_0.6.37         \n[109] progressr_0.15.1       ggrepel_0.9.6          htmlwidgets_1.6.4     \n[112] farver_2.1.2           htmltools_0.5.8.1      lifecycle_1.0.4       \n[115] httr_1.4.7             mime_0.12              bit64_4.5.2           \n[118] MASS_7.3-60.0.1"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html",
    "href": "labs/scanpy/scanpy_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands."
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_data",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\nimport os\n\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_covid = \"./data/covid/raw\"\nif not os.path.exists(path_covid):\n    os.makedirs(path_covid, exist_ok=True)\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\n\nimport subprocess\n\nfile_list = [\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n]\n\nfor i in file_list:\n    path_file = os.path.join(path_covid, i)\n    if not os.path.exists(path_file):\n        file_url = os.path.join(path_data, \"covid/raw\", i)\n        subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport warnings\nimport gc\n\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80)\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\nIn Scanpy we read them into an Anndata object with the the function read_10x_h5\n\ndata_cov1 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_1.h5'))\ndata_cov1.var_names_make_unique()\ndata_cov15 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_15.h5'))\ndata_cov15.var_names_make_unique()\ndata_cov16 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_16.h5'))\ndata_cov16.var_names_make_unique()\ndata_cov17 = sc.read_10x_h5(os.path.join(path_covid,'ncov_pbmc_17.h5'))\ndata_cov17.var_names_make_unique()\ndata_ctrl5 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_5.h5'))\ndata_ctrl5.var_names_make_unique()\ndata_ctrl13 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_13.h5'))\ndata_ctrl13.var_names_make_unique()\ndata_ctrl14 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_14.h5'))\ndata_ctrl14.var_names_make_unique()\ndata_ctrl19 = sc.read_10x_h5(os.path.join(path_covid,'normal_pbmc_19.h5'))\ndata_ctrl19.var_names_make_unique()\n\nreading ./data/covid/raw/ncov_pbmc_1.h5\n (0:00:00)\nreading ./data/covid/raw/ncov_pbmc_15.h5\n (0:00:00)\nreading ./data/covid/raw/ncov_pbmc_16.h5\n (0:00:00)\nreading ./data/covid/raw/ncov_pbmc_17.h5\n (0:00:00)\nreading ./data/covid/raw/normal_pbmc_5.h5\n (0:00:00)\nreading ./data/covid/raw/normal_pbmc_13.h5\n (0:00:00)\nreading ./data/covid/raw/normal_pbmc_14.h5\n (0:00:00)\nreading ./data/covid/raw/normal_pbmc_19.h5\n (0:00:00)"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_collate",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\nWe can now merge them objects into a single object. Each analysis workflow (Seurat, Scater, Scanpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column type in the metadata to define covid and ctrl samples.\n\n# add some metadata\ndata_cov1.obs['type']=\"Covid\"\ndata_cov1.obs['sample']=\"covid_1\"\ndata_cov15.obs['type']=\"Covid\"\ndata_cov15.obs['sample']=\"covid_15\"\ndata_cov16.obs['type']=\"Covid\"\ndata_cov16.obs['sample']=\"covid_16\"\ndata_cov17.obs['type']=\"Covid\"\ndata_cov17.obs['sample']=\"covid_17\"\ndata_ctrl5.obs['type']=\"Ctrl\"\ndata_ctrl5.obs['sample']=\"ctrl_5\"\ndata_ctrl13.obs['type']=\"Ctrl\"\ndata_ctrl13.obs['sample']=\"ctrl_13\"\ndata_ctrl14.obs['type']=\"Ctrl\"\ndata_ctrl14.obs['sample']=\"ctrl_14\"\ndata_ctrl19.obs['type']=\"Ctrl\"\ndata_ctrl19.obs['sample']=\"ctrl_19\"\n\n# merge into one object.\nadata = data_cov1.concatenate(data_cov15, data_cov16, data_cov17, data_ctrl5, data_ctrl13, data_ctrl14, data_ctrl19)\n\n# and delete individual datasets to save space\ndel(data_cov1, data_cov15, data_cov16, data_cov17)\ndel(data_ctrl5, data_ctrl13, data_ctrl14, data_ctrl19)\ngc.collect()\n\n1267\n\n\nYou can print a summary of the datasets in the Scanpy object, or a summary of the whole object.\n\nprint(adata.obs['sample'].value_counts())\nadata\n\ncovid_1     1500\ncovid_15    1500\ncovid_16    1500\ncovid_17    1500\nctrl_5      1500\nctrl_13     1500\nctrl_14     1500\nctrl_19     1500\nName: sample, dtype: int64\n\n\nAnnData object with n_obs × n_vars = 12000 × 33538\n    obs: 'type', 'sample', 'batch'\n    var: 'gene_ids', 'feature_types', 'genome'"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_calqc",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion of hemoglobin genes can give an indication of red blood cell contamination, but in some tissues it can also be the case that some celltypes have higher content of hemoglobin. This will be helpful to visualize them across different metadata parameters (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\nFirst, let Scanpy calculate some general qc-stats for genes and cells with the function sc.pp.calculate_qc_metrics, similar to calculateQCmetrics() in Scater. It can also calculate proportion of counts for specific gene populations, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.\n\n# mitochondrial genes\nadata.var['mt'] = adata.var_names.str.startswith('MT-') \n# ribosomal genes\nadata.var['ribo'] = adata.var_names.str.startswith((\"RPS\",\"RPL\"))\n# hemoglobin genes.\nadata.var['hb'] = adata.var_names.str.contains((\"^HB[^(P|E|S)]\"))\n\nadata.var\n\n\n\n\n\n\n\n\ngene_ids\nfeature_types\ngenome\nmt\nribo\nhb\n\n\n\n\nMIR1302-2HG\nENSG00000243485\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nFAM138A\nENSG00000237613\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nOR4F5\nENSG00000186092\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAL627309.1\nENSG00000238009\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAL627309.3\nENSG00000239945\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\nAC233755.2\nENSG00000277856\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC233755.1\nENSG00000275063\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC240274.1\nENSG00000271254\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nAC213203.1\nENSG00000277475\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\nFAM231C\nENSG00000268674\nGene Expression\nGRCh38\nFalse\nFalse\nFalse\n\n\n\n\n33538 rows × 6 columns\n\n\n\n\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt','ribo','hb'], percent_top=None, log1p=False, inplace=True)\n\nNow you can see that we have additional data in the metadata slot.\nAnother opition to using the calculate_qc_metrics function is to calculate the values on your own and add to a metadata slot. An example for mito genes can be found below:\n\nmito_genes = adata.var_names.str.startswith('MT-')\n# for each cell compute fraction of counts in mito genes vs. all genes\n# the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\nadata.obs['percent_mt2'] = np.sum(\n    adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n# add the total counts per cell as observations-annotation to adata\nadata.obs['n_counts'] = adata.X.sum(axis=1).A1\n\nadata\n\nAnnData object with n_obs × n_vars = 12000 × 33538\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_plotqc",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation= 45)\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLooking at the violin plots, what do you think are appropriate cutoffs for filtering these samples\n\n\nAs you can see, there is quite some difference in quality for these samples, with for instance the covid_15 and covid_16 samples having cells with fewer detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. We can also plot the different QC-measures as scatter plots.\n\nsc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color=\"sample\")\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_filter",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low number of reads as well as genes that are present in at least a given number of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\n\nsc.pp.filter_cells(adata, min_genes=200)\nsc.pp.filter_genes(adata, min_cells=3)\n\nprint(adata.n_obs, adata.n_vars)\n\nfiltered out 1336 cells that have less than 200 genes expressed\nfiltered out 14047 genes that are detected in less than 3 cells\n10664 19491\n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip for now as we are doing doublet prediction\n#keep_v2 = (adata.obs['n_genes_by_counts'] &lt; 2000) & (adata.obs['n_genes_by_counts'] &gt; 500) & (adata.obs['lib_prep'] == 'v2')\n#print(sum(keep_v2))\n\n# filter for gene detection for v3\n#keep_v3 = (adata.obs['n_genes_by_counts'] &lt; 4100) & (adata.obs['n_genes_by_counts'] &gt; 1000) & (adata.obs['lib_prep'] != 'v2')\n#print(sum(keep_v3))\n\n# keep both sets of cells\n#keep = (keep_v2) | (keep_v3)\n#print(sum(keep))\n#adata = adata[keep, :]\n\n#print(\"Remaining cells %d\"%adata.n_obs)\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\n\nsc.pl.highest_expr_genes(adata, n_top=20)\n\nnormalizing counts per cell\n    finished (0:00:00)\n\n\n\n\n\n\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It would be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\n# filter for percent mito\nadata = adata[adata.obs['pct_counts_mt'] &lt; 20, :]\n\n# filter for percent ribo &gt; 0.05\nadata = adata[adata.obs['pct_counts_ribo'] &gt; 5, :]\n\nprint(\"Remaining cells %d\"%adata.n_obs)\n\nRemaining cells 7431\n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats once more.\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'], jitter=0.4, groupby = 'sample', rotation = 45)\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis. In this case we will also remove the HB genes.\n\nmalat1 = adata.var_names.str.startswith('MALAT1')\n# we need to redefine the mito_genes since they were first \n# calculated on the full object before removing low expressed genes.\nmito_genes = adata.var_names.str.startswith('MT-')\nhb_genes = adata.var_names.str.contains('^HB[^(P|E|S)]')\n\nremove = np.add(mito_genes, malat1)\nremove = np.add(remove, hb_genes)\nkeep = np.invert(remove)\n\nadata = adata[:,keep]\n\nprint(adata.n_obs, adata.n_vars)\n\n7431 19468"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_sex",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain your experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also be a good way to detect if there has been any mislabelling in which case, the sample metadata sex does not agree with the computational predictions.\nTo get choromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. Hence, we will use biomart to fetch chromosome information.\n\n# requires pybiomart\n\nannot_file = 'data/covid/results/gene_annotations_pybiomart.csv'\n\nif not os.path.exists(annot_file):\n    annot = sc.queries.biomart_annotations(\"hsapiens\", [\"ensembl_gene_id\", \"external_gene_name\", \"start_position\", \"end_position\", \"chromosome_name\"] ).set_index(\"external_gene_name\")\n    annot.to_csv(annot_file)\nelse:\n    annot = pd.read_csv(annot_file, index_col=0)\n\nNow that we have the chromosome information, we can calculate the proportion of reads that comes from chromosome Y per cell.But first we have to remove all genes in the pseudoautosmal regions of chrY that are: * chromosome:GRCh38:Y:10001 - 2781479 is shared with X: 10001 - 2781479 (PAR1) * chromosome:GRCh38:Y:56887903 - 57217415 is shared with X: 155701383 - 156030895 (PAR2)\n\nchrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"Y\"])\nchrY_genes\n\npar1 = [10001, 2781479]\npar2 = [56887903, 57217415]\n\npar1_genes = annot.index[(annot.chromosome_name == \"Y\") & (annot.start_position &gt; par1[0]) & (annot.start_position &lt; par1[1]) ]\n\npar2_genes = annot.index[(annot.chromosome_name == \"Y\") & (annot.start_position &gt; par2[0]) & (annot.start_position &lt; par2[1]) ]\n\nchrY_genes = chrY_genes.difference(par1_genes)\nchrY_genes = chrY_genes.difference(par2_genes)\n\nadata.obs['percent_chrY'] = np.sum(\n    adata[:, chrY_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\n# color inputs must be from either .obs or .var, so add in XIST expression to obs.\nadata.obs[\"XIST-counts\"] = adata.X[:,adata.var_names.str.match('XIST')].toarray()\n\nsc.pl.scatter(adata, x='XIST-counts', y='percent_chrY', color=\"sample\")\n\n\n\n\n\n\nPlot as violins.\n\nsc.pl.violin(adata, [\"XIST-counts\", \"percent_chrY\"], jitter=0.4, groupby = 'sample', rotation= 45)\n\n\n\n\n\n\nHere, we can see clearly that we have three males and five females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_cellcycle",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in the metadata, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\nFirst read the file with cell cycle genes, from Regev lab and split into S and G2M phase genes. We first download the file.\n\npath_file = os.path.join(path_results, 'regev_lab_cell_cycle_genes.txt')\nif not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"misc/regev_lab_cell_cycle_genes.txt\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\n\ncell_cycle_genes = [x.strip() for x in open('./data/covid/results/regev_lab_cell_cycle_genes.txt')]\nprint(len(cell_cycle_genes))\n\n# Split into 2 lists\ns_genes = cell_cycle_genes[:43]\ng2m_genes = cell_cycle_genes[43:]\n\ncell_cycle_genes = [x for x in cell_cycle_genes if x in adata.var_names]\nprint(len(cell_cycle_genes))\n\n97\n94\n\n\nBefore running cell cycle we have to normalize the data. In the scanpy object, the data slot will be overwritten with the normalized data. So first, save the raw data into the slot raw. Then run normalization, log transformation and scale the data.\n\n# save raw counts in raw slot.\nadata.raw = adata\n\n# normalize to depth 10 000\nsc.pp.normalize_total(adata, target_sum=1e4)\n\n# logaritmize\nsc.pp.log1p(adata)\n\n# scale\nsc.pp.scale(adata)\n\nnormalizing counts per cell\n    finished (0:00:00)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\n\n\nWe here perform cell cycle scoring. The function is actually a wrapper to sc.tl.score_gene_list, which is launched twice, to score separately S and G2M phases. Both sc.tl.score_gene_list and sc.tl.score_cell_cycle_genes are a port from Seurat and are supposed to work in a very similar way. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in data, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\nsc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n\ncalculating cell cycle phase\ncomputing score 'S_score'\nWARNING: genes are not in var_names and ignored: Index(['MLF1IP'], dtype='object')\n    finished: added\n    'S_score', score of gene set (adata.obs).\n    688 total control genes are used. (0:00:00)\ncomputing score 'G2M_score'\nWARNING: genes are not in var_names and ignored: Index(['FAM64A', 'HN1'], dtype='object')\n    finished: added\n    'G2M_score', score of gene set (adata.obs).\n    815 total control genes are used. (0:00:00)\n--&gt;     'phase', cell cycle phase (adata.obs)\n\n\nWe can now create a violin plot for the cell cycle scores as well.\n\nsc.pl.violin(adata, ['S_score', 'G2M_score'], jitter=0.4, groupby = 'sample', rotation=45)\n\n\n\n\n\n\nIn this case it looks like we only have a few cycling cells in these datasets.\nScanpy does an automatic prediction of cell cycle phase with a default cutoff of the scores at zero. As you can see this does not fit this data very well, so be cautios with using these predictions. Instead we suggest that you look at the scores.\n\nsc.pl.scatter(adata, x='S_score', y='G2M_score', color=\"phase\")"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_doublet",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\nFor doublet detection, we will use the package Scrublet, so first we need to get the raw counts from adata.raw.X and run scrublet with that matrix. Then we add in the doublet prediction info into our anndata object.\nDoublet prediction should be run for each dataset separately, so first we need to split the adata object into 6 separate objects, one per sample and then run scrublet on each of them.\n\nimport scrublet as scr\n\n# split per batch into new objects.\nbatches = adata.obs['sample'].cat.categories.tolist()\nalldata = {}\nfor batch in batches:\n    tmp = adata[adata.obs['sample'] == batch,]\n    print(batch, \":\", tmp.shape[0], \" cells\")\n    scrub = scr.Scrublet(tmp.raw.X)\n    out = scrub.scrub_doublets(verbose=False, n_prin_comps = 20)\n    alldata[batch] = pd.DataFrame({'doublet_score':out[0],'predicted_doublets':out[1]},index = tmp.obs.index)\n    print(alldata[batch].predicted_doublets.sum(), \" predicted_doublets\")\n\ncovid_1 : 900  cells\n12  predicted_doublets\ncovid_15 : 599  cells\n0  predicted_doublets\ncovid_16 : 373  cells\n2  predicted_doublets\ncovid_17 : 1101  cells\n11  predicted_doublets\nctrl_5 : 1052  cells\n13  predicted_doublets\nctrl_13 : 1173  cells\n19  predicted_doublets\nctrl_14 : 1063  cells\n24  predicted_doublets\nctrl_19 : 1170  cells\n18  predicted_doublets\n\n\n\n# add predictions to the adata object.\nscrub_pred = pd.concat(alldata.values())\nadata.obs['doublet_scores'] = scrub_pred['doublet_score'] \nadata.obs['predicted_doublets'] = scrub_pred['predicted_doublets'] \n\nsum(adata.obs['predicted_doublets'])\n\n99\n\n\nWe should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.\n\n# add in column with singlet/doublet instead of True/Fals\n%matplotlib inline\n\nadata.obs['doublet_info'] = adata.obs[\"predicted_doublets\"].astype(str)\nsc.pl.violin(adata, 'n_genes_by_counts', jitter=0.4, groupby = 'doublet_info', rotation=45)\n\n\n\n\n\n\nNow, lets run PCA and UMAP and plot doublet scores onto UMAP to check the doublet predictions. We will go through these steps in more detail in the later exercises.\n\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\nadata = adata[:, adata.var.highly_variable]\nsc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\nsc.pp.scale(adata, max_value=10)\nsc.tl.pca(adata, svd_solver='arpack')\nsc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color=['doublet_scores','doublet_info','sample'])\n\nextracting highly variable genes\n    finished (0:00:01)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nregressing out ['total_counts', 'pct_counts_mt']\n    finished (0:00:17)\ncomputing PCA\n    with n_comps=50\n    finished (0:00:06)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 40\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:07)\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\n# also revert back to the raw counts as the main matrix in adata\nadata = adata.raw.to_adata() \n\nadata = adata[adata.obs['doublet_info'] == 'False',:]\nprint(adata.shape)\n\n(7332, 19468)\n\n\nTo summarize, lets check how many cells we have removed per sample, we started with 1500 cells per sample. Looking back at the intitial QC plots does it make sense that some samples have much fewer cells now?\n#| label: view-data\nadata.obs[\"sample\"].value_counts()\n\n\n\n\n\n\nDiscuss\n\n\n\n“In this case we ran doublet detection with all samples together since we have very small subsampled datasets. But in a real scenario it should be run one sample at a time. Why is this important do you think?”"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-qc_save",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory data/covid/results and save data to that folder. This will be used in downstream labs.\n\nadata.write_h5ad('data/covid/results/scanpy_covid_qc.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_01_qc.html#meta-session",
    "href": "labs/scanpy/scanpy_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nannoy               NA\nasttokens           NA\ncffi                1.17.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nh5py                3.12.1\nigraph              0.11.6\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlazy_loader         0.4\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npatsy               1.0.1\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nscipy               1.14.1\nscrublet            NA\nseaborn             0.13.2\nsession_info        1.0.0\nsix                 1.17.0\nskimage             0.25.0\nsklearn             1.6.1\nsparse              0.15.5\nstack_data          0.6.3\nstatsmodels         0.14.4\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\nzstandard           0.23.0\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:16"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html",
    "href": "labs/bioc/bioc_01_qc.html",
    "title": " Quality Control",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_data",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_data",
    "title": " Quality Control",
    "section": "1 Get data",
    "text": "1 Get data\nIn this tutorial, we will run all tutorials with a set of 8 PBMC 10x datasets from 4 covid-19 patients and 4 healthy controls, the samples have been subsampled to 1500 cells per sample. We can start by defining our paths.\n\n# download pre-computed annotation\nfetch_annotation &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_covid &lt;- \"./data/covid/raw\"\nif (!dir.exists(path_covid)) dir.create(path_covid, recursive = T)\n\npath_results &lt;- \"./data/covid/results\"\nif (!dir.exists(path_results)) dir.create(path_results, recursive = T)\n\n\nfile_list &lt;- c(\n    \"normal_pbmc_13.h5\", \"normal_pbmc_14.h5\", \"normal_pbmc_19.h5\", \"normal_pbmc_5.h5\",\n    \"ncov_pbmc_15.h5\", \"ncov_pbmc_16.h5\", \"ncov_pbmc_17.h5\", \"ncov_pbmc_1.h5\"\n)\n\nfor (i in file_list) {\n    path_file &lt;- file.path(path_covid, i)\n    if (!file.exists(path_file)) {\n        download.file(url = file.path(file.path(path_data, \"covid/raw\"), i), \n                      destfile = path_file, method = \"curl\", extra = curl_upass)\n    }\n}\n\nWith data in place, now we can start loading libraries we will use in this tutorial.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork) # combining figures\n    library(org.Hs.eg.db)\n    library(scDblFinder)\n})\n\nWe can first load the data individually by reading directly from HDF5 file format (.h5).\n\ncov.15 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_15.h5\"),\n    use.names = T\n)\ncov.1 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_1.h5\"),\n    use.names = T\n)\ncov.16 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_16.h5\"),\n    use.names = T\n)\ncov.17 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"ncov_pbmc_17.h5\"),\n    use.names = T\n)\n\nctrl.5 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_5.h5\"),\n    use.names = T\n)\nctrl.13 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_13.h5\"),\n    use.names = T\n)\nctrl.14 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_14.h5\"),\n    use.names = T\n)\nctrl.19 &lt;- Seurat::Read10X_h5(\n    filename = file.path(path_covid, \"normal_pbmc_19.h5\"),\n    use.names = T\n)"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_collate",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_collate",
    "title": " Quality Control",
    "section": "2 Collate",
    "text": "2 Collate\nWe can now merge them objects into a single object. Each analysis workflow (Seurat, Scater, Scanpy, etc) has its own way of storing data. We will add dataset labels as cell.ids just in case you have overlapping barcodes between the datasets. After that we add a column type in the metadata to define covid and ctrl samples.\n\nsce &lt;- SingleCellExperiment(assays = list(counts = cbind(cov.1, cov.15, cov.16, cov.17, ctrl.5, ctrl.13, ctrl.14,ctrl.19)))\ndim(sce)\n\n[1] 33538 12000\n\n# Adding metadata\nsce@colData$sample &lt;- unlist(sapply(c(\"cov.1\", \"cov.15\", \"cov.16\", \"cov.17\", \"ctrl.5\", \"ctrl.13\", \"ctrl.14\",\"ctrl.19\"), function(x) rep(x, ncol(get(x)))))\nsce@colData$type &lt;- ifelse(grepl(\"cov\", sce@colData$sample), \"Covid\", \"Control\")\n\nOnce you have created the merged Seurat object, the count matrices and individual count matrices and objects are not needed anymore. It is a good idea to remove them and run garbage collect to free up some memory.\n\n# remove all objects that will not be used.\nrm(cov.15, cov.1, cov.17, cov.16, ctrl.5, ctrl.13, ctrl.14, ctrl.19)\n# run garbage collect to free up memory\ngc()\n\n           used  (Mb) gc trigger  (Mb)  max used  (Mb)\nNcells 11938606 637.6   17315390 924.8  16951466 905.4\nVcells 47505463 362.5  119270751 910.0 119024704 908.1\n\n\nHere is how the count matrix and the metadata look like for every cell.\n\nhead(counts(sce)[, 1:10])\n\n6 x 10 sparse Matrix of class \"dgCMatrix\"\n\n\n                               \nMIR1302-2HG . . . . . . . . . .\nFAM138A     . . . . . . . . . .\nOR4F5       . . . . . . . . . .\nAL627309.1  . . . . . . . . . .\nAL627309.3  . . . . . . . . . .\nAL627309.2  . . . . . . . . . .\n\nhead(sce@colData, 10)\n\nDataFrame with 10 rows and 2 columns\n                        sample        type\n                   &lt;character&gt; &lt;character&gt;\nAGGTAGGTCGTTGTTT-1       cov.1       Covid\nTAGAGTCGTCCTCCAT-1       cov.1       Covid\nCCCTGATAGCGAACTG-1       cov.1       Covid\nTCATCATTCCACGTAA-1       cov.1       Covid\nATTTACCCAAGCCTGC-1       cov.1       Covid\nGTTGTCCTCTAGAACC-1       cov.1       Covid\nCCTCCAACAAGAGATT-1       cov.1       Covid\nAATAGAGGTGTGAGCA-1       cov.1       Covid\nGGTGGCTAGCGAATGC-1       cov.1       Covid\nTCGGGCACAGTGTGGA-1       cov.1       Covid"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_calqc",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_calqc",
    "title": " Quality Control",
    "section": "3 Calculate QC",
    "text": "3 Calculate QC\nHaving the data in a suitable format, we can start calculating some quality metrics. We can for example calculate the percentage of mitochondrial and ribosomal genes per cell and add to the metadata. The proportion of hemoglobin genes can give an indication of red blood cell contamination, but in some tissues it can also be the case that some celltypes have higher content of hemoglobin. This will be helpful to visualize them across different metadata parameters (i.e. datasetID and chemistry version). There are several ways of doing this. The QC metrics are finally added to the metadata table.\nCiting from Simple Single Cell workflows (Lun, McCarthy & Marioni, 2017): High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane.\n\n# Mitochondrial genes\nmito_genes &lt;- rownames(sce)[grep(\"^MT-\", rownames(sce))]\n# Ribosomal genes\nribo_genes &lt;- rownames(sce)[grep(\"^RP[SL]\", rownames(sce))]\n# Hemoglobin genes - includes all genes starting with HB except HBP.\nhb_genes &lt;- rownames(sce)[grep(\"^HB[^(P|E|S)]\", rownames(sce))]\n\nFirst, let Scran calculate some general qc-stats for genes and cells with the function perCellQCMetrics. It can also calculate proportion of counts for specific gene subsets, so first we need to define which genes are mitochondrial, ribosomal and hemoglobin.\n\nsce &lt;- addPerCellQC(sce, flatten = T, subsets = list(mt = mito_genes, hb = hb_genes, ribo = ribo_genes))\n\n# Way2: Doing it manually\nsce@colData$percent_mito &lt;- Matrix::colSums(counts(sce)[mito_genes, ]) / sce@colData$total * 100\n\nNow you can see that we have additional data in the metadata slot.\n\nhead(colData(sce))\n\nDataFrame with 6 rows and 15 columns\n                        sample        type       sum  detected subsets_mt_sum\n                   &lt;character&gt; &lt;character&gt; &lt;numeric&gt; &lt;integer&gt;      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1       cov.1       Covid      1396       656             26\nTAGAGTCGTCCTCCAT-1       cov.1       Covid      1613       779            186\nCCCTGATAGCGAACTG-1       cov.1       Covid      9482      2036            761\nTCATCATTCCACGTAA-1       cov.1       Covid      4357       875           2960\nATTTACCCAAGCCTGC-1       cov.1       Covid     12466      3290            686\nGTTGTCCTCTAGAACC-1       cov.1       Covid      5541      1606            707\n                   subsets_mt_detected subsets_mt_percent subsets_hb_sum\n                             &lt;integer&gt;          &lt;numeric&gt;      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                   8            1.86246              1\nTAGAGTCGTCCTCCAT-1                  10           11.53131              0\nCCCTGATAGCGAACTG-1                  11            8.02573              3\nTCATCATTCCACGTAA-1                  13           67.93665              2\nATTTACCCAAGCCTGC-1                  12            5.50297              1\nGTTGTCCTCTAGAACC-1                  12           12.75943              3\n                   subsets_hb_detected subsets_hb_percent subsets_ribo_sum\n                             &lt;integer&gt;          &lt;numeric&gt;        &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                   1         0.07163324               11\nTAGAGTCGTCCTCCAT-1                   0         0.00000000               96\nCCCTGATAGCGAACTG-1                   1         0.03163889             4157\nTCATCATTCCACGTAA-1                   2         0.04590314               99\nATTTACCCAAGCCTGC-1                   1         0.00802182             2281\nGTTGTCCTCTAGAACC-1                   2         0.05414185             1664\n                   subsets_ribo_detected subsets_ribo_percent     total\n                               &lt;integer&gt;            &lt;numeric&gt; &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1                     9             0.787966      1396\nTAGAGTCGTCCTCCAT-1                    45             5.951643      1613\nCCCTGATAGCGAACTG-1                    85            43.840962      9482\nTCATCATTCCACGTAA-1                    52             2.272206      4357\nATTTACCCAAGCCTGC-1                    82            18.297770     12466\nGTTGTCCTCTAGAACC-1                    80            30.030680      5541\n                   percent_mito\n                      &lt;numeric&gt;\nAGGTAGGTCGTTGTTT-1      1.86246\nTAGAGTCGTCCTCCAT-1     11.53131\nCCCTGATAGCGAACTG-1      8.02573\nTCATCATTCCACGTAA-1     67.93665\nATTTACCCAAGCCTGC-1      5.50297\nGTTGTCCTCTAGAACC-1     12.75943"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_plotqc",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_plotqc",
    "title": " Quality Control",
    "section": "4 Plot QC",
    "text": "4 Plot QC\nNow we can plot some of the QC variables as violin plots.\n\n# total is total UMIs per cell\n# detected is number of detected genes.\n# the different gene subset percentages are listed as subsets_mt_percent etc.\n\nwrap_plots(\n    plotColData(sce, y = \"detected\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"total\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLooking at the violin plots, what do you think are appropriate cutoffs for filtering these samples\n\n\nAs you can see, there is quite some difference in quality for these samples, with for instance the covid_15 and covid_16 samples having cells with fewer detected genes and more mitochondrial content. As the ribosomal proteins are highly expressed they will make up a larger proportion of the transcriptional landscape when fewer of the lowly expressed genes are detected. We can also plot the different QC-measures as scatter plots.\n\nplotColData(sce, x = \"total\", y = \"detected\", colour_by = \"sample\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nPlot additional QC stats that we have calculated as scatter plots. How are the different measures correlated? Can you explain why?"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_filter",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_filter",
    "title": " Quality Control",
    "section": "5 Filtering",
    "text": "5 Filtering\n\n5.1 Detection-based filtering\nA standard approach is to filter cells with low number of reads as well as genes that are present in at least a given number of cells. Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells. Please note that those values are highly dependent on the library preparation method used.\nIn Scran, we can use the function quickPerCellQC to filter out outliers from distributions of qc stats, such as detected genes, gene subsets etc. But in this case, we will take one setting at a time and run through the steps of filtering cells.\n\ndim(sce)\n\n[1] 33538 12000\n\nselected_c &lt;- colnames(sce)[sce$detected &gt; 200]\nselected_f &lt;- rownames(sce)[Matrix::rowSums(counts(sce)) &gt; 3]\n\nsce.filt &lt;- sce[selected_f, selected_c]\ndim(sce.filt)\n\n[1] 18877 10656\n\n\nExtremely high number of detected genes could indicate doublets. However, depending on the cell type composition in your sample, you may have cells with higher number of genes (and also higher counts) from one cell type. In this case, we will run doublet prediction further down, so we will skip this step now, but the code below is an example of how it can be run:\n\n# skip for now and run doublet detection instead...\n\n# high.det.v3 &lt;- sce.filt$nFeatures &gt; 4100\n# high.det.v2 &lt;- (sce.filt$nFeatures &gt; 2000) & (sce.filt$sample_id == \"v2.1k\")\n\n# remove these cells\n# sce.filt &lt;- sce.filt[ , (!high.det.v3) & (!high.det.v2)]\n\n# check number of cells\n# ncol(sce.filt)\n\nAdditionally, we can also see which genes contribute the most to such reads. We can for instance plot the percentage of counts per gene.\nIn Scater, you can also use the function plotHighestExprs() to plot the gene contribution, but the function is quite slow, so we will do it on our own instead..\n\n# Compute the relative expression of each gene per cell\n# Use sparse matrix operations, if your dataset is large, doing matrix devisions the regular way will take a very long time.\nC &lt;- counts(sce.filt)\nC@x &lt;- C@x / rep.int(colSums(C), diff(C@p)) * 100\nmost_expressed &lt;- order(Matrix::rowSums(C), decreasing = T)[20:1]\nboxplot(as.matrix(t(C[most_expressed, ])), cex = .1, las = 1, xlab = \"% total count per cell\", col = scales::hue_pal()(20)[20:1], horizontal = TRUE)\n\n\n\n\n\n\n\nrm(C)\n\n# also, there is the option of running the function \"plotHighestExprs\" in the scater package, however, this function takes very long to execute.\n\nAs you can see, MALAT1 constitutes up to 30% of the UMIs from a single cell and the other top genes are mitochondrial and ribosomal genes. It is quite common that nuclear lincRNAs have correlation with quality and mitochondrial reads, so high detection of MALAT1 may be a technical issue. Let us assemble some information about such genes, which are important for quality control and downstream filtering.\n\n\n5.2 Mito/Ribo filtering\nWe also have quite a lot of cells with high proportion of mitochondrial and low proportion of ribosomal reads. It would be wise to remove those cells, if we have enough cells left after filtering. Another option would be to either remove all mitochondrial reads from the dataset and hope that the remaining genes still have enough biological signal. A third option would be to just regress out the percent_mito variable during scaling. In this case we had as much as 99.7% mitochondrial reads in some of the cells, so it is quite unlikely that there is much cell type signature left in those. Looking at the plots, make reasonable decisions on where to draw the cutoff. In this case, the bulk of the cells are below 20% mitochondrial reads and that will be used as a cutoff. We will also remove cells with less than 5% ribosomal reads.\n\nselected_mito &lt;- sce.filt$subsets_mt_percent &lt; 20\nselected_ribo &lt;- sce.filt$subsets_ribo_percent &gt; 5\n\n# and subset the object to only keep those cells\nsce.filt &lt;- sce.filt[, selected_mito & selected_ribo]\ndim(sce.filt)\n\n[1] 18877  7431\n\n\nAs you can see, a large proportion of sample covid_15 is filtered out. Also, there is still quite a lot of variation in percent_mito, so it will have to be dealt with in the data analysis step. We can also notice that the percent_ribo are also highly variable, but that is expected since different cell types have different proportions of ribosomal content, according to their function.\n\n\n5.3 Plot filtered QC\nLets plot the same QC-stats once more.\n\nwrap_plots(\n    plotColData(sce, y = \"detected\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"total\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n5.4 Filter genes\nAs the level of expression of mitochondrial and MALAT1 genes are judged as mainly technical, it can be wise to remove them from the dataset before any further analysis. In this case we will also remove the HB genes.\n\ndim(sce.filt)\n\n[1] 18877  7431\n\n# Filter MALAT1\nsce.filt &lt;- sce.filt[!grepl(\"MALAT1\", rownames(sce.filt)), ]\n\n# Filter Mitocondrial\nsce.filt &lt;- sce.filt[!grepl(\"^MT-\", rownames(sce.filt)), ]\n\n# Filter Ribossomal gene (optional if that is a problem on your data)\n# sce.filt &lt;- sce.filt[ ! grepl(\"^RP[SL]\", rownames(sce.filt)), ]\n\n# Filter Hemoglobin gene  (optional if that is a problem on your data)\nsce.filt &lt;- sce.filt[!grepl(\"^HB[^(P|E|S)]\", rownames(sce.filt)), ]\n\ndim(sce.filt)\n\n[1] 18854  7431"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_sex",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_sex",
    "title": " Quality Control",
    "section": "6 Sample sex",
    "text": "6 Sample sex\nWhen working with human or animal samples, you should ideally constrain your experiments to a single sex to avoid including sex bias in the conclusions. However this may not always be possible. By looking at reads from chromosomeY (males) and XIST (X-inactive specific transcript) expression (mainly female) it is quite easy to determine per sample which sex it is. It can also be a good way to detect if there has been any mislabelling in which case, the sample metadata sex does not agree with the computational predictions.\nTo get chromosome information for all genes, you should ideally parse the information from the gtf file that you used in the mapping pipeline as it has the exact same annotation version/gene naming. However, it may not always be available, as in this case where we have downloaded public data. R package biomaRt can be used to fetch annotation information. The code to run biomaRt is provided. As the biomart instances are quite often unresponsive, we will download and use a file that was created in advance.\n\n\n\n\n\n\nTip\n\n\n\n\n\nHere is the code to download annotation data from Ensembl using biomaRt. We will not run this now and instead use a pre-computed file in the step below.\n\n# fetch_annotation is defined at the top of this document\nif (!fetch_annotation) {\n  suppressMessages(library(biomaRt))\n\n  # initialize connection to mart, may take some time if the sites are unresponsive.\n  mart &lt;- useMart(\"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n\n  # fetch chromosome info plus some other annotations\n  genes_table &lt;- try(biomaRt::getBM(attributes = c(\n    \"ensembl_gene_id\", \"external_gene_name\",\n    \"description\", \"gene_biotype\", \"chromosome_name\", \"start_position\"\n  ), mart = mart, useCache = F))\n\n  write.csv(genes_table, file = \"data/covid/results/genes_table.csv\")\n}\n\n\n\n\nDownload precomputed data.\n\n# fetch_annotation is defined at the top of this document\nif (fetch_annotation) {\n  genes_file &lt;- file.path(path_results, \"genes_table.csv\")\n  if (!file.exists(genes_file)) download.file(file.path(path_data, \"covid/results_bioc/genes_table.csv\"), destfile = genes_file,\n                                              method = \"curl\", extra = curl_upass)\n}\n\n\ngenes.table &lt;- read.csv(genes_file)\ngenes.table &lt;- genes.table[genes.table$external_gene_name %in% rownames(sce.filt), ]\n\nNow that we have the chromosome information, we can calculate the proportion of reads that comes from chromosome Y per cell.But first we have to remove all genes in the pseudoautosmal regions of chrY that are: * chromosome:GRCh38:Y:10001 - 2781479 is shared with X: 10001 - 2781479 (PAR1) * chromosome:GRCh38:Y:56887903 - 57217415 is shared with X: 155701383 - 156030895 (PAR2)\n\npar1 = c(10001, 2781479)\npar2 = c(56887903, 57217415)\np1.gene = genes.table$external_gene_name[genes.table$start_position &gt; par1[1] & genes.table$start_position &lt; par1[2] & genes.table$chromosome_name == \"Y\"]\np2.gene = genes.table$external_gene_name[genes.table$start_position &gt; par2[1] & genes.table$start_position &lt; par2[2] & genes.table$chromosome_name == \"Y\"]\n\nchrY.gene &lt;- genes.table$external_gene_name[genes.table$chromosome_name == \"Y\"]\nchrY.gene = setdiff(chrY.gene, c(p1.gene, p2.gene))\n\nsce.filt@colData$pct_chrY &lt;- Matrix::colSums(counts(sce.filt)[chrY.gene, ]) / colSums(counts(sce.filt))\n\nThen plot XIST expression vs chrY proportion. As you can see, the samples are clearly on either side, even if some cells do not have detection of either.\n\n# as plotColData cannot take an expression vs metadata, we need to add in XIST expression to colData\nsce.filt@colData$XIST &lt;- counts(sce.filt)[\"XIST\", ] / colSums(counts(sce.filt)) * 10000\nplotColData(sce.filt, \"XIST\", \"pct_chrY\")\n\n\n\n\n\n\n\n\nPlot as violins.\n\nwrap_plots(\n    plotColData(sce.filt, y = \"XIST\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"pct_chrY\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 2\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHere, we can see clearly that we have three males and five females, can you see which samples they are? Do you think this will cause any problems for downstream analysis? Discuss with your group: what would be the best way to deal with this type of sex bias?"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_cellcycle",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_cellcycle",
    "title": " Quality Control",
    "section": "7 Cell cycle state",
    "text": "7 Cell cycle state\nWe here perform cell cycle scoring. To score a gene list, the algorithm calculates the difference of mean expression of the given list and the mean expression of reference genes. To build the reference, the function randomly chooses a bunch of genes matching the distribution of the expression of the given list. Cell cycle scoring adds three slots in the metadata, a score for S phase, a score for G2M phase and the predicted cell cycle phase.\n\nhs.pairs &lt;- readRDS(system.file(\"exdata\", \"human_cycle_markers.rds\", package = \"scran\"))\nanno &lt;- select(org.Hs.eg.db, keys = rownames(sce.filt), keytype = \"SYMBOL\", column = \"ENSEMBL\")\nensembl &lt;- anno$ENSEMBL[match(rownames(sce.filt), anno$SYMBOL)]\n\n# Use only genes related to biological process cell cycle to speed up\n# https://www.ebi.ac.uk/QuickGO/term/GO:0007049 = cell cycle (BP,Biological Process)\nGOs &lt;- na.omit(select(org.Hs.eg.db, keys = na.omit(ensembl), keytype = \"ENSEMBL\", column = \"GO\"))\nGOs &lt;- GOs[GOs$GO == \"GO:0007049\", \"ENSEMBL\"]\nhs.pairs &lt;- lapply(hs.pairs, function(x) {\n    x[rowSums(apply(x, 2, function(i) i %in% GOs)) &gt;= 1, ]\n})\nstr(hs.pairs)\n\nList of 3\n $ G1 :'data.frame':    6633 obs. of  2 variables:\n  ..$ first : chr [1:6633] \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" ...\n  ..$ second: chr [1:6633] \"ENSG00000065135\" \"ENSG00000080345\" \"ENSG00000101266\" \"ENSG00000135679\" ...\n $ S  :'data.frame':    8308 obs. of  2 variables:\n  ..$ first : chr [1:8308] \"ENSG00000255302\" \"ENSG00000119969\" \"ENSG00000179051\" \"ENSG00000127586\" ...\n  ..$ second: chr [1:8308] \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000100519\" \"ENSG00000136856\" ...\n $ G2M:'data.frame':    6235 obs. of  2 variables:\n  ..$ first : chr [1:6235] \"ENSG00000100519\" \"ENSG00000136856\" \"ENSG00000136856\" \"ENSG00000136856\" ...\n  ..$ second: chr [1:6235] \"ENSG00000146457\" \"ENSG00000138028\" \"ENSG00000227268\" \"ENSG00000101265\" ...\n\ncc.ensembl &lt;- ensembl[ensembl %in% GOs] # This is the fastest (less genes), but less accurate too\n# cc.ensembl &lt;- ensembl[ ensembl %in% unique(unlist(hs.pairs))]\n\nassignments &lt;- cyclone(sce.filt[ensembl %in% cc.ensembl, ], hs.pairs, gene.names = ensembl[ensembl %in% cc.ensembl])\nsce.filt$G1.score &lt;- assignments$scores$G1\nsce.filt$G2M.score &lt;- assignments$scores$G2M\nsce.filt$S.score &lt;- assignments$scores$S\nsce.filt$phase &lt;- assignments$phases\n\ntable(sce.filt$phase)\n\n\n  G1  G2M    S \n4337  828 1746 \n\n\nWe can now create a violin plot for the cell cycle scores as well.\n\nwrap_plots(\n    plotColData(sce.filt, y = \"G2M.score\", x = \"G1.score\", colour_by = \"phase\"),\n    plotColData(sce.filt, y = \"G2M.score\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"G1.score\", x = \"sample\", colour_by = \"sample\"),\n    plotColData(sce.filt, y = \"S.score\", x = \"sample\", colour_by = \"sample\"),\n    ncol = 4\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nCyclone predicts most cells as G1, but also quite a lot of cells with high S-Phase scores. Compare to results with Seurat and Scanpy and see how different predictors will give clearly different results.\nCyclone does an automatic prediction of cell cycle phase with a default cutoff of the scores at 0.5 As you can see this does not fit this data very well, so be cautious with using these predictions. Instead we suggest that you look at the scores."
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_doublet",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_doublet",
    "title": " Quality Control",
    "section": "8 Predict doublets",
    "text": "8 Predict doublets\nDoublets/Multiples of cells in the same well/droplet is a common issue in scRNAseq protocols. Especially in droplet-based methods with overloading of cells. In a typical 10x experiment the proportion of doublets is linearly dependent on the amount of loaded cells. As indicated from the Chromium user guide, doublet rates are about as follows:\n\nMost doublet detectors simulates doublets by merging cell counts and predicts doublets as cells that have similar embeddings as the simulated doublets. Most such packages need an assumption about the number/proportion of expected doublets in the dataset. The data you are using is subsampled, but the original datasets contained about 5 000 cells per sample, hence we can assume that they loaded about 9 000 cells and should have a doublet rate at about 4%.\n\n\n\n\n\n\nCaution\n\n\n\nIdeally doublet prediction should be run on each sample separately, especially if your samples have different proportions of cell types. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs, so it is okay to run them together.\n\n\nThere is a method to predict if a cluster consists of mainly doublets findDoubletClusters(), but we can also predict individual cells based on simulations using the function computeDoubletDensity() which we will do here. Doublet detection will be performed using PCA, so we need to first normalize the data and run variable gene detection, as well as UMAP for visualization. These steps will be explored in more detail in coming exercises.\n\nsce.filt &lt;- logNormCounts(sce.filt)\ndec &lt;- modelGeneVar(sce.filt, block = sce.filt$sample)\nhvgs &lt;- getTopHVGs(dec, n = 2000)\n\nsce.filt &lt;- runPCA(sce.filt, subset_row = hvgs)\n\nsce.filt &lt;- runUMAP(sce.filt, pca = 10)\n\n\n# run computeDoubletDensity with 10 principal components.\nsce.filt &lt;- scDblFinder(sce.filt, dims = 10)\n\n\nwrap_plots(\n    plotUMAP(sce.filt, colour_by = \"scDblFinder.score\"),\n    plotUMAP(sce.filt, colour_by = \"scDblFinder.class\"),\n    plotUMAP(sce.filt, colour_by = \"sample\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe should expect that two cells have more detected genes than a single cell, lets check if our predicted doublets also have more detected genes in general.\n\nplotColData(sce.filt, y = \"detected\", x = \"scDblFinder.class\")\n\n\n\n\n\n\n\n\nNow, lets remove all predicted doublets from our data.\n\nsce.filt &lt;- sce.filt[, sce.filt$scDblFinder.class == \"singlet\"]\ndim(sce.filt)\n\n[1] 18854  6924\n\n\nTo summarize, lets check how many cells we have removed per sample, we started with 1500 cells per sample. Looking back at the intitial QC plots does it make sense that some samples have much fewer cells now?\n\ntable(sce$sample)\n\n\n  cov.1  cov.15  cov.16  cov.17 ctrl.13 ctrl.14 ctrl.19  ctrl.5 \n   1500    1500    1500    1500    1500    1500    1500    1500 \n\ntable(sce.filt$sample)\n\n\n  cov.1  cov.15  cov.16  cov.17 ctrl.13 ctrl.14 ctrl.19  ctrl.5 \n    836     538     355    1062    1111     952    1086     984 \n\n\n\n\n\n\n\n\nDiscuss\n\n\n\n“In this case we ran doublet detection with all samples together since we have very small subsampled datasets. But in a real scenario it should be run one sample at a time. Why is this important do you think?”"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-qc_save",
    "href": "labs/bioc/bioc_01_qc.html#meta-qc_save",
    "title": " Quality Control",
    "section": "9 Save data",
    "text": "9 Save data\nFinally, lets save the QC-filtered data for further analysis. Create output directory data/covid/results and save data to that folder. This will be used in downstream labs.\n\nsaveRDS(sce.filt, file.path(path_results, \"bioc_covid_qc.rds\"))"
  },
  {
    "objectID": "labs/bioc/bioc_01_qc.html#meta-session",
    "href": "labs/bioc/bioc_01_qc.html#meta-session",
    "title": " Quality Control",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] scDblFinder_1.16.0          org.Hs.eg.db_3.18.0        \n [3] AnnotationDbi_1.64.1        patchwork_1.3.0            \n [5] scran_1.30.0                scater_1.30.1              \n [7] ggplot2_3.5.1               scuttle_1.12.0             \n [9] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n[11] Biobase_2.62.0              GenomicRanges_1.54.1       \n[13] GenomeInfoDb_1.38.1         IRanges_2.36.0             \n[15] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[17] MatrixGenerics_1.14.0       matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.22          splines_4.3.3            \n  [3] later_1.4.1               BiocIO_1.12.0            \n  [5] bitops_1.0-9              tibble_3.2.1             \n  [7] polyclip_1.10-7           XML_3.99-0.17            \n  [9] fastDummies_1.7.5         lifecycle_1.0.4          \n [11] edgeR_4.0.16              hdf5r_1.3.11             \n [13] globals_0.16.3            lattice_0.22-6           \n [15] MASS_7.3-60.0.1           magrittr_2.0.3           \n [17] limma_3.58.1              plotly_4.10.4            \n [19] rmarkdown_2.29            yaml_2.3.10              \n [21] metapod_1.10.0            httpuv_1.6.15            \n [23] Seurat_5.1.0              sctransform_0.4.1        \n [25] spam_2.11-1               spatstat.sparse_3.1-0    \n [27] sp_2.2-0                  reticulate_1.40.0        \n [29] cowplot_1.1.3             pbapply_1.7-2            \n [31] DBI_1.2.3                 RColorBrewer_1.1-3       \n [33] abind_1.4-5               zlibbioc_1.48.0          \n [35] Rtsne_0.17                purrr_1.0.2              \n [37] RCurl_1.98-1.16           GenomeInfoDbData_1.2.11  \n [39] ggrepel_0.9.6             irlba_2.3.5.1            \n [41] spatstat.utils_3.1-2      listenv_0.9.1            \n [43] goftest_1.2-3             RSpectra_0.16-2          \n [45] spatstat.random_3.3-2     dqrng_0.3.2              \n [47] fitdistrplus_1.2-2        parallelly_1.42.0        \n [49] DelayedMatrixStats_1.24.0 leiden_0.4.3.1           \n [51] codetools_0.2-20          DelayedArray_0.28.0      \n [53] tidyselect_1.2.1          farver_2.1.2             \n [55] ScaledMatrix_1.10.0       viridis_0.6.5            \n [57] spatstat.explore_3.3-4    GenomicAlignments_1.38.0 \n [59] jsonlite_1.8.9            BiocNeighbors_1.20.0     \n [61] progressr_0.15.1          ggridges_0.5.6           \n [63] survival_3.8-3            tools_4.3.3              \n [65] ica_1.0-3                 Rcpp_1.0.14              \n [67] glue_1.8.0                gridExtra_2.3            \n [69] SparseArray_1.2.2         xfun_0.50                \n [71] dplyr_1.1.4               withr_3.0.2              \n [73] fastmap_1.2.0             bluster_1.12.0           \n [75] digest_0.6.37             rsvd_1.0.5               \n [77] R6_2.6.1                  mime_0.12                \n [79] colorspace_2.1-1          scattermore_1.2          \n [81] tensor_1.5                spatstat.data_3.1-4      \n [83] RSQLite_2.3.9             tidyr_1.3.1              \n [85] generics_0.1.3            data.table_1.16.4        \n [87] rtracklayer_1.62.0        httr_1.4.7               \n [89] htmlwidgets_1.6.4         S4Arrays_1.2.0           \n [91] uwot_0.2.2                pkgconfig_2.0.3          \n [93] gtable_0.3.6              blob_1.2.4               \n [95] lmtest_0.9-40             XVector_0.42.0           \n [97] htmltools_0.5.8.1         dotCall64_1.2            \n [99] SeuratObject_5.0.2        scales_1.3.0             \n[101] png_0.1-8                 spatstat.univar_3.1-1    \n[103] knitr_1.49                reshape2_1.4.4           \n[105] rjson_0.2.23              nlme_3.1-167             \n[107] cachem_1.1.0              zoo_1.8-12               \n[109] stringr_1.5.1             KernSmooth_2.23-26       \n[111] parallel_4.3.3            miniUI_0.1.1.1           \n[113] vipor_0.4.7               restfulr_0.0.15          \n[115] pillar_1.10.1             grid_4.3.3               \n[117] vctrs_0.6.5               RANN_2.6.2               \n[119] promises_1.3.2            BiocSingular_1.18.0      \n[121] beachmat_2.18.0           xtable_1.8-4             \n[123] cluster_2.1.8             beeswarm_0.4.0           \n[125] evaluate_1.0.3            cli_3.6.4                \n[127] locfit_1.5-9.11           compiler_4.3.3           \n[129] Rsamtools_2.18.0          rlang_1.1.5              \n[131] crayon_1.5.3              future.apply_1.11.3      \n[133] labeling_0.4.3            plyr_1.8.9               \n[135] ggbeeswarm_0.7.2          stringi_1.8.4            \n[137] deldir_2.0-4              viridisLite_0.4.2        \n[139] BiocParallel_1.36.0       munsell_0.5.1            \n[141] Biostrings_2.70.1         lazyeval_0.2.2           \n[143] spatstat.geom_3.3-5       Matrix_1.6-5             \n[145] RcppHNSW_0.6.0            sparseMatrixStats_1.14.0 \n[147] bit64_4.5.2               future_1.34.0            \n[149] KEGGREST_1.42.0           statmod_1.5.0            \n[151] shiny_1.10.0              ROCR_1.0-11              \n[153] igraph_2.0.3              memoise_2.0.1            \n[155] bit_4.5.0.1               xgboost_2.1.4.1"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html",
    "href": "labs/scanpy/scanpy_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands."
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_prep",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport subprocess\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\n# sc.logging.print_versions()\n\nsc.settings.set_figure_params(dpi=80)\n\n\n# download pre-computed data if missing or long compute\nfetch_data = True\n\n# url for source and intermediate data\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc.h5ad\"\n# if fetch_data is false and path_file doesn't exist\n\nif fetch_data and not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"covid/results_scanpy/scanpy_covid_qc.h5ad\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 7332 × 19468\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'umap'\n    obsm: 'X_pca', 'X_umap'\n    obsp: 'connectivities', 'distances'\n\n\nBefore variable gene selection we need to normalize and log transform the data. Then store the full matrix in the raw slot before doing variable gene selection.\n\n# normalize to depth 10 000\nsc.pp.normalize_total(adata, target_sum=1e4)\n\n# log transform\nsc.pp.log1p(adata)\n\n# store normalized counts in the raw slot, \n# we will subset adata.X for variable genes, but want to keep all genes matrix as well.\nadata.raw = adata\n\nadata\n\nnormalizing counts per cell\n    finished (0:00:00)\nWARNING: adata.X seems to be already log-transformed.\n\n\nAnnData object with n_obs × n_vars = 7332 × 19468\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'umap'\n    obsm: 'X_pca', 'X_umap'\n    obsp: 'connectivities', 'distances'"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_fs",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nWe first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\n\n# compute variable genes\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\nprint(\"Highly variable genes: %d\"%sum(adata.var.highly_variable))\n\n#plot variable genes\nsc.pl.highly_variable_genes(adata)\n\n# subset for variable genes in the dataset\nadata = adata[:, adata.var['highly_variable']]\n\nextracting highly variable genes\n    finished (0:00:02)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes: 2656"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_zs",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the genes have been selected, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling called Z-score normalization is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria etc. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default, variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\n\n#run this line if you get the \"AttributeError: swapaxes not found\" \n# adata = adata.copy()\n\n# regress out unwanted variables\nsc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt'])\n\n# scale data, clip values exceeding standard deviation 10.\nsc.pp.scale(adata, max_value=10)\n\nregressing out ['total_counts', 'pct_counts_mt']\n    sparse input is densified and may lead to high memory use\n    finished (0:00:22)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_pca",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of single-cell data, we want to segregate samples based on gene expression patterns in the data.\nTo run PCA, you can use the function pca().\n\nsc.tl.pca(adata, svd_solver='arpack')\n\ncomputing PCA\n    with n_comps=50\n    finished (0:00:07)\n\n\nWe then plot the first principal components.\n\n# plot more PCS\nsc.pl.pca(adata, color='sample', components = ['1,2','3,4','5,6','7,8'], ncols=2)\n\n\n\n\n\n\nTo identify genes that contribute most to each PC, one can retrieve the loading matrix information.\n\n#Plot loadings\nsc.pl.pca_loadings(adata, components=[1,2,3,4,5,6,7,8])\n\n# OBS! only plots the positive axes genes from each PC!!\n\n\n\n\n\n\nThe function to plot loading genes only plots genes on the positive axes. Instead plot as a heatmaps, with genes on both positive and negative side, one per pc, and plot their expression amongst cells ordered by their position along the pc.\n\n# adata.obsm[\"X_pca\"] is the embeddings\n# adata.uns[\"pca\"] is pc variance\n# adata.varm['PCs'] is the loadings\n\ngenes = adata.var['gene_ids']\n\nfor pc in [1,2,3,4]:\n    g = adata.varm['PCs'][:,pc-1]\n    o = np.argsort(g)\n    sel = np.concatenate((o[:10],o[-10:])).tolist()\n    emb = adata.obsm['X_pca'][:,pc-1]\n    # order by position on that pc\n    tempdata = adata[np.argsort(emb),]\n    sc.pl.heatmap(tempdata, var_names = genes[sel].index.tolist(), groupby='predicted_doublets', swap_axes = True, use_raw=False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also plot the amount of variance explained by each PC.\n\nsc.pl.pca_variance_ratio(adata, log=True, n_pcs = 50)\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_tsne",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe will now run BH-tSNE.\n\nsc.tl.tsne(adata, n_pcs = 30)\n\ncomputing tSNE\n    using 'X_pca' with n_pcs = 30\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm)\n    'tsne', tSNE parameters (adata.uns) (0:00:12)\n\n\nWe plot the tSNE scatterplot colored by dataset. We can clearly see the effect of batches present in the dataset.\n\nsc.pl.tsne(adata, color='sample')"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_umap",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nThe UMAP implementation in SCANPY uses a neighborhood graph as the distance matrix, so we need to first calculate the graph.\n\nsc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20)\n\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\n\n\nWe can now run UMAP for cell embeddings.\n\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='sample')\n\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:09)\n\n\n\n\n\n\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\n# run with 10 components, save to a new object so that the umap with 2D is not overwritten.\numap10 = sc.tl.umap(adata, n_components=10, copy=True)\nfig, axs = plt.subplots(1, 3, figsize=(10, 4), constrained_layout=True)\n\nsc.pl.umap(adata, color='sample',  title=\"UMAP\",\n           show=False, ax=axs[0], legend_loc=None)\nsc.pl.umap(umap10, color='sample', title=\"UMAP10\", show=False,\n           ax=axs[1], components=['1,2'], legend_loc=None)\nsc.pl.umap(umap10, color='sample', title=\"UMAP10\",\n           show=False, ax=axs[2], components=['3,4'], legend_loc=None)\n\n# we can also plot the umap with neighbor edges\nsc.pl.umap(adata, color='sample', title=\"UMAP\", edges=True)\n\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:11)\n\n\n\n\n\n\n\n\n\n\n\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE. What similarities/differences do you see? Can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 8), constrained_layout=True)\nsc.pl.pca(adata, color='sample', components=['1,2'], ax=axs[0, 0], show=False)\nsc.pl.tsne(adata, color='sample', components=['1,2'], ax=axs[0, 1], show=False)\nsc.pl.umap(adata, color='sample', components=['1,2'], ax=axs[1, 0], show=False)\n\n&lt;Axes: title={'center': 'sample'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\nFinally, we can compare the PCA, tSNE and UMAP.\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "7 Genes of interest",
    "text": "7 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nsc.pl.umap(adata, color=[\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR3A\"])\n\n\n\n\n\n\nThe default is to plot gene expression in the normalized and log-transformed data. You can also plot it on the scaled and corrected data by using use_raw=False. However, not all of these genes are included in the variable gene set, and hence are not included in the scaled adata.X, so we first need to filter them.\n\ngenes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR3A\"]\nvar_genes = adata.var.highly_variable\nvar_genes.index[var_genes]\nvarg = [x for x in genes if x in var_genes.index[var_genes]]\nsc.pl.umap(adata, color=varg, use_raw=False)\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?\n\n\n\nsc.pl.umap(adata, color=['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_ribo', 'pct_counts_hb'], ncols=3,use_raw=False)"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_save",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "8 Save data",
    "text": "8 Save data\nWe can finally save the object for use in future steps.\n\nadata.write_h5ad('data/covid/results/scanpy_covid_qc_dr.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#note",
    "href": "labs/scanpy/scanpy_02_dimred.html#note",
    "title": " Dimensionality Reduction",
    "section": "9 Note",
    "text": "9 Note\nJust as a reminder, you need to keep in mind what you have in the X matrix. After these operations you have an X matrix with only variable genes, that are normalized, logtransformed and scaled.\nWe stored the expression of all genes in raw.X after doing lognormalization so that matrix is a sparse matrix with logtransformed values.\n\nprint(adata.X.shape)\nprint(adata.raw.X.shape)\n\nprint(adata.X[:3,:3])\nprint(adata.raw.X[:10,:10])\n\n(7332, 2656)\n(7332, 19468)\n[[-0.04097649 -0.04808595 -0.06951175]\n [-0.05810044 -0.11063513 -0.34450077]\n [-0.07079222 -0.13746446 -0.48150336]]\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 2 stored elements and shape (10, 10)&gt;\n  Coords    Values\n  (1, 4)    1.479703103222477\n  (8, 7)    1.6397408237842532"
  },
  {
    "objectID": "labs/scanpy/scanpy_02_dimred.html#meta-session",
    "href": "labs/scanpy/scanpy_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nasttokens           NA\ncffi                1.17.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nh5py                3.12.1\nigraph              0.11.6\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnetworkx            3.4\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npatsy               1.0.1\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nscipy               1.14.1\nsession_info        1.0.0\nsix                 1.17.0\nsklearn             1.6.1\nsparse              0.15.5\nstack_data          0.6.3\nstatsmodels         0.14.4\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:18"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html",
    "href": "labs/seurat/seurat_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_prep",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(ggplot2) # plotting\n    library(patchwork) # combining figures\n    library(scran)\n})\n\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/seurat_covid_qc.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_seurat/seurat_covid_qc.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nalldata &lt;- readRDS(path_file)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_fs",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nWe first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\n\nsuppressWarnings(suppressMessages(alldata &lt;- FindVariableFeatures(alldata, selection.method = \"vst\", nfeatures = 2000, verbose = FALSE, assay = \"RNA\")))\ntop20 &lt;- head(VariableFeatures(alldata), 20)\n\nLabelPoints(plot = VariableFeaturePlot(alldata), points = top20, repel = TRUE)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_zs",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the genes have been selected, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling called Z-score normalization is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria etc. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default, variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\n\nalldata &lt;- ScaleData(alldata, vars.to.regress = c(\"percent_mito\", \"nFeature_RNA\"), assay = \"RNA\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_pca",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of single-cell data, we want to segregate samples based on gene expression patterns in the data.\nTo run PCA, you can use the function RunPCA().\n\nalldata &lt;- RunPCA(alldata, npcs = 50, verbose = F)\n\nWe then plot the first principal components.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 1:2),\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 3:4),\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\", dims = 5:6),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nTo identify which genes (Seurat) or metadata parameters (Scater/Scran) contribute the most to each PC, one can retrieve the loading matrix information. Unfortunately, this is not implemented in Scater/Scran, so you will need to compute PCA using logcounts.\n\nVizDimLoadings(alldata, dims = 1:5, reduction = \"pca\", ncol = 5, balanced = T)\n\n\n\n\n\n\n\n\nWe can also plot the amount of variance explained by each PC.\n\nElbowPlot(alldata, reduction = \"pca\", ndims = 50)\n\n\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)\nWith the scater package we can check how different metadata variables contribute to each PCs. This can be important to look at to understand different biases you may have in your data.\n\nscater::plotExplanatoryPCs(as.SingleCellExperiment(alldata), nvars_to_plot = 15, npcs_to_plot = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the plot from plotExplanatoryPCs and the gene loadings plots. Do you think the top components are biologically relevant or more driven by technical noise"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_tsne",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe will now run BH-tSNE.\n\nalldata &lt;- RunTSNE(\n    alldata,\n    reduction = \"pca\", dims = 1:30,\n    perplexity = 30,\n    max_iter = 1000,\n    theta = 0.5,\n    eta = 200,\n    num_threads = 0\n)\n# see ?Rtsne and ?RunTSNE for more info\n\nWe plot the tSNE scatterplot colored by dataset. We can clearly see the effect of batches present in the dataset.\n\nDimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_umap",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nWe can now run UMAP for cell embeddings.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction = \"pca\",\n    dims = 1:30,\n    n.components = 2,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n# see ?RunUMAP for more info\n\nA feature of UMAP is that it is not limited by the number of dimensions the data cen be reduced into (unlike tSNE). We can simply reduce the dimentions altering the n.components parameter. So here we will create a UMAP with 10 dimensions.\nIn Seurat, we can add in additional reductions, by default they are named “pca”, “umap”, “tsne” etc. depending on the function you run. Here we will specify an alternative name for the umap with the reduction.name parameter.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction.name = \"UMAP10_on_PCA\",\n    reduction = \"pca\",\n    dims = 1:30,\n    n.components = 10,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n# see ?RunUMAP for more info\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    DimPlot(alldata, reduction = \"UMAP10_on_PCA\", group.by = \"orig.ident\", dims = 1:2) + ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    DimPlot(alldata, reduction = \"UMAP10_on_PCA\", group.by = \"orig.ident\", dims = 3:4) + ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE. What similarities/differences do you see? Can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\"),\n    DimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\"),\n    DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_zsg",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_zsg",
    "title": " Dimensionality Reduction",
    "section": "7 Z-scores & DR graphs",
    "text": "7 Z-scores & DR graphs\nAlthough running a second dimensionality reduction (i.e tSNE or UMAP) on PCA would be a standard approach (because it allows higher computation efficiency), the options are actually limitless. Below we will show a couple of other common options such as running directly on the scaled data (z-scores) (which was used for PCA) or on a graph built from scaled data. We will only work with UMAPs, but the same applies for tSNE.\n\n7.1 UMAP from z-scores\nTo run tSNE or UMAP on the scaled data, one first needs to select the number of variables to use. This is because including dimensions that do contribute to the separation of your cell types will in the end mask those differences. Another reason for it is because running with all genes/features also will take longer or might be computationally unfeasible. Therefore we will use the scaled data of the highly variable genes.\n\nalldata &lt;- RunUMAP(\n    alldata,\n    reduction.name = \"UMAP_on_ScaleData\",\n    features = VariableFeatures(alldata),\n    assay = \"RNA\",\n    n.components = 2,\n    n.neighbors = 30,\n    n.epochs = 200,\n    min.dist = 0.3,\n    learning.rate = 1,\n    spread = 1\n)\n\n\n\n7.2 UMAP from graph\nTo run tSNE or UMAP on the a graph, we first need to build a graph from the data. In fact, both tSNE and UMAP first build a graph from the data using a specified distance matrix and then optimize the embedding. Since a graph is just a matrix containing distances from cell to cell and as such, you can run either UMAP or tSNE using any other distance metric desired. Euclidean and Correlation are usually the most commonly used.\n\n#OBS! Skip for now, known issue with later version of umap-learn in Seurat5\n# have 0.5.7 now, tested downgrading to 0.5.4 or 0.5.3 but still have same error.\n# Seurat 5.2.0 has a fix for this, but not the version we have now.\n\n# Build Graph\nalldata &lt;- FindNeighbors(alldata,\n    reduction = \"pca\",\n    assay = \"RNA\",\n    k.param = 20,\n    features = VariableFeatures(alldata)\n)\n\nalldata &lt;- RunUMAP(alldata,\n    reduction.name = \"UMAP_on_Graph\",\n    umap.method = \"umap-learn\",\n    graph = \"RNA_snn\",\n    n.epochs = 200,\n    assay = \"RNA\"\n)\n\nWe can now plot the UMAP comparing both on PCA vs ScaledSata vs Graph.\n\np1 &lt;- DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_PCA\")\np2 &lt;- DimPlot(alldata, reduction = \"UMAP_on_ScaleData\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_ScaleData\")\n#p3 &lt;- DimPlot(alldata, reduction = \"UMAP_on_Graph\", group.by = \"orig.ident\") + ggplot2::ggtitle(label = \"UMAP_on_Graph\")\n#wrap_plots(p1, p2, p3, ncol = 3) + plot_layout(guides = \"collect\")\nwrap_plots(p1, p2, ncol = 2) + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "8 Genes of interest",
    "text": "8 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nmyfeatures &lt;- c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")\nFeaturePlot(alldata, reduction = \"umap\", dims = 1:2, features = myfeatures, ncol = 4, order = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?\n\n\n\nmyfeatures &lt;- c(\"nCount_RNA\",\"nFeature_RNA\", \"percent_mito\",\"percent_ribo\",\"percent_hb\",\"percent_plat\")\nFeaturePlot(alldata, reduction = \"umap\", dims = 1:2, features = myfeatures, ncol = 3, order = T)"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-dimred_save",
    "href": "labs/seurat/seurat_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "9 Save data",
    "text": "9 Save data\nWe can finally save the object for use in future steps.\n\nsaveRDS(alldata, \"data/covid/results/seurat_covid_qc_dr.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_02_dimred.html#meta-session",
    "href": "labs/seurat/seurat_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] scran_1.30.0                scuttle_1.12.0             \n [3] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [5] Biobase_2.62.0              GenomicRanges_1.54.1       \n [7] GenomeInfoDb_1.38.1         IRanges_2.36.0             \n [9] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[11] MatrixGenerics_1.14.0       matrixStats_1.5.0          \n[13] patchwork_1.3.0             ggplot2_3.5.1              \n[15] Seurat_5.1.0                SeuratObject_5.0.2         \n[17] sp_2.2-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.22          splines_4.3.3            \n  [3] later_1.4.1               bitops_1.0-9             \n  [5] tibble_3.2.1              polyclip_1.10-7          \n  [7] fastDummies_1.7.5         lifecycle_1.0.4          \n  [9] edgeR_4.0.16              globals_0.16.3           \n [11] lattice_0.22-6            MASS_7.3-60.0.1          \n [13] magrittr_2.0.3            limma_3.58.1             \n [15] plotly_4.10.4             rmarkdown_2.29           \n [17] yaml_2.3.10               metapod_1.10.0           \n [19] httpuv_1.6.15             sctransform_0.4.1        \n [21] spam_2.11-1               spatstat.sparse_3.1-0    \n [23] reticulate_1.40.0         cowplot_1.1.3            \n [25] pbapply_1.7-2             RColorBrewer_1.1-3       \n [27] abind_1.4-5               zlibbioc_1.48.0          \n [29] Rtsne_0.17                purrr_1.0.2              \n [31] RCurl_1.98-1.16           GenomeInfoDbData_1.2.11  \n [33] ggrepel_0.9.6             irlba_2.3.5.1            \n [35] listenv_0.9.1             spatstat.utils_3.1-2     \n [37] goftest_1.2-3             RSpectra_0.16-2          \n [39] spatstat.random_3.3-2     dqrng_0.3.2              \n [41] fitdistrplus_1.2-2        parallelly_1.42.0        \n [43] DelayedMatrixStats_1.24.0 leiden_0.4.3.1           \n [45] codetools_0.2-20          DelayedArray_0.28.0      \n [47] tidyselect_1.2.1          farver_2.1.2             \n [49] viridis_0.6.5             ScaledMatrix_1.10.0      \n [51] spatstat.explore_3.3-4    jsonlite_1.8.9           \n [53] BiocNeighbors_1.20.0      progressr_0.15.1         \n [55] ggridges_0.5.6            survival_3.8-3           \n [57] scater_1.30.1             tools_4.3.3              \n [59] ica_1.0-3                 Rcpp_1.0.14              \n [61] glue_1.8.0                gridExtra_2.3            \n [63] SparseArray_1.2.2         xfun_0.50                \n [65] dplyr_1.1.4               withr_3.0.2              \n [67] fastmap_1.2.0             bluster_1.12.0           \n [69] digest_0.6.37             rsvd_1.0.5               \n [71] R6_2.6.1                  mime_0.12                \n [73] colorspace_2.1-1          scattermore_1.2          \n [75] tensor_1.5                spatstat.data_3.1-4      \n [77] tidyr_1.3.1               generics_0.1.3           \n [79] data.table_1.16.4         httr_1.4.7               \n [81] htmlwidgets_1.6.4         S4Arrays_1.2.0           \n [83] uwot_0.2.2                pkgconfig_2.0.3          \n [85] gtable_0.3.6              lmtest_0.9-40            \n [87] XVector_0.42.0            htmltools_0.5.8.1        \n [89] dotCall64_1.2             scales_1.3.0             \n [91] png_0.1-8                 spatstat.univar_3.1-1    \n [93] knitr_1.49                reshape2_1.4.4           \n [95] nlme_3.1-167              zoo_1.8-12               \n [97] stringr_1.5.1             KernSmooth_2.23-26       \n [99] parallel_4.3.3            miniUI_0.1.1.1           \n[101] vipor_0.4.7               pillar_1.10.1            \n[103] grid_4.3.3                vctrs_0.6.5              \n[105] RANN_2.6.2                promises_1.3.2           \n[107] BiocSingular_1.18.0       beachmat_2.18.0          \n[109] xtable_1.8-4              cluster_2.1.8            \n[111] beeswarm_0.4.0            evaluate_1.0.3           \n[113] cli_3.6.4                 locfit_1.5-9.11          \n[115] compiler_4.3.3            rlang_1.1.5              \n[117] crayon_1.5.3              future.apply_1.11.3      \n[119] labeling_0.4.3            plyr_1.8.9               \n[121] ggbeeswarm_0.7.2          stringi_1.8.4            \n[123] viridisLite_0.4.2         deldir_2.0-4             \n[125] BiocParallel_1.36.0       munsell_0.5.1            \n[127] lazyeval_0.2.2            spatstat.geom_3.3-5      \n[129] Matrix_1.6-5              RcppHNSW_0.6.0           \n[131] sparseMatrixStats_1.14.0  future_1.34.0            \n[133] statmod_1.5.0             shiny_1.10.0             \n[135] ROCR_1.0-11               igraph_2.0.3"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html",
    "href": "labs/bioc/bioc_02_dimred.html",
    "title": " Dimensionality Reduction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_prep",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_prep",
    "title": " Dimensionality Reduction",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nFirst, let’s load all necessary libraries and the QC-filtered dataset from the previous step.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(umap)\n})\n\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/bioc_covid_qc.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_bioc/bioc_covid_qc.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nsce &lt;- readRDS(path_file)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_fs",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_fs",
    "title": " Dimensionality Reduction",
    "section": "2 Feature selection",
    "text": "2 Feature selection\nWe first need to define which features/genes are important in our dataset to distinguish cell types. For this purpose, we need to find genes that are highly variable across cells, which in turn will also provide a good separation of the cell clusters.\nWith modelGeneVar we can specify a blocking parameter, so the trend fitting and variance decomposition is done separately for each batch.\n\nsce &lt;- computeSumFactors(sce, sizes = c(20, 40, 60, 80))\nsce &lt;- logNormCounts(sce)\nvar.out &lt;- modelGeneVar(sce, block = sce$sample)\nhvgs &lt;- getTopHVGs(var.out, n = 2000)\n\nWe can plot the total variance and the biological variance vs mean expressioni for one of the samples.\n\npar(mfrow = c(1, 2))\n# plot mean over TOTAL variance\n# Visualizing the fit:\nfit.var &lt;- metadata(var.out$per.block[[1]])\n{\n    plot(fit.var$mean, fit.var$var,\n        xlab = \"Mean of log-expression\",\n        ylab = \"Variance of log-expression\",\n        main = \"Total variance\"\n    )\n    curve(fit.var$trend(x), col = \"dodgerblue\", add = TRUE, lwd = 2)\n\n    # Select 1000 top variable genes\n    hvg.out &lt;- getTopHVGs(var.out, n = 1000)\n\n    # highligt those cells in the plot\n    cutoff &lt;- rownames(var.out) %in% hvg.out\n    points(fit.var$mean[cutoff], fit.var$var[cutoff], col = \"red\", pch = 16, cex = .6)\n}\n\n{\n    # plot mean over BIOLOGICAL variance for same sample\n    plot(var.out$per.block[[1]]$mean, var.out$per.block[[1]]$bio, pch = 16, cex = 0.4, \n         xlab = \"Mean log-expression\", \n         ylab = \"Variance of log-expression\",\n         main = \"Biological variance\")\n    lines(c(min(var.out$per.block[[1]]$mean), max(var.out$per.block[[1]]$mean)), c(0, 0), col = \"dodgerblue\", lwd = 2)\n    points(var.out$per.block[[1]]$mean[cutoff], var.out$per.block[[1]]$bio[cutoff], col = \"red\", pch = 16, cex = .6)\n}\n\n\n\n\n\n\n\n\nWe can plot the same for all the samples, also showing the technical variance.\n\ncutoff &lt;- rownames(var.out) %in% hvgs\n\npar(mfrow = c(1, 3))\n    plot(var.out$mean, var.out$total, pch = 16, cex = 0.4, \n         xlab = \"Mean log-expression\", \n         ylab = \"Variance of log-expression\",\n         main = \"Total variance\")\n    points(var.out$mean[cutoff], var.out$total[cutoff], col = \"red\", pch = 16, cex = .6)\n\n    plot(var.out$mean, var.out$bio, pch = 16, cex = 0.4, \n         xlab = \"Mean log-expression\", \n         ylab = \"Variance of log-expression\",\n         main = \"Biological variance\")\n    points(var.out$mean[cutoff], var.out$bio[cutoff], col = \"red\", pch = 16, cex = .6)\n    \n    plot(var.out$mean, var.out$tech, pch = 16, cex = 0.4, \n         xlab = \"Mean log-expression\", \n         ylab = \"Variance of log-expression\",\n         main = \"Technical variance\")\n    points(var.out$mean[cutoff], var.out$tech[cutoff], col = \"red\", pch = 16, cex = .6)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_zs",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_zs",
    "title": " Dimensionality Reduction",
    "section": "3 Z-score transformation",
    "text": "3 Z-score transformation\nNow that the genes have been selected, we now proceed with PCA. Since each gene has a different expression level, it means that genes with higher expression values will naturally have higher variation that will be captured by PCA. This means that we need to somehow give each gene a similar weight when performing PCA (see below). The common practice is to center and scale each gene before performing PCA. This exact scaling called Z-score normalization is very useful for PCA, clustering and plotting heatmaps. Additionally, we can use regression to remove any unwanted sources of variation from the dataset, such as cell cycle, sequencing depth, percent mitochondria etc. This is achieved by doing a generalized linear regression using these parameters as co-variates in the model. Then the residuals of the model are taken as the regressed data. Although perhaps not in the best way, batch effect regression can also be done here. By default, variables are scaled in the PCA step and is not done separately. But it could be achieved by running the commands below:\nHowever, unlike the Seurat, this step is implemented inside the PCA function below. Here we will show you how to add the scaledData back to the object.\n\n# sce@assays$data@listData$scaled.data &lt;- apply(exprs(sce)[rownames(hvg.out),,drop=FALSE],2,function(x) scale(x,T,T))\n# rownames(sce@assays$data@listData$scaled.data) &lt;- rownames(hvg.out)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_pca",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_pca",
    "title": " Dimensionality Reduction",
    "section": "4 PCA",
    "text": "4 PCA\nPerforming PCA has many useful applications and interpretations, which much depends on the data used. In the case of single-cell data, we want to segregate samples based on gene expression patterns in the data.\nWe use the logcounts and then set scale_features to TRUE in order to scale each gene.\n\n# runPCA and specify the variable genes to use for dim reduction with subset_row\nsce &lt;- runPCA(sce, exprs_values = \"logcounts\", ncomponents = 50, subset_row = hvgs, scale = TRUE)\n\nWe then plot the first principal components.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 1:2, point_size = 0.6),\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 3:4, point_size = 0.6),\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", ncomponents = 5:6, point_size = 0.6),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nTo identify which genes (Seurat) or metadata parameters (Scater/Scran) contribute the most to each PC, one can retrieve the loading matrix information. Unfortunately, this is not implemented in Scater/Scran, so you will need to compute PCA using logcounts.\nHere, we can check how the different metadata variables contributes to each PC. This can be important to look at to understand different biases you may have in your data.\n\nplotExplanatoryPCs(sce,nvars_to_plot = 15)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the plot from plotExplanatoryPCs and the gene loadings plots. Do you think the top components are biologically relevant or more driven by technical noise\n\n\nWe can also plot the amount of variance explained by each PC.\n\nplot(attr(reducedDim(sce, \"PCA\"), \"percentVar\")[1:50] * 100, type = \"l\", ylab = \"% variance\", xlab = \"Principal component #\")\npoints(attr(reducedDim(sce, \"PCA\"), \"percentVar\")[1:50] * 100, pch = 21, bg = \"grey\", cex = .5)\n\n\n\n\n\n\n\n\nBased on this plot, we can see that the top 8 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types (such as platelets and DCs in this dataset)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_tsne",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_tsne",
    "title": " Dimensionality Reduction",
    "section": "5 tSNE",
    "text": "5 tSNE\nWe will now run BH-tSNE.\n\nset.seed(42)\nsce &lt;- runTSNE(sce, dimred = \"PCA\", n_dimred = 30, perplexity = 30, name = \"tSNE_on_PCA\")\n\nWe plot the tSNE scatterplot colored by dataset. We can clearly see the effect of batches present in the dataset.\n\nplotReducedDim(sce, dimred = \"tSNE_on_PCA\", colour_by = \"sample\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_umap",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_umap",
    "title": " Dimensionality Reduction",
    "section": "6 UMAP",
    "text": "6 UMAP\nWe can now run UMAP for cell embeddings.\n\nsce &lt;- runUMAP(sce, dimred = \"PCA\", n_dimred = 30, ncomponents = 2, name = \"UMAP_on_PCA\")\n# see ?umap and ?runUMAP for more info\n\nUMAP is plotted colored per dataset. Although less distinct as in the tSNE, we still see quite an effect of the different batches in the data.\n\nsce &lt;- runUMAP(sce, dimred = \"PCA\", n_dimred = 30, ncomponents = 10, name = \"UMAP10_on_PCA\")\n# see ?umap and ?runUMAP for more info\n\nWe can now plot PCA, UMAP and tSNE side by side for comparison. Have a look at the UMAP and tSNE. What similarities/differences do you see? Can you explain the differences based on what you learned during the lecture? Also, we can conclude from the dimensionality reductions that our dataset contains a batch effect that needs to be corrected before proceeding to clustering and differential gene expression analysis.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP10_on_PCA\", colour_by = \"sample\", ncomponents = 1:2) +\n        ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP10_on_PCA\", colour_by = \"sample\", ncomponents = 3:4) +\n        ggplot2::ggtitle(label = \"UMAP10_on_PCA\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nWe have now done Variable gene selection, PCA and UMAP with the settings we selected for you. Test a few different ways of selecting variable genes, number of PCs for UMAP and check how it influences your embedding."
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_zsg",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_zsg",
    "title": " Dimensionality Reduction",
    "section": "7 Z-scores & DR graphs",
    "text": "7 Z-scores & DR graphs\nAlthough running a second dimensionality reduction (i.e tSNE or UMAP) on PCA would be a standard approach (because it allows higher computation efficiency), the options are actually limitless. Below we will show a couple of other common options such as running directly on the scaled data (z-scores) (which was used for PCA) or on a graph built from scaled data. We will only work with UMAPs, but the same applies for tSNE.\n\n7.1 UMAP from z-scores\nTo run tSNE or UMAP on the scaled data, one first needs to select the number of variables to use. This is because including dimensions that do contribute to the separation of your cell types will in the end mask those differences. Another reason for it is because running with all genes/features also will take longer or might be computationally unfeasible. Therefore we will use the scaled data of the highly variable genes.\n\nsce &lt;- runUMAP(sce, exprs_values = \"logcounts\", name = \"UMAP_on_ScaleData\")\n\n\n\n7.2 UMAP from graph\nTo run tSNE or UMAP on the a graph, we first need to build a graph from the data. In fact, both tSNE and UMAP first build a graph from the data using a specified distance matrix and then optimize the embedding. Since a graph is just a matrix containing distances from cell to cell and as such, you can run either UMAP or tSNE using any other distance metric desired. Euclidean and Correlation are usually the most commonly used.\n\n# Build Graph\nnn &lt;- RANN::nn2(reducedDim(sce, \"PCA\"), k = 30)\nnames(nn) &lt;- c(\"idx\", \"dist\")\ng &lt;- buildKNNGraph(sce, k = 30, use.dimred = \"PCA\")\nreducedDim(sce, \"KNN\") &lt;- igraph::as_adjacency_matrix(g)\n\n# Run UMAP and rename it for comparisson\n# temp &lt;- umap::umap.defaults\ntry(reducedDim(sce, \"UMAP_on_Graph\") &lt;- NULL)\nreducedDim(sce, \"UMAP_on_Graph\") &lt;- uwot::umap(X = NULL, n_components = 2, nn_method = nn)\n\nWe can now plot the UMAP comparing both on PCA vs ScaledSata vs Graph.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_ScaleData\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_ScaleData\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Graph\", colour_by = \"sample\") +\n        ggplot2::ggtitle(label = \"UMAP_on_Graph\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_plotgenes",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_plotgenes",
    "title": " Dimensionality Reduction",
    "section": "8 Genes of interest",
    "text": "8 Genes of interest\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nplotlist &lt;- list()\nfor (i in c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")) {\n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = i, by_exprs_values = \"logcounts\") +\n        scale_fill_gradientn(colours = colorRampPalette(c(\"grey90\", \"orange3\", \"firebrick\", \"firebrick\", \"red\", \"red\"))(10)) +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist, ncol = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nSelect some of your dimensionality reductions and plot some of the QC stats that were calculated in the previous lab. Can you see if some of the separation in your data is driven by quality of the cells?\n\n\n\nplotlist &lt;- list()\nfor (i in c(\"detected\", \"total\", \"subsets_mt_percent\",\"subsets_ribo_percent\",\"subsets_hb_percent\")) { \n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = i, by_exprs_values = \"logcounts\") +\n        scale_fill_gradientn(colours = colorRampPalette(c(\"grey90\", \"orange3\", \"firebrick\", \"firebrick\", \"red\", \"red\"))(10)) +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist, ncol = 3)"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-dimred_save",
    "href": "labs/bioc/bioc_02_dimred.html#meta-dimred_save",
    "title": " Dimensionality Reduction",
    "section": "9 Save data",
    "text": "9 Save data\nWe can finally save the object for use in future steps.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_02_dimred.html#meta-session",
    "href": "labs/bioc/bioc_02_dimred.html#meta-session",
    "title": " Dimensionality Reduction",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] umap_0.2.10.0               patchwork_1.3.0            \n [3] scran_1.30.0                scater_1.30.1              \n [5] ggplot2_3.5.1               scuttle_1.12.0             \n [7] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [9] Biobase_2.62.0              GenomicRanges_1.54.1       \n[11] GenomeInfoDb_1.38.1         IRanges_2.36.0             \n[13] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[15] MatrixGenerics_1.14.0       matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1          viridisLite_0.4.2        \n [3] dplyr_1.1.4               vipor_0.4.7              \n [5] farver_2.1.2              viridis_0.6.5            \n [7] bitops_1.0-9              fastmap_1.2.0            \n [9] RCurl_1.98-1.16           RANN_2.6.2               \n[11] bluster_1.12.0            digest_0.6.37            \n[13] rsvd_1.0.5                lifecycle_1.0.4          \n[15] cluster_2.1.8             statmod_1.5.0            \n[17] magrittr_2.0.3            compiler_4.3.3           \n[19] rlang_1.1.5               tools_4.3.3              \n[21] igraph_2.0.3              yaml_2.3.10              \n[23] knitr_1.49                labeling_0.4.3           \n[25] askpass_1.2.1             S4Arrays_1.2.0           \n[27] dqrng_0.3.2               htmlwidgets_1.6.4        \n[29] reticulate_1.40.0         DelayedArray_0.28.0      \n[31] abind_1.4-5               BiocParallel_1.36.0      \n[33] Rtsne_0.17                withr_3.0.2              \n[35] grid_4.3.3                beachmat_2.18.0          \n[37] colorspace_2.1-1          edgeR_4.0.16             \n[39] scales_1.3.0              cli_3.6.4                \n[41] rmarkdown_2.29            crayon_1.5.3             \n[43] generics_0.1.3            metapod_1.10.0           \n[45] RSpectra_0.16-2           DelayedMatrixStats_1.24.0\n[47] ggbeeswarm_0.7.2          zlibbioc_1.48.0          \n[49] parallel_4.3.3            XVector_0.42.0           \n[51] vctrs_0.6.5               Matrix_1.6-5             \n[53] jsonlite_1.8.9            BiocSingular_1.18.0      \n[55] BiocNeighbors_1.20.0      ggrepel_0.9.6            \n[57] irlba_2.3.5.1             beeswarm_0.4.0           \n[59] locfit_1.5-9.11           limma_3.58.1             \n[61] glue_1.8.0                codetools_0.2-20         \n[63] uwot_0.2.2                cowplot_1.1.3            \n[65] RcppAnnoy_0.0.22          gtable_0.3.6             \n[67] ScaledMatrix_1.10.0       munsell_0.5.1            \n[69] tibble_3.2.1              pillar_1.10.1            \n[71] htmltools_0.5.8.1         openssl_2.3.2            \n[73] GenomeInfoDbData_1.2.11   R6_2.6.1                 \n[75] sparseMatrixStats_1.14.0  evaluate_1.0.3           \n[77] lattice_0.22-6            png_0.1-8                \n[79] Rcpp_1.0.14               gridExtra_2.3            \n[81] SparseArray_1.2.2         xfun_0.50                \n[83] pkgconfig_2.0.3"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html",
    "href": "labs/bioc/bioc_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-int_prep",
    "href": "labs/bioc/bioc_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(batchelor)\n    library(harmony)\n    library(basilisk)\n})\n\n# path to conda env for python environment with scanorama.\ncondapath =  \"/usr/local/conda/envs/seurat\"\n\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_bioc/bioc_covid_qc_dr.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nsce &lt;- readRDS(path_file)\nprint(reducedDims(sce))\n\nList of length 8\nnames(8): PCA UMAP tSNE_on_PCA ... UMAP_on_ScaleData KNN UMAP_on_Graph\n\n\nWe split the combined object into a list, with each dataset as an element. We perform standard preprocessing (log-normalization), and identify variable features individually for each dataset based on a variance stabilizing transformation (vst).\nIf you recall from the dimensionality reduction exercise, we can run variable genes detection with a blocking parameter to avoid including batch effect genes. Here we will explore the genesets we get with and without the blocking parameter and also the variable genes per dataset.\n\nvar.out &lt;- modelGeneVar(sce, block = sce$sample)\nhvgs &lt;- getTopHVGs(var.out, n = 2000)\n\nvar.out.nobatch &lt;- modelGeneVar(sce)\nhvgs.nobatch &lt;- getTopHVGs(var.out.nobatch, n = 2000)\n\n# the var out with block has a data frame of data frames in column 7. \n# one per dataset.\nhvgs_per_dataset &lt;- lapply(var.out[[7]], getTopHVGs, n=2000)\n                           \nhvgs_per_dataset$all = hvgs\nhvgs_per_dataset$all.nobatch = hvgs.nobatch\n\n\n\n\ntemp &lt;- unique(unlist(hvgs_per_dataset))\noverlap &lt;- sapply(hvgs_per_dataset, function(x) {\n    temp %in% x\n})\n\n\npheatmap::pheatmap(t(overlap * 1), cluster_rows = F, color = c(\"grey90\", \"grey20\")) ## MNN\n\n\n\n\n\n\n\n\nAs you can see, there are a lot of genes that are variable in just one dataset. There are also some genes in the gene set that was selected using all the data without blocking samples, that are not variable in any of the individual datasets. These are most likely genes driven by batch effects.\nThe best way to select features for integration is to combine the information on variable genes across the dataset. This is what we have in the all section where the information on variable features in the different datasets is combined.\n\n\n\n\n\n\nDiscuss\n\n\n\nDid you understand the difference between running variable gene selection per dataset and combining them vs running it on all samples together. Can you think of any situation where it would be best to run it on all samples and a situation where it should be done by batch?\n\n\nFor all downstream integration we will use this set of genes so that it is comparable across the methods. We already used that set of genes in the dimensionality reduction exercise to run scaling and pca.\nWe also store the variable gene information in the object for use furhter down the line.\n\nmetadata(sce)$hvgs = hvgs"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#fastmnn",
    "href": "labs/bioc/bioc_03_integration.html#fastmnn",
    "title": " Data Integration",
    "section": "2 fastMNN",
    "text": "2 fastMNN\nThe mutual nearest neighbors (MNN) approach within the scran package utilizes a novel approach to adjust for batch effects. The fastMNN() function returns a representation of the data with reduced dimensionality, which can be used in a similar fashion to other lower-dimensional representations such as PCA. In particular, this representation can be used for downstream methods such as clustering. The BNPARAM can be used to specify the specific nearest neighbors method to use from the BiocNeighbors package. Here we make use of the Annoy library via the BiocNeighbors::AnnoyParam() argument. We save the reduced-dimension MNN representation into the reducedDims slot of our sce object.\n\nmnn_out &lt;- batchelor::fastMNN(sce, subset.row = hvgs, batch = factor(sce$sample), k = 20, d = 50)\n\n\n\n\n\n\n\nCaution\n\n\n\nfastMNN() does not produce a batch-corrected expression matrix.\n\n\nWe will take the reduced dimension in the new mnn_out object and add it into the original sce object.\n\nmnn_dim &lt;- reducedDim(mnn_out, \"corrected\")\nreducedDim(sce, \"MNN\") &lt;- mnn_dim\n\nWe can observe that a new assay slot is now created under the name MNN.\n\nreducedDims(sce)\n\nList of length 9\nnames(9): PCA UMAP tSNE_on_PCA UMAP_on_PCA ... KNN UMAP_on_Graph MNN\n\n\nThus, the result from fastMNN() should solely be treated as a reduced dimensionality representation, suitable for direct plotting, TSNE/UMAP, clustering, and trajectory analysis that relies on such results.\n\nset.seed(42)\nsce &lt;- runTSNE(sce, dimred = \"MNN\", n_dimred = 50, perplexity = 30, name = \"tSNE_on_MNN\")\nsce &lt;- runUMAP(sce, dimred = \"MNN\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_MNN\")\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"PCA\"),\n    plotReducedDim(sce, dimred = \"tSNE_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"tSNE_on_PCA\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_PCA\"),\n    plotReducedDim(sce, dimred = \"MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"MNN\"),\n    plotReducedDim(sce, dimred = \"tSNE_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"tSNE_on_MNN\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_MNN\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nplotlist &lt;- list()\nfor (i in c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")) {\n    plotlist[[i]] &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = i, by_exprs_values = \"logcounts\", point_size = 0.6) +\n        scale_fill_gradientn(colours = colorRampPalette(c(\"grey90\", \"orange3\", \"firebrick\", \"firebrick\", \"red\", \"red\"))(10)) +\n        ggtitle(label = i) + theme(plot.title = element_text(size = 20))\n}\nwrap_plots(plotlist = plotlist, ncol = 3)"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-dimred_harmony",
    "href": "labs/bioc/bioc_03_integration.html#meta-dimred_harmony",
    "title": " Data Integration",
    "section": "3 Harmony",
    "text": "3 Harmony\nAn alternative method for integration is Harmony, for more details on the method, please se their paper Nat. Methods. This method runs the integration on a dimensionality reduction, in most applications the PCA. So first, we prefer to have scaling and PCA with the same set of genes that were used for the CCA integration, which we ran earlier.\n\nlibrary(harmony)\n\nreducedDimNames(sce)\n\n [1] \"PCA\"               \"UMAP\"              \"tSNE_on_PCA\"      \n [4] \"UMAP_on_PCA\"       \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\"\n [7] \"KNN\"               \"UMAP_on_Graph\"     \"MNN\"              \n[10] \"tSNE_on_MNN\"       \"UMAP_on_MNN\"      \n\nsce &lt;- RunHarmony(\n    sce,\n    group.by.vars = \"sample\",\n    reduction.save = \"harmony\",\n    reduction = \"PCA\",\n    dims.use = 1:50\n)\n\n# Here we use all PCs computed from Harmony for UMAP calculation\nsce &lt;- runUMAP(sce, dimred = \"harmony\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_Harmony\")\n\nplotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Harmony\")"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-dimred_scanorama",
    "href": "labs/bioc/bioc_03_integration.html#meta-dimred_scanorama",
    "title": " Data Integration",
    "section": "4 Scanorama",
    "text": "4 Scanorama\nAnother integration method is Scanorama (see Nat. Biotech.). This method is implemented in python, but we can run it through the Reticulate package.\nWe will run it with the same set of variable genes, but first we have to create a list of all the objects per sample.\n\nscelist &lt;- lapply(unique(sce$sample), function(x) {\n    x &lt;- t(as.matrix(assay(sce, \"logcounts\")[hvgs,sce$sample == x]))\n})\ngenelist =  rep(list(hvgs),length(scelist))\n\nlapply(scelist, dim)\n\n[[1]]\n[1]  836 2000\n\n[[2]]\n[1]  538 2000\n\n[[3]]\n[1]  355 2000\n\n[[4]]\n[1] 1062 2000\n\n[[5]]\n[1]  984 2000\n\n[[6]]\n[1] 1111 2000\n\n[[7]]\n[1]  952 2000\n\n[[8]]\n[1] 1086 2000\n\n\nScanorama is implemented in python, but through reticulate we can load python packages and run python functions. In this case we also use the basilisk package for a more clean activation of python environment.\nAt the top of this script, we set the variable condapath to point to the conda environment where scanorama is included.\n\n# run scanorama via basilisk with scelist and genelist as input.\nintegrated.data = basiliskRun(env=condapath, fun=function(datas, genes) {\n  scanorama &lt;- reticulate::import(\"scanorama\")\n  output &lt;- scanorama$integrate(datasets_full = datas,\n                                         genes_list = genes )\n  return(output)\n}, datas = scelist, genes = genelist, testload=\"scanorama\")\n\nFound 2000 genes among all datasets\n[[0.         0.53159851 0.38028169 0.26741996 0.45334928 0.33851675\n  0.2930622  0.13075506]\n [0.         0.         0.74084507 0.26208178 0.36788618 0.18215613\n  0.19330855 0.11524164]\n [0.         0.         0.         0.22253521 0.41971831 0.52394366\n  0.29014085 0.24507042]\n [0.         0.         0.         0.         0.21849593 0.05932203\n  0.13088512 0.17771639]\n [0.         0.         0.         0.         0.         0.84146341\n  0.62296748 0.17403315]\n [0.         0.         0.         0.         0.         0.\n  0.77587759 0.38029466]\n [0.         0.         0.         0.         0.         0.\n  0.         0.70073665]\n [0.         0.         0.         0.         0.         0.\n  0.         0.        ]]\nProcessing datasets (4, 5)\nProcessing datasets (5, 6)\nProcessing datasets (1, 2)\nProcessing datasets (6, 7)\nProcessing datasets (4, 6)\nProcessing datasets (0, 1)\nProcessing datasets (2, 5)\nProcessing datasets (0, 4)\nProcessing datasets (2, 4)\nProcessing datasets (5, 7)\nProcessing datasets (0, 2)\nProcessing datasets (1, 4)\nProcessing datasets (0, 5)\nProcessing datasets (0, 6)\nProcessing datasets (2, 6)\nProcessing datasets (0, 3)\nProcessing datasets (1, 3)\nProcessing datasets (2, 7)\nProcessing datasets (2, 3)\nProcessing datasets (3, 4)\nProcessing datasets (1, 6)\nProcessing datasets (1, 5)\nProcessing datasets (3, 7)\nProcessing datasets (4, 7)\nProcessing datasets (3, 6)\nProcessing datasets (0, 7)\nProcessing datasets (1, 7)\n\nintdimred &lt;- do.call(rbind, integrated.data[[1]])\ncolnames(intdimred) &lt;- paste0(\"PC_\", 1:100)\nrownames(intdimred) &lt;- colnames(logcounts(sce))\n\n# Add standard deviations in order to draw Elbow Plots \nstdevs &lt;- apply(intdimred, MARGIN = 2, FUN = sd)\nattr(intdimred, \"varExplained\") &lt;- stdevs\n\nreducedDim(sce, \"Scanorama\") &lt;- intdimred\n\n# Here we use all PCs computed from Scanorama for UMAP calculation\nsce &lt;- runUMAP(sce, dimred = \"Scanorama\", n_dimred = 50, ncomponents = 2, name = \"UMAP_on_Scanorama\")\n\nplotReducedDim(sce, dimred = \"UMAP_on_Scanorama\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Scanorama\")"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#overview-all-methods",
    "href": "labs/bioc/bioc_03_integration.html#overview-all-methods",
    "title": " Data Integration",
    "section": "5 Overview all methods",
    "text": "5 Overview all methods\nNow we will plot UMAPS with all three integration methods side by side.\n\np1 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_PCA\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_PCA\")\np2 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_MNN\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_MNN\")\np3 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Harmony\")\np4 &lt;- plotReducedDim(sce, dimred = \"UMAP_on_Scanorama\", colour_by = \"sample\", point_size = 0.6) + ggplot2::ggtitle(label = \"UMAP_on_Scanorama\")\n\nwrap_plots(p1, p2, p3, p4, nrow = 2) +\n    plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLook at the different integration results, which one do you think looks the best? How would you motivate selecting one method over the other? How do you think you could best evaluate if the integration worked well?\n\n\nLet’s save the integrated data for further analysis.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr_int.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_03_integration.html#meta-session",
    "href": "labs/bioc/bioc_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] basilisk_1.14.1             harmony_1.2.1              \n [3] Rcpp_1.0.14                 batchelor_1.18.0           \n [5] patchwork_1.3.0             scran_1.30.0               \n [7] scater_1.30.1               ggplot2_3.5.1              \n [9] scuttle_1.12.0              SingleCellExperiment_1.24.0\n[11] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[13] GenomicRanges_1.54.1        GenomeInfoDb_1.38.1        \n[15] IRanges_2.36.0              S4Vectors_0.40.2           \n[17] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[19] matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-9              gridExtra_2.3            \n [3] rlang_1.1.5               magrittr_2.0.3           \n [5] RcppAnnoy_0.0.22          compiler_4.3.3           \n [7] dir.expiry_1.10.0         DelayedMatrixStats_1.24.0\n [9] png_0.1-8                 vctrs_0.6.5              \n[11] pkgconfig_2.0.3           crayon_1.5.3             \n[13] fastmap_1.2.0             XVector_0.42.0           \n[15] labeling_0.4.3            rmarkdown_2.29           \n[17] ggbeeswarm_0.7.2          xfun_0.50                \n[19] bluster_1.12.0            zlibbioc_1.48.0          \n[21] beachmat_2.18.0           jsonlite_1.8.9           \n[23] DelayedArray_0.28.0       BiocParallel_1.36.0      \n[25] irlba_2.3.5.1             parallel_4.3.3           \n[27] cluster_2.1.8             R6_2.6.1                 \n[29] RColorBrewer_1.1-3        limma_3.58.1             \n[31] reticulate_1.40.0         knitr_1.49               \n[33] Matrix_1.6-5              igraph_2.0.3             \n[35] tidyselect_1.2.1          abind_1.4-5              \n[37] yaml_2.3.10               viridis_0.6.5            \n[39] codetools_0.2-20          lattice_0.22-6           \n[41] tibble_3.2.1              basilisk.utils_1.14.1    \n[43] withr_3.0.2               evaluate_1.0.3           \n[45] Rtsne_0.17                pillar_1.10.1            \n[47] filelock_1.0.3            generics_0.1.3           \n[49] RCurl_1.98-1.16           sparseMatrixStats_1.14.0 \n[51] munsell_0.5.1             scales_1.3.0             \n[53] RhpcBLASctl_0.23-42       glue_1.8.0               \n[55] metapod_1.10.0            pheatmap_1.0.12          \n[57] tools_4.3.3               BiocNeighbors_1.20.0     \n[59] ScaledMatrix_1.10.0       locfit_1.5-9.11          \n[61] cowplot_1.1.3             grid_4.3.3               \n[63] edgeR_4.0.16              colorspace_2.1-1         \n[65] GenomeInfoDbData_1.2.11   beeswarm_0.4.0           \n[67] BiocSingular_1.18.0       vipor_0.4.7              \n[69] cli_3.6.4                 rsvd_1.0.5               \n[71] S4Arrays_1.2.0            viridisLite_0.4.2        \n[73] dplyr_1.1.4               uwot_0.2.2               \n[75] ResidualMatrix_1.12.0     gtable_0.3.6             \n[77] digest_0.6.37             SparseArray_1.2.2        \n[79] ggrepel_0.9.6             dqrng_0.3.2              \n[81] htmlwidgets_1.6.4         farver_2.1.2             \n[83] htmltools_0.5.8.1         lifecycle_1.0.4          \n[85] statmod_1.5.0"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html",
    "href": "labs/bioc/bioc_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial, we will continue the analysis of the integrated dataset. We will use the integrated PCA or CCA to perform the clustering. First, we will construct a \\(k\\)-nearest neighbor graph in order to perform a clustering on the graph. We will also show how to perform hierarchical clustering and k-means clustering on the selected space.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(igraph)\n    library(clustree)\n    library(bluster)\n})\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr_int.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_bioc/bioc_covid_qc_dr_int.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nsce &lt;- readRDS(path_file)\nprint(reducedDims(sce))\n\nList of length 15\nnames(15): PCA UMAP tSNE_on_PCA ... UMAP_on_Harmony Scanorama UMAP_on_Scanorama"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_graphclust",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps:\n- Build a kNN graph from the data.\n- Prune spurious connections from kNN graph (optional step). This is a SNN graph.\n- Find groups of cells that maximizes the connections within the group compared other groups.\n\n1.1 Building kNN / SNN graph\nThe first step into graph clustering is to construct a k-nn graph, in case you don’t have one. For this, we will use the PCA space. Thus, as done for dimensionality reduction, we will use ony the top N PCA dimensions for this purpose (the same used for computing UMAP / tSNE).\n\n# These 2 lines are for demonstration purposes only\ng &lt;- buildKNNGraph(sce, k = 30, use.dimred = \"harmony\")\nreducedDim(sce, \"KNN\") &lt;- igraph::as_adjacency_matrix(g)\n\n# These 2 lines are the most recommended, it first run the KNN graph construction and then creates the SNN graph.\ng &lt;- buildSNNGraph(sce, k = 30, use.dimred = \"harmony\")\nreducedDim(sce, \"SNN\") &lt;- as_adjacency_matrix(g, attr = \"weight\")\n\nWe can take a look at the kNN and SNN graphs. The kNN graph is a matrix where every connection between cells is represented as \\(1\\)s. This is called a unweighted graph (default in Seurat). In the SNN graph on the other hand, some cell connections have more importance than others, and the graph scales from \\(0\\) to a maximum distance (in this case \\(1\\)). Usually, the smaller the distance, the closer two points are, and stronger is their connection. This is called a weighted graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (&gt; 100k cells).\n\n# plot the KNN graph\npheatmap(reducedDim(sce, \"KNN\")[1:200, 1:200],\n    col = c(\"white\", \"black\"), border_color = \"grey90\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n# or the SNN graph\npheatmap(reducedDim(sce, \"SNN\")[1:200, 1:200],\n    col = colorRampPalette(c(\"white\", \"yellow\", \"red\", \"black\"))(20),\n    border_color = \"grey90\",\n    legend = T, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n\nAs you can see, the way Scran computes the SNN graph is different to Seurat. It gives edges to all cells that shares a neighbor, but weights the edges by how similar the neighbors are. Hence, the SNN graph has more edges than the KNN graph.\nThere are 3 different options how to define the SNN these are:\n\nrank- scoring based on shared close neighbors, i.e. ranking the neighbors of two cells and comparing the ranks.\nnumber - number of shared neighbors\njaccard - calculate Jaccard similarity, same as in Seurat.\n\n\n\n1.2 Clustering on a graph\nOnce the graph is built, we can now perform graph clustering. The clustering is done respective to a resolution which can be interpreted as how coarse you want your cluster to be. Higher resolution means higher number of clusters.\nFor clustering we can use the function clusterCells() which actually runs the steps of building the KNN and SNN graph for us, and also does the graph partition. All the clustering builds on the bluster package and we specify the different options using the NNGraphParam() class.\nSome parameters to consider are:\n\nshared, can be TRUE/FALSE - construct SNN graph (TRUE) or cluster on the KNN graph (FALSE)\ntype - for SNN graph method, can be rank, number or jaccard\nk - number of neighbors in the KNN construction. Can be any function implemented in ighraph\ncluster.fun - which community detection method.\ncluster.args - paramters to the different clustering functions\n\nSo to find out what the different options are for the different methods you would have to check the documentation in the igraph package, e.g. ?igraph::cluster_leiden.\nHere we will use the integration with Harmony to build the graph, and the umap built on Harmony for visualization.\nOBS! There is no method to select fewer than the total 50 components in the embedding for creating the graph, so here we create a new reducedDim instance with only 20 components.\n\nreducedDims(sce)$harmony2 = reducedDims(sce)$harmony[,1:20]\n\nsce$louvain_k30 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=30, cluster.fun=\"louvain\",  cluster.args = list(resolution=0.5)))\nsce$louvain_k20 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=20, cluster.fun=\"louvain\",  cluster.args = list(resolution=0.5)))\nsce$louvain_k10 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=10, cluster.fun=\"louvain\",  cluster.args = list(resolution=0.5)))\n\nsce$leiden_k30 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=30, cluster.fun=\"leiden\",  cluster.args = list(resolution_parameter=0.3)))\nsce$leiden_k20 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=20, cluster.fun=\"leiden\",  cluster.args = list(resolution_parameter=0.3)))\nsce$leiden_k10 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=SNNGraphParam(k=10, cluster.fun=\"leiden\",  cluster.args = list(resolution_parameter=0.3)))\n\n\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"louvain_k30\") +\n        ggplot2::ggtitle(label = \"louvain_k30\"),  \n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"louvain_k20\") +\n        ggplot2::ggtitle(label = \"louvain_k20\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"louvain_k10\") +\n        ggplot2::ggtitle(label = \"louvain_k10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_k30\") +\n        ggplot2::ggtitle(label = \"leiden_k30\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_k20\") +\n        ggplot2::ggtitle(label = \"leiden_k20\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_k10\") +\n        ggplot2::ggtitle(label = \"leiden_k10\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe can now use the clustree package to visualize how cells are distributed between clusters depending on resolution.\n\nsuppressPackageStartupMessages(library(clustree))\nclustree(sce, prefix = \"louvain_k\")"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_kmean",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans() function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\n#| fig-height: 8\n#| fig-width: 10\n\nsce$kmeans_5 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=KmeansParam(centers=5))\nsce$kmeans_10 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=KmeansParam(centers=10))  \nsce$kmeans_15 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=KmeansParam(centers=15))\nsce$kmeans_20 &lt;- clusterCells(sce, use.dimred = \"harmony2\", BLUSPARAM=KmeansParam(centers=20))\n\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"kmeans_5\") +\n        ggplot2::ggtitle(label = \"KMeans5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"kmeans_10\") +\n        ggplot2::ggtitle(label = \"KMeans10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"kmeans_15\") +\n        ggplot2::ggtitle(label = \"KMeans15\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"kmeans_15\") +\n        ggplot2::ggtitle(label = \"KMeans20\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\nclustree(sce, prefix = \"kmeans_\")"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_hier",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\nThere is the optioni to run hierarchical clustering in the clusterCells function using HclustParam, but there are limited options to specify distances such as correlations that we show below, so we will run the clustering with our own implementation.\n\n3.1 Defining distance between cells\nThe base R stats package already contains a function dist that calculates distances between all pairs of samples. Since we want to compute distances between samples, rather than among genes, we need to transpose the data before applying it to the dist function. This can be done by simply adding the transpose function t() to the data. The distance methods available in dist are: ‘euclidean’, ‘maximum’, ‘manhattan’, ‘canberra’, ‘binary’ or ‘minkowski’.\n\nd &lt;- dist(reducedDim(sce, \"harmony2\"), method = \"euclidean\")\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n\\[adj = \\frac{1- cor}{2}\\]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist() function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\n\n# Compute sample correlations\nsample_cor &lt;- cor(Matrix::t(reducedDim(sce, \"harmony2\")))\n\n# Transform the scale from correlations\nsample_cor &lt;- (1 - sample_cor) / 2\n\n# Convert it to a distance object\nd2 &lt;- as.dist(sample_cor)\n\n\n\n3.2 Clustering cells\nAfter having calculated the distances between samples, we can now proceed with the hierarchical clustering per-se. We will use the function hclust() for this purpose, in which we can simply run it with the distance objects created above. The methods available are: ‘ward.D’, ‘ward.D2’, ‘single’, ‘complete’, ‘average’, ‘mcquitty’, ‘median’ or ‘centroid’. It is possible to plot the dendrogram for all cells, but this is very time consuming and we will omit for this tutorial.\n\n# euclidean\nh_euclidean &lt;- hclust(d, method = \"ward.D2\")\n\n# correlation\nh_correlation &lt;- hclust(d2, method = \"ward.D2\")\n\nOnce your dendrogram is created, the next step is to define which samples belong to a particular cluster. After identifying the dendrogram, we can now literally cut the tree at a fixed threshold (with cutree) at different levels to define the clusters. We can either define the number of clusters or decide on a height. We can simply try different clustering levels.\n\n# euclidean distance\nsce$hc_euclidean_5 &lt;- factor(cutree(h_euclidean, k = 5))\nsce$hc_euclidean_10 &lt;- factor(cutree(h_euclidean, k = 10))\nsce$hc_euclidean_15 &lt;- factor(cutree(h_euclidean, k = 15))\n\n# correlation distance\nsce$hc_corelation_5 &lt;- factor(cutree(h_correlation, k = 5))\nsce$hc_corelation_10 &lt;- factor(cutree(h_correlation, k = 10))\nsce$hc_corelation_15 &lt;- factor(cutree(h_correlation, k = 15))\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_euclidean_5\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_euclidean_10\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_euclidean_15\") +\n        ggplot2::ggtitle(label = \"HC_euclidean_15\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_corelation_5\") +\n        ggplot2::ggtitle(label = \"HC_correlation_5\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_corelation_10\") +\n        ggplot2::ggtitle(label = \"HC_correlation_10\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"hc_corelation_15\") +\n        ggplot2::ggtitle(label = \"HC_correlation_15\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nsaveRDS(sce, \"data/covid/results/bioc_covid_qc_dr_int_cl.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_distribution",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_distribution",
    "title": " Clustering",
    "section": "4 Distribution of clusters",
    "text": "4 Distribution of clusters\nNow, we can select one of our clustering methods and compare the proportion of samples across the clusters.\n\np1 &lt;- ggplot(as.data.frame(colData(sce)), aes(x = leiden_k20, fill = sample)) +\n    geom_bar(position = \"fill\")\np2 &lt;- ggplot(as.data.frame(colData(sce)), aes(x = leiden_k20, fill = type)) +\n    geom_bar(position = \"fill\")\n\np1 + p2\n\n\n\n\n\n\n\n\nIn this case we have quite good representation of each sample in each cluster. But there are clearly some biases with more cells from one sample in some clusters and also more covid cells in some of the clusters.\nWe can also plot it in the other direction, the proportion of each cluster per sample.\n\nggplot(as.data.frame(colData(sce)), aes(x = sample, fill = leiden_k20)) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated by quality metrics. Could it be explained biologically, or could there be a technical bias there?\n\n\n\nwrap_plots(\n    plotColData(sce, y = \"detected\", x = \"leiden_k20\", colour_by = \"leiden_k20\"),\n    plotColData(sce, y = \"total\", x = \"leiden_k20\", colour_by = \"leiden_k20\"),\n    plotColData(sce, y = \"subsets_mt_percent\", x = \"leiden_k20\", colour_by = \"leiden_k20\"),\n    plotColData(sce, y = \"subsets_ribo_percent\", x = \"leiden_k20\", colour_by = \"leiden_k20\"),\n    plotColData(sce, y = \"subsets_hb_percent\", x = \"leiden_k20\", colour_by = \"leiden_k20\"),\n    ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nSome clusters that are clearly defined by higher number of genes and counts. These are either doublets or a larger celltype. And some clusters with low values on these metrics that are either low quality cells or a smaller celltype. You will have to explore these clusters in more detail to judge what you believe them to be."
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-clust_sub",
    "href": "labs/bioc/bioc_04_clustering.html#meta-clust_sub",
    "title": " Clustering",
    "section": "5 Subclustering of T and NK-cells",
    "text": "5 Subclustering of T and NK-cells\nIt is common that the subtypes of cells within a cluster is not so well separated when you have a heterogeneous dataset. In such a case it could be a good idea to run subclustering of individual celltypes. The main reason for subclustering is that the variable genes and the first principal components in the full analysis are mainly driven by differences between celltypes, while with subclustering we may detect smaller differences between subtypes within celltypes.\nSo first, lets find out where our T-cell and NK-cell clusters are. We know that T-cells express CD3E, and the main subtypes are CD4 and CD8, while NK-cells express GNLY.\n\nwrap_plots(\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_k30\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"CD3E\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"CD4\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"CD8A\"),\n    plotReducedDim(sce, dimred = \"UMAP_on_Harmony\", colour_by = \"GNLY\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe can clearly see what clusters are T-cell clusters, so lets subset the data for those cells\n\ntcells = sce[,sce$leiden_k30 %in% c(3,4)]\n\ntable(tcells$sample)\n\n\n  cov.1  cov.15  cov.16  cov.17 ctrl.13 ctrl.14 ctrl.19  ctrl.5 \n    241     172     108     266     607     462     510     656 \n\n\nIdeally we should rerun all steps of integration with that subset of cells instead of just taking the joint embedding. If you have too few cells per sample in the celltype that you want to cluster it may not be possible. We will start with selecting a new set of genes that better reflecs the variability within this celltype\n\nvar.out &lt;- modelGeneVar(tcells, block = tcells$sample)\nhvgs.tcell &lt;- getTopHVGs(var.out, n = 2000)\n\n# check overlap with the variable genes using all the data\nlength(intersect(metadata(sce)$hvgs, hvgs.tcell))\n\n[1] 982\n\n\nWe clearly have a very different geneset now, so hopefully it should better capture the variability within T-cells.\nNow we have to run the full pipeline with scaling, pca, integration and clustering on this subset of cells, using the new set of variable genes\n\ntcells = runPCA(tcells, exprs_values = \"logcounts\", ncomponents = 30, subset_row = hvgs.tcell, scale = TRUE)\n\n\nlibrary(harmony)\ntcells &lt;- RunHarmony(\n    tcells,\n    group.by.vars = \"sample\",\n    reduction.save = \"harmony\",\n    reduction = \"PCA\"\n)\n\n# Here we use all PCs computed from Harmony for UMAP calculation\ntcells &lt;- runUMAP(tcells, dimred = \"harmony\", n_dimred = 30, ncomponents = 2, name = \"UMAP_tcell\")\ntcells$leiden_tcell_k20 &lt;- clusterCells(tcells, use.dimred = \"harmony\", BLUSPARAM=SNNGraphParam(k=20, cluster.fun=\"leiden\",  cluster.args = list(resolution_parameter=0.3)))\n\n\nwrap_plots(\n    plotReducedDim(tcells, dimred = \"UMAP_on_Harmony\", colour_by = \"sample\") +ggtitle(\"Full umap\"),\n    plotReducedDim(tcells, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_k20\") +ggtitle(\"Full umap, full clust\"),\n    plotReducedDim(tcells, dimred = \"UMAP_on_Harmony\", colour_by = \"leiden_tcell_k20\") +ggtitle(\"Full umap, T-cell clust\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"sample\") +ggtitle(\"T-cell umap\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"leiden_k20\") +ggtitle(\"T-cell umap, full clust\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"leiden_tcell_k20\") +ggtitle(\"T-cell umap, T-cell clust\"),\n    ncol = 3\n)+ plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nAs you can see, we do have some new clusters that did not stand out before. But in general the separation looks very similar.\nLets also have a look at the same genes in the new umap:\n\nwrap_plots(\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"CD3E\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"CD4\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"CD8A\"),\n    plotReducedDim(tcells, dimred = \"UMAP_tcell\", colour_by = \"GNLY\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the T-cells in the umaps with all cells or only T/NK cells. What are the main differences? Do you think it improved with subclustering? Also, there are some cells in these clusters that fall far away from the rest in the UMAPs, why do you think that is?"
  },
  {
    "objectID": "labs/bioc/bioc_04_clustering.html#meta-session",
    "href": "labs/bioc/bioc_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] harmony_1.2.1               Rcpp_1.0.14                \n [3] bluster_1.12.0              clustree_0.5.1             \n [5] ggraph_2.2.1                igraph_2.0.3               \n [7] pheatmap_1.0.12             patchwork_1.3.0            \n [9] scran_1.30.0                scater_1.30.1              \n[11] ggplot2_3.5.1               scuttle_1.12.0             \n[13] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n[15] Biobase_2.62.0              GenomicRanges_1.54.1       \n[17] GenomeInfoDb_1.38.1         IRanges_2.36.0             \n[19] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[21] MatrixGenerics_1.14.0       matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n [1] bitops_1.0-9              gridExtra_2.3            \n [3] rlang_1.1.5               magrittr_2.0.3           \n [5] compiler_4.3.3            DelayedMatrixStats_1.24.0\n [7] vctrs_0.6.5               pkgconfig_2.0.3          \n [9] crayon_1.5.3              fastmap_1.2.0            \n[11] backports_1.5.0           XVector_0.42.0           \n[13] labeling_0.4.3            rmarkdown_2.29           \n[15] ggbeeswarm_0.7.2          purrr_1.0.2              \n[17] xfun_0.50                 zlibbioc_1.48.0          \n[19] cachem_1.1.0              beachmat_2.18.0          \n[21] jsonlite_1.8.9            DelayedArray_0.28.0      \n[23] BiocParallel_1.36.0       tweenr_2.0.3             \n[25] irlba_2.3.5.1             parallel_4.3.3           \n[27] cluster_2.1.8             R6_2.6.1                 \n[29] RColorBrewer_1.1-3        limma_3.58.1             \n[31] knitr_1.49                FNN_1.1.4.1              \n[33] Matrix_1.6-5              tidyselect_1.2.1         \n[35] abind_1.4-5               yaml_2.3.10              \n[37] viridis_0.6.5             codetools_0.2-20         \n[39] lattice_0.22-6            tibble_3.2.1             \n[41] withr_3.0.2               evaluate_1.0.3           \n[43] polyclip_1.10-7           pillar_1.10.1            \n[45] checkmate_2.3.2           generics_0.1.3           \n[47] RCurl_1.98-1.16           sparseMatrixStats_1.14.0 \n[49] munsell_0.5.1             scales_1.3.0             \n[51] RhpcBLASctl_0.23-42       glue_1.8.0               \n[53] metapod_1.10.0            tools_4.3.3              \n[55] BiocNeighbors_1.20.0      ScaledMatrix_1.10.0      \n[57] locfit_1.5-9.11           graphlayouts_1.2.2       \n[59] cowplot_1.1.3             tidygraph_1.3.0          \n[61] grid_4.3.3                tidyr_1.3.1              \n[63] edgeR_4.0.16              colorspace_2.1-1         \n[65] GenomeInfoDbData_1.2.11   beeswarm_0.4.0           \n[67] BiocSingular_1.18.0       ggforce_0.4.2            \n[69] vipor_0.4.7               cli_3.6.4                \n[71] rsvd_1.0.5                S4Arrays_1.2.0           \n[73] viridisLite_0.4.2         dplyr_1.1.4              \n[75] uwot_0.2.2                gtable_0.3.6             \n[77] digest_0.6.37             SparseArray_1.2.2        \n[79] ggrepel_0.9.6             dqrng_0.3.2              \n[81] htmlwidgets_1.6.4         farver_2.1.2             \n[83] memoise_2.0.1             htmltools_0.5.8.1        \n[85] lifecycle_1.0.4           statmod_1.5.0            \n[87] MASS_7.3-60.0.1"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html",
    "href": "labs/seurat/seurat_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-int_prep",
    "href": "labs/seurat/seurat_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(ggplot2)\n    library(patchwork)\n    library(basilisk)\n})\n\ncondapath = \"/usr/local/conda/envs/seurat\"\n\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_seurat/seurat_covid_qc_dr.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nalldata &lt;- readRDS(path_file)\nprint(names(alldata@reductions))\n\n[1] \"pca\"               \"umap\"              \"tsne\"             \n[4] \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\"\n\n\nWith Seurat5 we can split the RNA assay into multiple Layers with one count matrix and one data matrix per sample. When we then run FindVariableFeatures on the object it will run it for each of the samples separately, but also compute the overall variable features by combining their ranks.\n\n# get the variable genes from all the datasets without batch information.\nhvgs_old = VariableFeatures(alldata)\n\n# now split the object into layers\nalldata[[\"RNA\"]] &lt;- split(alldata[[\"RNA\"]], f = alldata$orig.ident)\n\n# detect HVGs\nalldata &lt;- FindVariableFeatures(alldata, selection.method = \"vst\", nfeatures = 2000, verbose = FALSE)\n\n# to get the HVGs for each layer we have to fetch them individually\ndata.layers &lt;- Layers(alldata)[grep(\"data.\",Layers(alldata))]\nprint(data.layers)\n\n[1] \"data.covid_1\"  \"data.covid_15\" \"data.covid_16\" \"data.covid_17\"\n[5] \"data.ctrl_5\"   \"data.ctrl_13\"  \"data.ctrl_14\"  \"data.ctrl_19\" \n\nhvgs_per_dataset &lt;- lapply(data.layers, function(x) VariableFeatures(alldata, layer = x) )\nnames(hvgs_per_dataset) = data.layers\n\n# also add in the variable genes that was selected on the whole dataset and the old ones \nhvgs_per_dataset$all &lt;- VariableFeatures(alldata)\nhvgs_per_dataset$old &lt;- hvgs_old\n\ntemp &lt;- unique(unlist(hvgs_per_dataset))\noverlap &lt;- sapply( hvgs_per_dataset , function(x) { temp %in% x } )\npheatmap::pheatmap(t(overlap*1),cluster_rows = F ,\n                   color = c(\"grey90\",\"grey20\"))\n\n\n\n\n\n\n\n\nAs you can see, there are a lot of genes that are variable in just one dataset. There are also some genes in the gene set that was selected using all the data that are not variable in any of the individual datasets. These are most likely genes driven by batch effects.\nA better way to select features for integration is to combine the information on variable genes across the dataset. This is what we have in the all section where the ranks of the variable features in the different datasets is combined.\n\n\n\n\n\n\nDiscuss\n\n\n\nDid you understand the difference between running variable gene selection per dataset and combining them vs running it on all samples together. Can you think of any situation where it would be best to run it on all samples and a situation where it should be done by batch?\n\n\nFor all downstream integration we will use this set of genes so that it is comparable across the methods. Before doing anything else we need to rerun ScaleData and PCA with that set of genes.\n\nhvgs_all = hvgs_per_dataset$all\n\nalldata = ScaleData(alldata, features = hvgs_all, vars.to.regress = c(\"percent_mito\", \"nFeature_RNA\"))\nalldata = RunPCA(alldata, features = hvgs_all, verbose = FALSE)"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#cca",
    "href": "labs/seurat/seurat_03_integration.html#cca",
    "title": " Data Integration",
    "section": "2 CCA",
    "text": "2 CCA\nIn Seurat v4 we run the integration in two steps, first finding anchors between datasets with FindIntegrationAnchors() and then running the actual integration with IntegrateData(). Since Seurat v5 this is done in a single command using the function IntegrateLayers(), we specify the name for the integration as integrated_cca.\n\nalldata &lt;- IntegrateLayers(object = alldata, \n                           method = CCAIntegration, orig.reduction = \"pca\", \n                           new.reduction = \"integrated_cca\", verbose = FALSE)\n\nWe should now have a new dimensionality reduction slot (integrated_cca) in the object:\n\nnames(alldata@reductions)\n\n[1] \"pca\"               \"umap\"              \"tsne\"             \n[4] \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\" \"integrated_cca\"   \n\n\nUsing this new integrated dimensionality reduction we can now run UMAP and tSNE on that object, and we again specify the names of the new reductions so that the old UMAP and tSNE are not overwritten.\n\nalldata &lt;- RunUMAP(alldata, reduction = \"integrated_cca\", dims = 1:30, reduction.name = \"umap_cca\")\nalldata &lt;- RunTSNE(alldata, reduction = \"integrated_cca\", dims = 1:30, reduction.name = \"tsne_cca\")\n\nnames(alldata@reductions)\n\n[1] \"pca\"               \"umap\"              \"tsne\"             \n[4] \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\" \"integrated_cca\"   \n[7] \"umap_cca\"          \"tsne_cca\"         \n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nwrap_plots(\n  DimPlot(alldata, reduction = \"pca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"PCA raw_data\"),\n  DimPlot(alldata, reduction = \"tsne\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"tSNE raw_data\"),\n  DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"UMAP raw_data\"),\n  \n  DimPlot(alldata, reduction = \"integrated_cca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"CCA integrated\"),\n  DimPlot(alldata, reduction = \"tsne_cca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"tSNE integrated\"),\n  DimPlot(alldata, reduction = \"umap_cca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"UMAP integrated\"),\n  ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n2.1 Marker genes\nLet’s plot some marker genes for different cell types onto the embedding.\n\n\n\nMarkers\nCell Type\n\n\n\n\nCD3E\nT cells\n\n\nCD3E CD4\nCD4+ T cells\n\n\nCD3E CD8A\nCD8+ T cells\n\n\nGNLY, NKG7\nNK cells\n\n\nMS4A1\nB cells\n\n\nCD14, LYZ, CST3, MS4A7\nCD14+ Monocytes\n\n\nFCGR3A, LYZ, CST3, MS4A7\nFCGR3A+ Monocytes\n\n\nFCER1A, CST3\nDCs\n\n\n\n\nmyfeatures &lt;- c(\"CD3E\", \"CD4\", \"CD8A\", \"NKG7\", \"GNLY\", \"MS4A1\", \"CD14\", \"LYZ\", \"MS4A7\", \"FCGR3A\", \"CST3\", \"FCER1A\")\nFeaturePlot(alldata, reduction = \"umap_cca\", dims = 1:2, features = myfeatures, ncol = 4, order = T) + NoLegend() + NoAxes() + NoGrid()"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-dimred_harmony",
    "href": "labs/seurat/seurat_03_integration.html#meta-dimred_harmony",
    "title": " Data Integration",
    "section": "3 Harmony",
    "text": "3 Harmony\nAn alternative method for integration is Harmony, for more details on the method, please se their paper Nat. Methods. This method runs the integration on a dimensionality reduction, in most applications the PCA. So first, we prefer to have scaling and PCA with the same set of genes that were used for the CCA integration, which we ran earlier.\nWe can use the same function IntegrateLayers() but intstead specify the method HarmonyIntegration. And as above, we run UMAP on the new reduction from Harmony.\n\nalldata &lt;- IntegrateLayers(\n  object = alldata, method = HarmonyIntegration,\n  orig.reduction = \"pca\", new.reduction = \"harmony\",\n  verbose = FALSE\n)\n\n\nalldata &lt;- RunUMAP(alldata, dims = 1:30, reduction = \"harmony\", reduction.name = \"umap_harmony\")\nDimPlot(alldata, reduction = \"umap_harmony\", group.by = \"orig.ident\") + NoAxes() + ggtitle(\"Harmony UMAP\")"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-dimred_scanorama",
    "href": "labs/seurat/seurat_03_integration.html#meta-dimred_scanorama",
    "title": " Data Integration",
    "section": "4 Scanorama",
    "text": "4 Scanorama\nAnother integration method is Scanorama (see Nat. Biotech.). This method is implemented in python, but we can run it through the Reticulate package.\nWe will run it with the same set of variable genes, but first we have to create a list of all the objects per sample.\nKeep in mind that for most python tools that uses AnnData format the gene x cell matrix is transposed so that genes are rows and cells are columns.\n\n# get data matrices from all samples, with only the variable genes.\ndata.layers &lt;- Layers(alldata)[grep(\"data.\",Layers(alldata))]\nprint(data.layers)\n\n[1] \"data.covid_1\"  \"data.covid_15\" \"data.covid_16\" \"data.covid_17\"\n[5] \"data.ctrl_5\"   \"data.ctrl_13\"  \"data.ctrl_14\"  \"data.ctrl_19\" \n\nassaylist &lt;- lapply(data.layers, function(x) t(as.matrix(LayerData(alldata, layer = x)[hvgs_all,])))\ngenelist =  rep(list(hvgs_all),length(assaylist))\n\nlapply(assaylist,dim)\n\n[[1]]\n[1]  875 2000\n\n[[2]]\n[1]  549 2000\n\n[[3]]\n[1]  357 2000\n\n[[4]]\n[1] 1057 2000\n\n[[5]]\n[1] 1033 2000\n\n[[6]]\n[1] 1126 2000\n\n[[7]]\n[1]  996 2000\n\n[[8]]\n[1] 1141 2000\n\n\nScanorama is implemented in python, but through reticulate we can load python packages and run python functions. In this case we also use the basilisk package for a more clean activation of python environment.\nAt the top of this script, we set the variable condapath to point to the conda environment where scanorama is included.\n\n# run scanorama via basilisk with assaylis and genelist as input.\nintegrated.data = basiliskRun(env=condapath, fun=function(datas, genes) {\n  scanorama &lt;- reticulate::import(\"scanorama\")\n  output &lt;- scanorama$integrate(datasets_full = datas,\n                                         genes_list = genes )\n  return(output)\n}, datas = assaylist, genes = genelist, testload=\"scanorama\")\n\nFound 2000 genes among all datasets\n[[0.         0.57741348 0.51540616 0.26206244 0.52274927 0.368\n  0.35085714 0.12      ]\n [0.         0.         0.73041894 0.35883424 0.41335915 0.2295082\n  0.28051002 0.15846995]\n [0.         0.         0.         0.24369748 0.47619048 0.50980392\n  0.3837535  0.28571429]\n [0.         0.         0.         0.         0.23136496 0.08514664\n  0.15421003 0.18141981]\n [0.         0.         0.         0.         0.         0.82768635\n  0.65343659 0.33829974]\n [0.         0.         0.         0.         0.         0.\n  0.75843694 0.53198948]\n [0.         0.         0.         0.         0.         0.\n  0.         0.69237511]\n [0.         0.         0.         0.         0.         0.\n  0.         0.        ]]\nProcessing datasets (4, 5)\nProcessing datasets (5, 6)\nProcessing datasets (1, 2)\nProcessing datasets (6, 7)\nProcessing datasets (4, 6)\nProcessing datasets (0, 1)\nProcessing datasets (5, 7)\nProcessing datasets (0, 4)\nProcessing datasets (0, 2)\nProcessing datasets (2, 5)\nProcessing datasets (2, 4)\nProcessing datasets (1, 4)\nProcessing datasets (2, 6)\nProcessing datasets (0, 5)\nProcessing datasets (1, 3)\nProcessing datasets (0, 6)\nProcessing datasets (4, 7)\nProcessing datasets (2, 7)\nProcessing datasets (1, 6)\nProcessing datasets (0, 3)\nProcessing datasets (2, 3)\nProcessing datasets (3, 4)\nProcessing datasets (1, 5)\nProcessing datasets (3, 7)\nProcessing datasets (1, 7)\nProcessing datasets (3, 6)\nProcessing datasets (0, 7)\n\n# Now we create a new dim reduction object in the format that Seurat uses\nintdimred &lt;- do.call(rbind, integrated.data[[1]])\ncolnames(intdimred) &lt;- paste0(\"Scanorama_\", 1:100)\nrownames(intdimred) &lt;- colnames(alldata)\n\n# Add standard deviations in order to draw Elbow Plots in Seurat\nstdevs &lt;- apply(intdimred, MARGIN = 2, FUN = sd)\n\n# Create a new dim red object.\nalldata[[\"scanorama\"]] &lt;- CreateDimReducObject(\n  embeddings = intdimred,\n  stdev      = stdevs,\n  key        = \"Scanorama_\",\n  assay      = \"RNA\")\n\nTry the same but using counts instead of data.\n\n# get count matrices from all samples, with only the variable genes.\ncount.layers &lt;- Layers(alldata)[grep(\"counts.\",Layers(alldata))]\nprint(count.layers)\n\n[1] \"counts.covid_1\"  \"counts.covid_15\" \"counts.covid_16\" \"counts.covid_17\"\n[5] \"counts.ctrl_5\"   \"counts.ctrl_13\"  \"counts.ctrl_14\"  \"counts.ctrl_19\" \n\nassaylist &lt;- lapply(count.layers, function(x) t(as.matrix(LayerData(alldata, layer = x)[hvgs_all,])))\n\n# run scanorama via basilisk with assaylis and genelist as input.\nintegrated.data = basiliskRun(env=condapath, fun=function(datas, genes) {\n  scanorama &lt;- reticulate::import(\"scanorama\")\n  output &lt;- scanorama$integrate(datasets_full = datas,\n                                         genes_list = genes )\n  return(output)\n}, datas = assaylist, genes = genelist, testload=\"scanorama\")\n\nFound 2000 genes among all datasets\n[[0.         0.45901639 0.50420168 0.26285714 0.51597289 0.54742857\n  0.44342857 0.21371429]\n [0.         0.         0.72313297 0.55373406 0.30418944 0.19307832\n  0.21857923 0.29184926]\n [0.         0.         0.         0.49019608 0.35014006 0.40336134\n  0.33053221 0.44817927]\n [0.         0.         0.         0.         0.29912875 0.15988647\n  0.1371807  0.25591586]\n [0.         0.         0.         0.         0.         0.73475315\n  0.64085189 0.40841367]\n [0.         0.         0.         0.         0.         0.\n  0.79484902 0.66520596]\n [0.         0.         0.         0.         0.         0.\n  0.         0.65907099]\n [0.         0.         0.         0.         0.         0.\n  0.         0.        ]]\nProcessing datasets (5, 6)\nProcessing datasets (4, 5)\nProcessing datasets (1, 2)\nProcessing datasets (5, 7)\nProcessing datasets (6, 7)\nProcessing datasets (4, 6)\nProcessing datasets (1, 3)\nProcessing datasets (0, 5)\nProcessing datasets (0, 4)\nProcessing datasets (0, 2)\nProcessing datasets (2, 3)\nProcessing datasets (0, 1)\nProcessing datasets (2, 7)\nProcessing datasets (0, 6)\nProcessing datasets (4, 7)\nProcessing datasets (2, 5)\nProcessing datasets (2, 4)\nProcessing datasets (2, 6)\nProcessing datasets (1, 4)\nProcessing datasets (3, 4)\nProcessing datasets (1, 7)\nProcessing datasets (0, 3)\nProcessing datasets (3, 7)\nProcessing datasets (1, 6)\nProcessing datasets (0, 7)\nProcessing datasets (1, 5)\nProcessing datasets (3, 5)\nProcessing datasets (3, 6)\n\n# Now we create a new dim reduction object in the format that Seurat uses\n# The scanorama output has 100 dimensions.\nintdimred &lt;- do.call(rbind, integrated.data[[1]])\ncolnames(intdimred) &lt;- paste0(\"Scanorama_\", 1:100)\nrownames(intdimred) &lt;- colnames(alldata)\n\n# Add standard deviations in order to draw Elbow Plots in Seurat\nstdevs &lt;- apply(intdimred, MARGIN = 2, FUN = sd)\n\n# Create a new dim red object.\nalldata[[\"scanoramaC\"]] &lt;- CreateDimReducObject(\n  embeddings = intdimred,\n  stdev      = stdevs,\n  key        = \"Scanorama_\",\n  assay      = \"RNA\")\n\n\n#Here we use all PCs computed from Scanorama for UMAP calculation\nalldata &lt;- RunUMAP(alldata, dims = 1:100, reduction = \"scanorama\",reduction.name = \"umap_scanorama\")\nalldata &lt;- RunUMAP(alldata, dims = 1:100, reduction = \"scanoramaC\",reduction.name = \"umap_scanoramaC\")\n\n\np1 = DimPlot(alldata, reduction = \"umap_scanorama\", group.by = \"orig.ident\") + NoAxes() + ggtitle(\"Scanorama UMAP\")\np2 = DimPlot(alldata, reduction = \"umap_scanoramaC\", group.by = \"orig.ident\") + NoAxes() + ggtitle(\"ScanoramaC UMAP\")\n\nwrap_plots(p1,p2)"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#overview-all-methods",
    "href": "labs/seurat/seurat_03_integration.html#overview-all-methods",
    "title": " Data Integration",
    "section": "5 Overview all methods",
    "text": "5 Overview all methods\nNow we will plot UMAPS with all three integration methods side by side.\n\np1 &lt;- DimPlot(alldata, reduction = \"umap\", group.by = \"orig.ident\") + ggtitle(\"UMAP raw_data\")\np2 &lt;- DimPlot(alldata, reduction = \"umap_cca\", group.by = \"orig.ident\") + ggtitle(\"UMAP CCA\")\np3 &lt;- DimPlot(alldata, reduction = \"umap_harmony\", group.by = \"orig.ident\") + ggtitle(\"UMAP Harmony\")\np4 &lt;- DimPlot(alldata, reduction = \"umap_scanorama\", group.by = \"orig.ident\")+ggtitle(\"UMAP Scanorama\")\n\nwrap_plots(p1, p2, p3, p4, nrow = 2) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLook at the different integration results, which one do you think looks the best? How would you motivate selecting one method over the other? How do you think you could best evaluate if the integration worked well?\n\n\nLet’s save the integrated data for further analysis.\n\nsaveRDS(alldata,\"data/covid/results/seurat_covid_qc_dr_int.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#extra-task",
    "href": "labs/seurat/seurat_03_integration.html#extra-task",
    "title": " Data Integration",
    "section": "6 Extra task",
    "text": "6 Extra task\nYou have now done the Seurat integration with CCA which is quite slow. There are other options in the IntegrateLayers() function. Try rerunning the integration with RPCAIntegration and create a new UMAP. Compare the results."
  },
  {
    "objectID": "labs/seurat/seurat_03_integration.html#meta-session",
    "href": "labs/seurat/seurat_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "7 Session info",
    "text": "7 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] basilisk_1.14.1    patchwork_1.3.0    ggplot2_3.5.1      Seurat_5.1.0      \n[5] SeuratObject_5.0.2 sp_2.2-0          \n\nloaded via a namespace (and not attached):\n  [1] deldir_2.0-4           pbapply_1.7-2          gridExtra_2.3         \n  [4] rlang_1.1.5            magrittr_2.0.3         RcppAnnoy_0.0.22      \n  [7] spatstat.geom_3.3-5    matrixStats_1.5.0      ggridges_0.5.6        \n [10] compiler_4.3.3         dir.expiry_1.10.0      png_0.1-8             \n [13] vctrs_0.6.5            reshape2_1.4.4         stringr_1.5.1         \n [16] pkgconfig_2.0.3        fastmap_1.2.0          labeling_0.4.3        \n [19] promises_1.3.2         rmarkdown_2.29         purrr_1.0.2           \n [22] xfun_0.50              jsonlite_1.8.9         goftest_1.2-3         \n [25] later_1.4.1            spatstat.utils_3.1-2   irlba_2.3.5.1         \n [28] parallel_4.3.3         cluster_2.1.8          R6_2.6.1              \n [31] ica_1.0-3              stringi_1.8.4          RColorBrewer_1.1-3    \n [34] spatstat.data_3.1-4    reticulate_1.40.0      parallelly_1.42.0     \n [37] spatstat.univar_3.1-1  lmtest_0.9-40          scattermore_1.2       \n [40] Rcpp_1.0.14            knitr_1.49             tensor_1.5            \n [43] future.apply_1.11.3    zoo_1.8-12             sctransform_0.4.1     \n [46] httpuv_1.6.15          Matrix_1.6-5           splines_4.3.3         \n [49] igraph_2.0.3           tidyselect_1.2.1       abind_1.4-5           \n [52] yaml_2.3.10            spatstat.random_3.3-2  codetools_0.2-20      \n [55] miniUI_0.1.1.1         spatstat.explore_3.3-4 listenv_0.9.1         \n [58] lattice_0.22-6         tibble_3.2.1           plyr_1.8.9            \n [61] basilisk.utils_1.14.1  withr_3.0.2            shiny_1.10.0          \n [64] ROCR_1.0-11            evaluate_1.0.3         Rtsne_0.17            \n [67] future_1.34.0          fastDummies_1.7.5      survival_3.8-3        \n [70] polyclip_1.10-7        fitdistrplus_1.2-2     filelock_1.0.3        \n [73] pillar_1.10.1          KernSmooth_2.23-26     plotly_4.10.4         \n [76] generics_0.1.3         RcppHNSW_0.6.0         munsell_0.5.1         \n [79] scales_1.3.0           globals_0.16.3         xtable_1.8-4          \n [82] RhpcBLASctl_0.23-42    glue_1.8.0             pheatmap_1.0.12       \n [85] lazyeval_0.2.2         tools_4.3.3            data.table_1.16.4     \n [88] RSpectra_0.16-2        RANN_2.6.2             leiden_0.4.3.1        \n [91] dotCall64_1.2          cowplot_1.1.3          grid_4.3.3            \n [94] tidyr_1.3.1            colorspace_2.1-1       nlme_3.1-167          \n [97] cli_3.6.4              spatstat.sparse_3.1-0  spam_2.11-1           \n[100] viridisLite_0.4.2      dplyr_1.1.4            uwot_0.2.2            \n[103] gtable_0.3.6           digest_0.6.37          progressr_0.15.1      \n[106] ggrepel_0.9.6          htmlwidgets_1.6.4      farver_2.1.2          \n[109] htmltools_0.5.8.1      lifecycle_1.0.4        httr_1.4.7            \n[112] mime_0.12              harmony_1.2.1          MASS_7.3-60.0.1"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html",
    "href": "labs/scanpy/scanpy_03_integration.html",
    "title": " Data Integration",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nIn this tutorial we will look at different ways of integrating multiple single cell RNA-seq datasets. We will explore a few different methods to correct for batch effects across datasets. Seurat uses the data integration method presented in Comprehensive Integration of Single Cell Data, while Scran and Scanpy use a mutual Nearest neighbour method (MNN). Below you can find a list of some methods for single data integration:"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-int_prep",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-int_prep",
    "title": " Data Integration",
    "section": "1 Data preparation",
    "text": "1 Data preparation\nLet’s first load necessary libraries and the data saved in the previous lab.\n\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport subprocess\n\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3             \n\nsc.settings.set_figure_params(dpi=80)\n%matplotlib inline\n\nCreate individual adata objects per batch.\n\n# download pre-computed data if missing or long compute\nfetch_data = True\n\n# url for source and intermediate data\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc_dr.h5ad\"\nif fetch_data and not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"covid/results_scanpy/scanpy_covid_qc_dr.h5ad\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 7332 × 2656\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n    uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap'\n    obsm: 'X_pca', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'\n\n\n\nprint(adata.X.shape)\n\n(7332, 2656)\n\n\nAs the stored AnnData object contains scaled data based on variable genes, we need to make a new object with the logtransformed normalized counts. The new variable gene selection should not be performed on the scaled data matrix.\n\n# First store the old set of hvgs\nvar_genes_all = adata.var.highly_variable\nprint(\"Highly variable genes: %d\"%sum(var_genes_all))\n\nadata = adata.raw.to_adata() \n\n# in some versions of Anndata there is an issue with information on the logtransformation in the slot log1p.base so we set it to None to not get errors.\nadata.uns['log1p']['base']=None\n\n# check that the matrix looks like normalized counts\nprint(adata.X[1:10,1:10])\n\nHighly variable genes: 2656\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 2 stored elements and shape (9, 9)&gt;\n  Coords    Values\n  (0, 3)    1.479703103222477\n  (7, 6)    1.6397408237842532"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#detect-variable-genes",
    "href": "labs/scanpy/scanpy_03_integration.html#detect-variable-genes",
    "title": " Data Integration",
    "section": "2 Detect variable genes",
    "text": "2 Detect variable genes\nVariable genes can be detected across the full dataset, but then we run the risk of getting many batch-specific genes that will drive a lot of the variation. Or we can select variable genes from each batch separately to get only celltype variation. In the dimensionality reduction exercise, we already selected variable genes, so they are already stored in adata.var.highly_variable.\nDetect variable genes in each dataset separately using the batch_key parameter.\n\nsc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key = 'sample')\n\nprint(\"Highly variable genes intersection: %d\"%sum(adata.var.highly_variable_intersection))\n\nprint(\"Number of batches where gene is variable:\")\nprint(adata.var.highly_variable_nbatches.value_counts())\n\nvar_genes_batch = adata.var.highly_variable_nbatches &gt; 0\n\nextracting highly variable genes\n    finished (0:00:03)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes intersection: 83\nNumber of batches where gene is variable:\n0    6760\n1    5164\n2    3560\n3    2050\n4    1003\n5     487\n6     228\n7     133\n8      83\nName: highly_variable_nbatches, dtype: int64\n\n\nCompare overlap of variable genes with batches or with all data.\n\nprint(\"Any batch var genes: %d\"%sum(var_genes_batch))\nprint(\"All data var genes: %d\"%sum(var_genes_all))\nprint(\"Overlap: %d\"%sum(var_genes_batch & var_genes_all))\nprint(\"Variable genes in all batches: %d\"%sum(adata.var.highly_variable_nbatches == 6))\nprint(\"Overlap batch instersection and all: %d\"%sum(var_genes_all & adata.var.highly_variable_intersection))\n\nAny batch var genes: 12708\nAll data var genes: 2656\nOverlap: 2654\nVariable genes in all batches: 228\nOverlap batch instersection and all: 83\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDid you understand the difference between running variable gene selection per dataset and combining them vs running it on all samples together. Can you think of any situation where it would be best to run it on all samples and a situation where it should be done by batch?\n\n\nSelect all genes that are variable in at least 2 datasets and use for remaining analysis.\n\nvar_select = adata.var.highly_variable_nbatches &gt; 2\nvar_genes = var_select.index[var_select]\nlen(var_genes)\n\n3984\n\n\nRun scaling and pca with that set of genes.\n\n# first store again the full matrix to the raw slot.\nadata.raw = adata\nadata = adata[:,var_genes]\n\nsc.pp.scale(adata)\nsc.tl.pca(adata, svd_solver='arpack')\n\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\ncomputing PCA\n    with n_comps=50\n    finished (0:00:04)\n\n\nBefore running integrations and new dimensionality reduction, lets save the old Umap and tSNE into a new slot in obsm.\n\nadata.obsm['X_umap_uncorr'] = adata.obsm['X_umap']\nadata.obsm['X_tsne_uncorr'] = adata.obsm['X_tsne']"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#bbknn",
    "href": "labs/scanpy/scanpy_03_integration.html#bbknn",
    "title": " Data Integration",
    "section": "3 BBKNN",
    "text": "3 BBKNN\nFirst, we will run BBKNN, it takes the anndata object and calculates a knn graph that is batch balanced. We can then use that graph to run Umap, tSNE and/or clustering.\n\nsc.external.pp.bbknn(adata, 'sample')\n\nsc.tl.umap(adata)\nsc.tl.tsne(adata)\n\n# save new umap/tsne to new slots in obsm\nadata.obsm['X_umap_bbknn'] = adata.obsm['X_umap']\nadata.obsm['X_tsne_bbknn'] = adata.obsm['X_tsne']\n\ncomputing batch balanced neighbors\nWARNING: consider updating your call to make use of `computation`\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:02)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:10)\ncomputing tSNE\n    using 'X_pca' with n_pcs = 50\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm)\n    'tsne', tSNE parameters (adata.uns) (0:00:12)\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.embedding(adata, \"X_umap_uncorr\",color=\"sample\", title=\"Uncorrected umap\", ax=axs[0,0], show=False)\nsc.pl.embedding(adata, \"X_tsne_uncorr\",color=\"sample\", title=\"Uncorrected tsne\", ax=axs[0,1], show=False)\nsc.pl.embedding(adata, \"X_umap_bbknn\",color=\"sample\", title=\"BBKNN Corrected umap\", ax=axs[1,0], show=False)\nsc.pl.embedding(adata, \"X_tsne_bbknn\",color=\"sample\", title=\"BBKNN Corrected tsne\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'BBKNN Corrected tsne'}, xlabel='X_tsne_bbknn1', ylabel='X_tsne_bbknn2'&gt;\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\nsave_file = './data/covid/results/scanpy_covid_qc_dr_bbknn.h5ad'\nadata.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#harmony",
    "href": "labs/scanpy/scanpy_03_integration.html#harmony",
    "title": " Data Integration",
    "section": "4 Harmony",
    "text": "4 Harmony\nAn alternative method for integration is Harmony, for more details on the method, please se their paper Nat. Methods. This method runs the integration on a dimensionality reduction, in most applications the PCA.\n\nimport scanpy.external as sce \nimport harmonypy as hm \n\nsce.pp.harmony_integrate(adata, 'sample')\n\n# Then we calculate a new umap and tsne.\nsc.pp.neighbors(adata, n_neighbors=10, n_pcs=30, use_rep='X_pca_harmony')\nsc.tl.umap(adata)\nsc.tl.tsne(adata, use_rep='X_pca_harmony')\nsc.tl.leiden(adata, resolution=0.5)\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:07)\ncomputing tSNE\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm)\n    'tsne', tSNE parameters (adata.uns) (0:00:19)\nrunning Leiden clustering\n    finished: found 12 clusters and added\n    'leiden', the cluster labels (adata.obs, categorical) (0:00:00)\n\n\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.embedding(adata, 'X_tsne_bbknn', color=\"sample\", title=\"BBKNN tsne\", ax=axs[0,0], show=False)\nsc.pl.tsne(adata, color=\"sample\", title=\"Harmony tsne\", ax=axs[0,1], show=False)\nsc.pl.embedding(adata, 'X_umap_bbknn', color=\"sample\", title=\"BBKNN umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Harmony umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Harmony umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\n# Store this umap and tsne with a new name.\nadata.obsm['X_umap_harmony'] = adata.obsm['X_umap']\nadata.obsm['X_tsne_harmony'] = adata.obsm['X_tsne']\n\n#save to file\nsave_file = './data/covid/results/scanpy_covid_qc_dr_harmony.h5ad'\nadata.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#combat",
    "href": "labs/scanpy/scanpy_03_integration.html#combat",
    "title": " Data Integration",
    "section": "5 Combat",
    "text": "5 Combat\nBatch correction can also be performed with combat. Note that ComBat batch correction requires a dense matrix format as input (which is already the case in this example).\n\n# create a new object with lognormalized counts\nadata_combat = sc.AnnData(X=adata.raw.X, var=adata.raw.var, obs = adata.obs)\n\n# first store the raw data \nadata_combat.raw = adata_combat\n\n# run combat\nsc.pp.combat(adata_combat, key='sample')\n\nStandardizing Data across genes.\n\nFound 8 batches\n\nFound 0 numerical variables:\n    \n\nFound 34 genes with zero variance.\nFitting L/S model and finding priors\n\nFinding parametric adjustments\n\nAdjusting data\n\n\n\nThen we run the regular steps of dimensionality reduction on the combat corrected data. Variable gene selection, pca and umap with combat data.\n\nsc.pp.highly_variable_genes(adata_combat)\nprint(\"Highly variable genes: %d\"%sum(adata_combat.var.highly_variable))\nsc.pl.highly_variable_genes(adata_combat)\n\nsc.pp.pca(adata_combat, n_comps=30, use_highly_variable=True, svd_solver='arpack')\n\nsc.pp.neighbors(adata_combat)\n\nsc.tl.umap(adata_combat)\nsc.tl.tsne(adata_combat)\n\nextracting highly variable genes\n    finished (0:00:00)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nHighly variable genes: 3271\ncomputing PCA\n    with n_comps=30\n    finished (0:00:02)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:08)\ncomputing tSNE\n    using 'X_pca' with n_pcs = 30\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm)\n    'tsne', tSNE parameters (adata.uns) (0:00:12)\n\n\n\n\n\n\n\n\n# compare var_genes\nvar_genes_combat = adata_combat.var.highly_variable\nprint(\"With all data %d\"%sum(var_genes_all))\nprint(\"With combat %d\"%sum(var_genes_combat))\nprint(\"Overlap %d\"%sum(var_genes_all & var_genes_combat))\n\nprint(\"With 2 batches %d\"%sum(var_select))\nprint(\"Overlap %d\"%sum(var_genes_combat & var_select))\n\nWith all data 2656\nWith combat 3271\nOverlap 1466\nWith 2 batches 3984\nOverlap 1815\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.tsne(adata, color=\"sample\", title=\"Harmony tsne\", ax=axs[0,0], show=False)\nsc.pl.tsne(adata_combat, color=\"sample\", title=\"Combat tsne\", ax=axs[0,1], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Harmony umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata_combat, color=\"sample\", title=\"Combat umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Combat umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\n# Add the dimred to the other adata object\nadata.obsm['X_umap_combat'] = adata_combat.obsm['X_umap']\nadata.obsm['X_tsne_combat'] = adata_combat.obsm['X_tsne']\nadata.obsm['X_pca_combat'] = adata_combat.obsm['X_pca']\n\n#save to file\nsave_file = './data/covid/results/scanpy_covid_qc_dr_combat.h5ad'\nadata_combat.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-int_scanorama",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-int_scanorama",
    "title": " Data Integration",
    "section": "6 Scanorama",
    "text": "6 Scanorama\nTry out Scanorama for data integration as well. First we need to create individual AnnData objects from each of the datasets.\nOBS! There is a function sc.external.pp.scanorama_integrate implemented in the scanpy toolkit. However, it runs scanorama on the PCA embedding and does not give us nice results when we have tested it, so we are not using it here.\n\n# split per batch into new objects.\nbatches = adata.obs['sample'].cat.categories.tolist()\nalldata = {}\nfor batch in batches:\n    alldata[batch] = adata[adata.obs['sample'] == batch,]\n\nalldata   \n\n{'covid_1': View of AnnData object with n_obs × n_vars = 888 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'covid_15': View of AnnData object with n_obs × n_vars = 599 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'covid_16': View of AnnData object with n_obs × n_vars = 371 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'covid_17': View of AnnData object with n_obs × n_vars = 1090 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'ctrl_5': View of AnnData object with n_obs × n_vars = 1039 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'ctrl_13': View of AnnData object with n_obs × n_vars = 1154 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'ctrl_14': View of AnnData object with n_obs × n_vars = 1039 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances',\n 'ctrl_19': View of AnnData object with n_obs × n_vars = 1152 × 3984\n     obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n     var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n     uns: 'doublet_info_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap', 'leiden'\n     obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_umap_uncorr', 'X_tsne_uncorr', 'X_umap_bbknn', 'X_tsne_bbknn', 'X_pca_harmony', 'X_umap_harmony', 'X_tsne_harmony', 'X_umap_combat', 'X_tsne_combat', 'X_pca_combat'\n     varm: 'PCs'\n     obsp: 'connectivities', 'distances'}\n\n\n\nimport scanorama\n\n#subset the individual dataset to the variable genes we defined at the beginning\nalldata2 = dict()\nfor ds in alldata.keys():\n    print(ds)\n    alldata2[ds] = alldata[ds][:,var_genes]\n\n#convert to list of AnnData objects\nadatas = list(alldata2.values())\n\n# run scanorama.integrate\nscanorama.integrate_scanpy(adatas, dimred = 50)\n\ncovid_1\ncovid_15\ncovid_16\ncovid_17\nctrl_5\nctrl_13\nctrl_14\nctrl_19\nFound 3984 genes among all datasets\n[[0.         0.63772955 0.61725067 0.29357798 0.56869369 0.57432432\n  0.48198198 0.19707207]\n [0.         0.         0.75202156 0.42737896 0.43022137 0.28547579\n  0.39732888 0.24874791]\n [0.         0.         0.         0.30188679 0.50134771 0.51212938\n  0.44204852 0.26145553]\n [0.         0.         0.         0.         0.30221367 0.13211009\n  0.20825688 0.28623853]\n [0.         0.         0.         0.         0.         0.89701636\n  0.71511068 0.32291667]\n [0.         0.         0.         0.         0.         0.\n  0.86915078 0.51128472]\n [0.         0.         0.         0.         0.         0.\n  0.         0.79861111]\n [0.         0.         0.         0.         0.         0.\n  0.         0.        ]]\nProcessing datasets (4, 5)\nProcessing datasets (5, 6)\nProcessing datasets (6, 7)\nProcessing datasets (1, 2)\nProcessing datasets (4, 6)\nProcessing datasets (0, 1)\nProcessing datasets (0, 2)\nProcessing datasets (0, 5)\nProcessing datasets (0, 4)\nProcessing datasets (2, 5)\nProcessing datasets (5, 7)\nProcessing datasets (2, 4)\nProcessing datasets (0, 6)\nProcessing datasets (2, 6)\nProcessing datasets (1, 4)\nProcessing datasets (1, 3)\nProcessing datasets (1, 6)\nProcessing datasets (4, 7)\nProcessing datasets (3, 4)\nProcessing datasets (2, 3)\nProcessing datasets (0, 3)\nProcessing datasets (3, 7)\nProcessing datasets (1, 5)\nProcessing datasets (2, 7)\nProcessing datasets (1, 7)\nProcessing datasets (3, 6)\nProcessing datasets (0, 7)\nProcessing datasets (3, 5)\n\n\n\n#scanorama adds the corrected matrix to adata.obsm in each of the datasets in adatas.\nadatas[0].obsm['X_scanorama'].shape\n\n(888, 50)\n\n\n\n# Get all the integrated matrices.\nscanorama_int = [ad.obsm['X_scanorama'] for ad in adatas]\n\n# make into one matrix.\nall_s = np.concatenate(scanorama_int)\nprint(all_s.shape)\n\n# add to the AnnData object, create a new object first\nadata.obsm[\"Scanorama\"] = all_s\n\n(7332, 50)\n\n\n\n# tsne and umap\nsc.pp.neighbors(adata, n_pcs =30, use_rep = \"Scanorama\")\nsc.tl.umap(adata)\nsc.tl.tsne(adata, n_pcs = 30, use_rep = \"Scanorama\")\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:08)\ncomputing tSNE\n    using sklearn.manifold.TSNE\n    finished: added\n    'X_tsne', tSNE coordinates (adata.obsm)\n    'tsne', tSNE parameters (adata.uns) (0:00:14)\n\n\nWe can now plot the unintegrated and the integrated space reduced dimensions.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.embedding(adata, 'X_tsne_harmony', color=\"sample\", title=\"Harmony tsne\", ax=axs[0,0], show=False)\nsc.pl.tsne(adata, color=\"sample\", title=\"Scanorama tsne\", ax=axs[0,1], show=False)\nsc.pl.embedding(adata, 'X_umap_harmony', color=\"sample\", title=\"Harmony umap\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Scanorama umap\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Scanorama umap'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\nLet’s save the integrated data for further analysis.\n\n# Store this umap and tsne with a new name.\nadata.obsm['X_umap_scanorama'] = adata.obsm['X_umap']\nadata.obsm['X_tsne_scanorama'] = adata.obsm['X_tsne']\n\n#save to file, now contains all integrations except the combat one.\nsave_file = './data/covid/results/scanpy_covid_qc_dr_int.h5ad'\nadata.write_h5ad(save_file)"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#overview-all-methods",
    "href": "labs/scanpy/scanpy_03_integration.html#overview-all-methods",
    "title": " Data Integration",
    "section": "7 Overview all methods",
    "text": "7 Overview all methods\nNow we will plot UMAPS with all three integration methods side by side.\n\nfig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\nsc.pl.embedding(adata, 'X_umap_uncorr', color=\"sample\", title=\"Uncorrected\", ax=axs[0,0], show=False)\nsc.pl.embedding(adata, 'X_umap_bbknn', color=\"sample\", title=\"BBKNN\", ax=axs[0,1], show=False)\nsc.pl.umap(adata_combat, color=\"sample\", title=\"Combat\", ax=axs[0,2], show=False)\nsc.pl.embedding(adata, 'X_umap_harmony', color=\"sample\", title=\"Harmony\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"sample\", title=\"Scanorama\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'Scanorama'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nLook at the different integration results, which one do you think looks the best? How would you motivate selecting one method over the other? How do you think you could best evaluate if the integration worked well?"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#extra-task",
    "href": "labs/scanpy/scanpy_03_integration.html#extra-task",
    "title": " Data Integration",
    "section": "8 Extra task",
    "text": "8 Extra task\nHave a look at the documentation for BBKNN\nTry changing some of the parameteres in BBKNN, such as distance metric, number of PCs and number of neighbors. How does the results change with different parameters? Can you explain why?"
  },
  {
    "objectID": "labs/scanpy/scanpy_03_integration.html#meta-session",
    "href": "labs/scanpy/scanpy_03_integration.html#meta-session",
    "title": " Data Integration",
    "section": "9 Session info",
    "text": "9 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nannoy               NA\nasttokens           NA\nbbknn               1.6.0\ncffi                1.17.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nfbpca               NA\nh5py                3.12.1\nharmonypy           0.0.10\nigraph              0.11.6\nintervaltree        NA\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npatsy               1.0.1\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nscanorama           1.7.4\nscipy               1.14.1\nsession_info        1.0.0\nsix                 1.17.0\nsklearn             1.6.1\nsortedcontainers    2.4.0\nsparse              0.15.5\nstack_data          0.6.3\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:23"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html",
    "href": "labs/bioc/bioc_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each cell type.\nIdeally celltype predictions should be run on each sample separately and not using the integrated data. In this case we will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to, even if that celltype is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nWe will use a reference PBMC dataset from the scPred package which is provided as a Seurat object with counts. And we will test classification based on the scPred and scMap methods. Finally we will use gene set enrichment predict celltype based on the DEGs of each cluster."
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_read",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_read",
    "title": " Celltype prediction",
    "section": "1 Read data",
    "text": "1 Read data\nFirst, lets load required libraries\n\nsuppressPackageStartupMessages({\n    library(scater)\n    library(scran)\n    library(dplyr)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(scPred)\n    library(scmap)\n    library(SingleR)\n})\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/bioc_covid_qc_dr_int_cl.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_bioc/bioc_covid_qc_dr_int_cl.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nalldata &lt;- readRDS(path_file)\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\nctrl.sce &lt;- alldata[, alldata$sample == \"ctrl.13\"]\n\n# remove all old dimensionality reductions as they will mess up the analysis further down\nreducedDims(ctrl.sce) &lt;- NULL"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_ref",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "2 Reference data",
    "text": "2 Reference data\nLoad the reference dataset with annotated labels that is provided by the scPred package, it is a subsampled set of cells from human PBMCs.\n\nreference &lt;- scPred::pbmc_1\nreference\n\nAn object of class Seurat \n32838 features across 3500 samples within 1 assay \nActive assay: RNA (32838 features, 0 variable features)\n 2 layers present: counts, data\n\n\nConvert to a SCE object.\n\nref.sce &lt;- Seurat::as.SingleCellExperiment(reference)\n\nRerun analysis pipeline. Run normalization, feature selection and dimensionality reduction\n\n# Normalize\nref.sce &lt;- computeSumFactors(ref.sce)\nref.sce &lt;- logNormCounts(ref.sce)\n\n# Variable genes\nvar.out &lt;- modelGeneVar(ref.sce, method = \"loess\")\nhvg.ref &lt;- getTopHVGs(var.out, n = 1000)\n\n# Dim reduction\nref.sce &lt;- runPCA(ref.sce,\n    exprs_values = \"logcounts\", scale = T,\n    ncomponents = 30, subset_row = hvg.ref\n)\nref.sce &lt;- runUMAP(ref.sce, dimred = \"PCA\")\n\n\nplotReducedDim(ref.sce, dimred = \"UMAP\", colour_by = \"cell_type\")\n\n\n\n\n\n\n\n\nRun all steps of the analysis for the ctrl sample as well. Use the clustering from the integration lab with resolution 0.5.\n\n# Normalize\nctrl.sce &lt;- computeSumFactors(ctrl.sce)\nctrl.sce &lt;- logNormCounts(ctrl.sce)\n\n# Variable genes\nvar.out &lt;- modelGeneVar(ctrl.sce, method = \"loess\")\nhvg.ctrl &lt;- getTopHVGs(var.out, n = 1000)\n\n# Dim reduction\nctrl.sce &lt;- runPCA(ctrl.sce, exprs_values = \"logcounts\", scale = T, ncomponents = 30, subset_row = hvg.ctrl)\nctrl.sce &lt;- runUMAP(ctrl.sce, dimred = \"PCA\")\n\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"leiden_k20\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#scmap",
    "href": "labs/bioc/bioc_06_celltyping.html#scmap",
    "title": " Celltype prediction",
    "section": "3 scMap",
    "text": "3 scMap\nThe scMap package is one method for projecting cells from a scRNA-seq experiment on to the cell-types or individual cells identified in a different experiment. It can be run on different levels, either projecting by cluster or by single cell, here we will try out both.\nFor scmap cell type labels must be stored in the cell_type1 column of the colData slots, and gene ids that are consistent across both datasets must be stored in the feature_symbol column of the rowData slots.\n\n3.1 scMap cluster\n\n# add in slot cell_type1\nref.sce$cell_type1 &lt;- ref.sce$cell_type\n# create a rowData slot with feature_symbol\nrd &lt;- data.frame(feature_symbol = rownames(ref.sce))\nrownames(rd) &lt;- rownames(ref.sce)\nrowData(ref.sce) &lt;- rd\n\n# same for the ctrl dataset\n# create a rowData slot with feature_symbol\nrd &lt;- data.frame(feature_symbol = rownames(ctrl.sce))\nrownames(rd) &lt;- rownames(ctrl.sce)\nrowData(ctrl.sce) &lt;- rd\n\nThen we can select variable features in both datasets.\n\n# select features\ncounts(ctrl.sce) &lt;- as.matrix(counts(ctrl.sce))\nlogcounts(ctrl.sce) &lt;- as.matrix(logcounts(ctrl.sce))\nctrl.sce &lt;- selectFeatures(ctrl.sce, suppress_plot = TRUE)\n\ncounts(ref.sce) &lt;- as.matrix(counts(ref.sce))\nlogcounts(ref.sce) &lt;- as.matrix(logcounts(ref.sce))\nref.sce &lt;- selectFeatures(ref.sce, suppress_plot = TRUE)\n\nThen we need to index the reference dataset by cluster, default is the clusters in cell_type1.\n\nref.sce &lt;- indexCluster(ref.sce)\n\nNow we project the Covid-19 dataset onto that index.\n\nproject_cluster &lt;- scmapCluster(\n    projection = ctrl.sce,\n    index_list = list(\n        ref = metadata(ref.sce)$scmap_cluster_index\n    )\n)\n\n# projected labels\ntable(project_cluster$scmap_cluster_labs)\n\n\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n         72         107         113          35         202         141 \n    NK cell         pDC Plasma cell  unassigned \n        280           2           1         158 \n\n\nThen add the predictions to metadata and plot UMAP.\n\n# add in predictions\nctrl.sce$scmap_cluster &lt;- project_cluster$scmap_cluster_labs\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cluster\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#scmap-cell",
    "href": "labs/bioc/bioc_06_celltyping.html#scmap-cell",
    "title": " Celltype prediction",
    "section": "4 scMap cell",
    "text": "4 scMap cell\nWe can instead index the refernce data based on each single cell and project our data onto the closest neighbor in that dataset.\n\nref.sce &lt;- indexCell(ref.sce)\n\nAgain we need to index the reference dataset.\n\nproject_cell &lt;- scmapCell(\n    projection = ctrl.sce,\n    index_list = list(\n        ref = metadata(ref.sce)$scmap_cell_index\n    )\n)\n\nWe now get a table with index for the 5 nearest neigbors in the reference dataset for each cell in our dataset. We will select the celltype of the closest neighbor and assign it to the data.\n\ncell_type_pred &lt;- colData(ref.sce)$cell_type1[project_cell$ref[[1]][1, ]]\ntable(cell_type_pred)\n\ncell_type_pred\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n         96         142         263          33         210         158 \n    NK cell         pDC Plasma cell \n        206           2           1 \n\n\nThen add the predictions to metadata and plot umap.\n\n# add in predictions\nctrl.sce$scmap_cell &lt;- cell_type_pred\n\nplotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\")\n\n\n\n\n\n\n\n\nPlot both:\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cluster\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\"),\n    ncol = 2\n)"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_singler",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_singler",
    "title": " Celltype prediction",
    "section": "5 SinlgeR",
    "text": "5 SinlgeR\nSingleR is performs unbiased cell type recognition from single-cell RNA sequencing data, by leveraging reference transcriptomic datasets of pure cell types to infer the cell of origin of each single cell independently.\nThere are multiple datasets included in the celldex package that can be used for celltype prediction, here we will test two different ones, the DatabaseImmuneCellExpressionData and the HumanPrimaryCellAtlasData. In addition we will use the same reference dataset that we used for label transfer above but using SingleR instead.\n\n5.1 Immune cell reference\n\nimmune = celldex::DatabaseImmuneCellExpressionData()\nsingler.immune &lt;- SingleR(test = ctrl.sce, ref = immune, assay.type.test=1,\n    labels = immune$label.main)\n\nhead(singler.immune)\n\nDataFrame with 6 rows and 4 columns\n                                               scores        labels delta.next\n                                             &lt;matrix&gt;   &lt;character&gt;  &lt;numeric&gt;\nAGGTCATGTGCGAACA-13  0.0679680:0.0760411:0.186694:... T cells, CD4+  0.1375513\nCCTATCGGTCCCTCAT-13  0.0027079:0.0960641:0.386088:...      NK cells  0.1490740\nTCCTCCCTCGTTCATT-13  0.0361115:0.1067465:0.394579:...      NK cells  0.1220681\nCAACCAATCATCTATC-13  0.0342030:0.1345967:0.402377:...      NK cells  0.1513308\nTACGGTATCGGATTAC-13 -0.0131813:0.0717678:0.283882:...      NK cells  0.0620657\nAATAGAGAGTTCGGTT-13  0.0841091:0.1367749:0.273738:... T cells, CD4+  0.0660296\n                    pruned.labels\n                      &lt;character&gt;\nAGGTCATGTGCGAACA-13 T cells, CD4+\nCCTATCGGTCCCTCAT-13      NK cells\nTCCTCCCTCGTTCATT-13      NK cells\nCAACCAATCATCTATC-13      NK cells\nTACGGTATCGGATTAC-13      NK cells\nAATAGAGAGTTCGGTT-13 T cells, CD4+\n\n\n\n\n5.2 HPCA reference\n\nhpca &lt;- HumanPrimaryCellAtlasData()\nsingler.hpca &lt;- SingleR(test = ctrl.sce, ref = hpca, assay.type.test=1,\n    labels = hpca$label.main)\n\nhead(singler.hpca)\n\nDataFrame with 6 rows and 4 columns\n                                            scores      labels delta.next\n                                          &lt;matrix&gt; &lt;character&gt;  &lt;numeric&gt;\nAGGTCATGTGCGAACA-13 0.141378:0.310009:0.275987:...     T_cells  0.4918992\nCCTATCGGTCCCTCAT-13 0.145926:0.300045:0.277827:...     NK_cell  0.3241970\nTCCTCCCTCGTTCATT-13 0.132119:0.311754:0.274127:...     NK_cell  0.0640608\nCAACCAATCATCTATC-13 0.157184:0.302219:0.284496:...     NK_cell  0.2012408\nTACGGTATCGGATTAC-13 0.125120:0.283118:0.250322:...     T_cells  0.1545913\nAATAGAGAGTTCGGTT-13 0.191441:0.374422:0.329988:...     T_cells  0.5063484\n                    pruned.labels\n                      &lt;character&gt;\nAGGTCATGTGCGAACA-13       T_cells\nCCTATCGGTCCCTCAT-13       NK_cell\nTCCTCCCTCGTTCATT-13       NK_cell\nCAACCAATCATCTATC-13       NK_cell\nTACGGTATCGGATTAC-13       T_cells\nAATAGAGAGTTCGGTT-13       T_cells\n\n\n\n\n5.3 With own reference data\n\nsingler.ref &lt;- SingleR(test=ctrl.sce, ref=ref.sce, labels=ref.sce$cell_type, de.method=\"wilcox\")\nhead(singler.ref)\n\nDataFrame with 6 rows and 4 columns\n                                            scores      labels delta.next\n                                          &lt;matrix&gt; &lt;character&gt;  &lt;numeric&gt;\nAGGTCATGTGCGAACA-13 0.741719:0.840093:0.805977:...  CD4 T cell  0.0423204\nCCTATCGGTCCCTCAT-13 0.649491:0.736753:0.815987:...     NK cell  0.0451715\nTCCTCCCTCGTTCATT-13 0.669603:0.731356:0.823308:...     NK cell  0.0865526\nCAACCAATCATCTATC-13 0.649948:0.721639:0.801202:...  CD8 T cell  0.0740195\nTACGGTATCGGATTAC-13 0.708827:0.776244:0.808044:...  CD8 T cell  0.0905218\nAATAGAGAGTTCGGTT-13 0.729010:0.847462:0.816299:...  CD4 T cell  0.0409309\n                    pruned.labels\n                      &lt;character&gt;\nAGGTCATGTGCGAACA-13    CD4 T cell\nCCTATCGGTCCCTCAT-13       NK cell\nTCCTCCCTCGTTCATT-13       NK cell\nCAACCAATCATCTATC-13    CD8 T cell\nTACGGTATCGGATTAC-13    CD8 T cell\nAATAGAGAGTTCGGTT-13    CD4 T cell\n\n\nCompare results:\n\nctrl.sce$singler.immune = singler.immune$pruned.labels\nctrl.sce$singler.hpca = singler.hpca$pruned.labels\nctrl.sce$singler.ref = singler.ref$pruned.labels\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.immune\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.hpca\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.ref\"),\n    ncol = 3\n)"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_compare",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_compare",
    "title": " Celltype prediction",
    "section": "6 Compare results",
    "text": "6 Compare results\nNow we will compare the output of the two methods using the convenient function in scPred crossTab() that prints the overlap between two metadata slots.\n\ntable(ctrl.sce$scmap_cell, ctrl.sce$singler.hpca)\n\n             \n              B_cell Macrophage Monocyte NK_cell Platelets T_cells\n  B cell          95          0        0       0         0       0\n  CD4 T cell       0          0        0       2         0     139\n  CD8 T cell       0          0        0     117         0     140\n  cDC              0          0       30       0         0       0\n  cMono            1          1      195       0         0       0\n  ncMono           1          1      153       0         1       0\n  NK cell          0          0        0     189         0      10\n  pDC              1          0        0       0         0       0\n  Plasma cell      1          0        0       0         0       0\n\n\nOr plot onto umap:\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cluster\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.immune\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.hpca\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.ref\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nAs you can see, the methods using the same reference all have similar results. While for instance singleR with different references give quite different predictions. This really shows that a relevant reference is the key in having reliable celltype predictions rather than the method used."
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-ct_gsea",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-ct_gsea",
    "title": " Celltype prediction",
    "section": "7 GSEA with celltype markers",
    "text": "7 GSEA with celltype markers\nAnother option, where celltype can be classified on cluster level is to use gene set enrichment among the DEGs with known markers for different celltypes. Similar to how we did functional enrichment for the DEGs in the differential expression exercise. There are some resources for celltype gene sets that can be used. Such as CellMarker, PanglaoDB or celltype gene sets at MSigDB. We can also look at overlap between DEGs in a reference dataset and the dataset you are analyzing.\n\n7.1 DEG overlap\nFirst, lets extract top DEGs for our Covid-19 dataset and the reference dataset. When we run differential expression for our dataset, we want to report as many genes as possible, hence we set the cutoffs quite lenient.\n\n# run differential expression in our dataset, using clustering at resolution 0.3\nDGE_list &lt;- scran::findMarkers(\n    x = alldata,\n    groups = as.character(alldata$leiden_k20),\n    pval.type = \"all\",\n    min.prop = 0\n)\n\n\n# Compute differential gene expression in reference dataset (that has cell annotation)\nref_DGE &lt;- scran::findMarkers(\n    x = ref.sce,\n    groups = as.character(ref.sce$cell_type),\n    pval.type = \"all\",\n    direction = \"up\"\n)\n\n# Identify the top cell marker genes in reference dataset\n# select top 50 with hihgest foldchange among top 100 signifcant genes.\nref_list &lt;- lapply(ref_DGE, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    x %&gt;%\n        as.data.frame() %&gt;%\n        filter(p.value &lt; 0.01) %&gt;%\n        top_n(-100, p.value) %&gt;%\n        top_n(50, logFC) %&gt;%\n        rownames()\n})\n\nunlist(lapply(ref_list, length))\n\n     B cell  CD4 T cell  CD8 T cell         cDC       cMono      ncMono \n         50          50          19          17          50          50 \n    NK cell         pDC Plasma cell \n         50          50          24 \n\n\nNow we can run GSEA for the DEGs from our dataset and check for enrichment of top DEGs in the reference dataset.\n\nsuppressPackageStartupMessages(library(fgsea))\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    gene_rank &lt;- setNames(x$logFC, rownames(x))\n    fgseaRes &lt;- fgsea(pathways = ref_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.1, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 2, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\nres\n\n$`1`\n      pathway         pval        padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;       &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:      cMono 0.0001076542 0.000484444  0.9513805  1.659747            0    47\n2:     ncMono 0.0001070205 0.000484444  0.8998402  1.575506            0    49\n3:    NK cell 0.0015197568 0.002343750 -0.7375281 -1.872188            0    49\n4:     B cell 0.0014025245 0.002343750 -0.7467564 -1.884577            0    47\n5: CD8 T cell 0.0005685048 0.001705514 -0.9345244 -1.917778            0    18\n6: CD4 T cell 0.0015625000 0.002343750 -0.7798324 -1.989129            0    50\n    leadingEdge\n         &lt;list&gt;\n1: S100A8, ....\n2: S100A11,....\n3: GNLY, NK....\n4: CXCR4, R....\n5: CCL5, IL....\n6: RPL3, IL....\n\n$`10`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:      cMono 0.0001154601 0.0005195705  0.9376287  1.750051            0    47\n2:     ncMono 0.0001149161 0.0005195705  0.8981789  1.681637            0    49\n3:        pDC 0.0950236693 0.1069016280  0.6923261  1.292203          822    47\n4:        cDC 0.0688836105 0.0885646420 -0.7083762 -1.444855          173    17\n5:    NK cell 0.0015384615 0.0023076923 -0.7086507 -1.795565            1    49\n6: CD8 T cell 0.0004012841 0.0012038523 -0.8805238 -1.831507            0    18\n7:     B cell 0.0007457122 0.0014229249 -0.7909288 -1.990145            0    47\n8: CD4 T cell 0.0007905138 0.0014229249 -0.8751524 -2.221244            0    50\n    leadingEdge\n         &lt;list&gt;\n1: S100A8, ....\n2: S100A4, ....\n3: CTSB, PL....\n4: HLA-DPB1....\n5: GNLY, NK....\n6: IL32, GZ....\n7: RPS5, RP....\n8: RPL3, RP....\n\n$`11`\n       pathway         pval         padj         ES       NES nMoreExtreme\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt;\n1:         pDC 0.0157068063 0.0235602094 -0.7249749 -1.468072          119\n2:         cDC 0.0055630732 0.0100135318 -0.8700304 -1.537075           36\n3:     NK cell 0.0029963523 0.0067417926 -0.7642624 -1.555252           22\n4: Plasma cell 0.0008605852 0.0025817556 -0.8842044 -1.635037            5\n5:       cMono 0.0001308901 0.0005890052 -0.8865040 -1.795168            0\n6:      ncMono 0.0001302762 0.0005890052 -0.9064454 -1.844590            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    47 PLEK, PA....\n2:    17 HLA-DRA,....\n3:    49 NKG7, B2....\n4:    24 RPL36AL,....\n5:    47 S100A6, ....\n6:    49 FTH1, S1....\n\n$`12`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:        cDC 0.0001220852 0.0009695142  0.9497624  1.591509            0    17\n2: CD4 T cell 0.0002154476 0.0009695142  0.8458436  1.562670            1    50\n3:        pDC 0.0153979614 0.0277163305  0.7612574  1.400365          141    47\n4:     ncMono 0.0712050922 0.1068076384  0.7022717  1.295862          659    49\n5: CD8 T cell 0.0011547344 0.0030695771 -0.9094652 -1.961383            1    18\n6:    NK cell 0.0013642565 0.0030695771 -0.8339656 -2.210332            0    49\n    leadingEdge\n         &lt;list&gt;\n1: HLA-DRA,....\n2: RPL5, RP....\n3: PPP1R14B....\n4: COTL1, A....\n5: CCL5, IL....\n6: NKG7, GN....\n\n$`2`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:     B cell 0.0001587806 0.0006147541  0.9657446  1.919709            0    47\n2: CD4 T cell 0.0001573317 0.0006147541  0.8855710  1.778772            0    50\n3:        cDC 0.0010413051 0.0016198704  0.9300426  1.603283            5    17\n4: CD8 T cell 0.0016486105 0.0021196420 -0.9129139 -1.687632            6    18\n5:      cMono 0.0010799136 0.0016198704 -0.7972154 -1.743186            3    47\n6:     ncMono 0.0002732240 0.0006147541 -0.8723829 -1.910654            0    49\n7:    NK cell 0.0002732240 0.0006147541 -0.9095437 -1.992042            0    49\n    leadingEdge\n         &lt;list&gt;\n1: MS4A1, C....\n2: RPS29, R....\n3: HLA-DRA,....\n4: CCL5, IL....\n5: LYZ, S10....\n6: S100A4, ....\n7: ITGB2, N....\n\n$`3`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: CD4 T cell 0.0001486547 0.0009146341  0.9766530  1.922438            0    50\n2:     B cell 0.0046268657 0.0069402985  0.7985055  1.560228           30    47\n3:    NK cell 0.0881097561 0.1132839721 -0.5962928 -1.328787          288    49\n4:        pDC 0.0012113870 0.0021804967 -0.7810776 -1.723785            3    47\n5:        cDC 0.0005042864 0.0011346445 -0.9323694 -1.731210            1    17\n6:      cMono 0.0003028468 0.0009146341 -0.9133823 -2.015772            0    47\n7:     ncMono 0.0003048780 0.0009146341 -0.9469756 -2.110254            0    49\n    leadingEdge\n         &lt;list&gt;\n1: IL7R, RP....\n2: RPS5, RP....\n3: NKG7, GN....\n4: PLEK, NP....\n5: HLA-DRA,....\n6: S100A9, ....\n7: FCER1G, ....\n\n$`4`\n       pathway         pval         padj         ES       NES nMoreExtreme\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt;\n1:     NK cell 0.0001407460 0.0006213324  0.9444606  1.872899            0\n2:  CD4 T cell 0.0002809778 0.0006213324  0.8912706  1.770319            1\n3:  CD8 T cell 0.0001554968 0.0006213324  0.9579691  1.651608            0\n4: Plasma cell 0.0237701219 0.0305615852  0.8176612  1.473258          157\n5:      B cell 0.0845827440 0.0951555870  0.6740450  1.329645          597\n6:         cDC 0.0066945607 0.0100418410 -0.8740728 -1.637344           23\n7:      ncMono 0.0003451847 0.0006213324 -0.8672835 -1.952424            0\n8:       cMono 0.0003410641 0.0006213324 -0.9067954 -2.028655            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    49 NKG7, GN....\n2:    50 RPS3, RP....\n3:    18 CCL5, IL....\n4:    24 RPL36AL,....\n5:    47 CXCR4, C....\n6:    17 HLA-DRA,....\n7:    49 FCER1G, ....\n8:    47 S100A9, ....\n\n$`5`\n       pathway         pval        padj         ES       NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;       &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:     NK cell 0.0001537279 0.001274788  0.9794204  1.986388            0    49\n2:  CD8 T cell 0.0034539474 0.005180921  0.9126339  1.607509           20    18\n3: Plasma cell 0.0233682514 0.030044895  0.8210124  1.511117          144    24\n4:      B cell 0.0033994334 0.005180921 -0.7288514 -1.630146           11    47\n5:      ncMono 0.0011438376 0.002573635 -0.7662987 -1.722308            3    49\n6:         cDC 0.0005112474 0.001533742 -0.9383143 -1.759558            1    17\n7:       cMono 0.0002832861 0.001274788 -0.8842132 -1.977628            0    47\n    leadingEdge\n         &lt;list&gt;\n1: GNLY, NK....\n2: CCL5, GZ....\n3: PPIB, FK....\n4: BIRC3, R....\n5: COTL1, F....\n6: HLA-DRA,....\n7: S100A9, ....\n\n$`6`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:        cDC 0.0142020680 0.0319546530 -0.8323141 -1.403660          113    17\n2:     B cell 0.0002450380 0.0007351139 -0.7993438 -1.532299            1    47\n3:      cMono 0.0001225190 0.0005513355 -0.8266230 -1.584591            0    47\n4: CD4 T cell 0.0001219215 0.0005513355 -0.9017402 -1.741123            0    50\n    leadingEdge\n         &lt;list&gt;\n1: HLA-DRB1....\n2: RPS23, R....\n3: JUND, S1....\n4: RPL34, R....\n\n$`7`\n       pathway         pval         padj         ES       NES nMoreExtreme\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt;\n1: Plasma cell 0.0020661157 0.0046487603  0.9025318  2.178514            0\n2:     NK cell 0.0055555556 0.0100000000  0.6565343  1.787421            0\n3:  CD8 T cell 0.0263157895 0.0263157895  0.7352301  1.718397           17\n4:         pDC 0.0239820390 0.0263157895 -0.7226835 -1.274055          234\n5:      B cell 0.0105112767 0.0135144986 -0.7433531 -1.310494          102\n6:         cDC 0.0100431965 0.0135144986 -0.8448613 -1.390448           92\n7:  CD4 T cell 0.0001018019 0.0003061537 -0.8724798 -1.542270            0\n8:       cMono 0.0001020512 0.0003061537 -0.8846901 -1.559664            0\n9:      ncMono 0.0001018123 0.0003061537 -0.9118589 -1.611116            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    24 JCHAIN, ....\n2:    49 NKG7, GN....\n3:    18 CCL5, GZ....\n4:    47 NPC2, CT....\n5:    47 CD37, RP....\n6:    17 HLA-DRA,....\n7:    50 RPL38, R....\n8:    47 LYZ, S10....\n9:    49 SAT1, FT....\n\n$`8`\n       pathway         pval         padj         ES       NES nMoreExtreme\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt;\n1:       cMono 0.0023094688 0.0041570439  0.9366222  2.248100            0\n2:      ncMono 0.0046948357 0.0070422535  0.7213799  1.746774            1\n3:  CD8 T cell 0.0147043154 0.0189055484 -0.8076532 -1.348074          137\n4:      B cell 0.0011495454 0.0025864772 -0.7682617 -1.370948           10\n5: Plasma cell 0.0003188437 0.0009565310 -0.8509078 -1.448435            2\n6:     NK cell 0.0001044277 0.0004699248 -0.8140750 -1.455427            0\n7:  CD4 T cell 0.0001042209 0.0004699248 -0.9151083 -1.638230            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    47 S100A9, ....\n2:    49 S100A4, ....\n3:    18 CCL5, IL....\n4:    47 RPL23A, ....\n5:    24 RPL36AL,....\n6:    49 HCST, CS....\n7:    50 RPS29, R....\n\n$`9`\n      pathway         pval         padj         ES       NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;      &lt;num&gt;     &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:     ncMono 0.0001061233 0.0009551098  0.9744272  1.685846            0    49\n2:        cDC 0.0160748560 0.0289347409  0.8763170  1.397840          133    17\n3:      cMono 0.0760962112 0.1141443167  0.7344356  1.269186          714    47\n4: CD4 T cell 0.0017667845 0.0039752650 -0.7236119 -1.869776            0    50\n5:    NK cell 0.0017271157 0.0039752650 -0.7480770 -1.918722            0    49\n6: CD8 T cell 0.0006191950 0.0027863777 -0.9337423 -1.972215            0    18\n    leadingEdge\n         &lt;list&gt;\n1: LST1, AI....\n2: HLA-DRA,....\n3: TYROBP, ....\n4: IL7R, LD....\n5: NKG7, GN....\n6: CCL5, IL....\n\n\nSelecting top significant overlap per cluster, we can now rename the clusters according to the predicted labels. OBS! Be aware that if you have some clusters that have non-significant p-values for all the gene sets, the cluster label will not be very reliable. Also, the gene sets you are using may not cover all the celltypes you have in your dataset and hence predictions may just be the most similar celltype. Also, some of the clusters have very similar p-values to multiple celltypes, for instance the ncMono and cMono celltypes are equally good for some clusters.\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\n\nalldata$ref_gsea &lt;- new.cluster.ids[as.character(alldata$leiden_k20)]\n\nwrap_plots(\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"leiden_k20\"),\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nCompare the results with the other celltype prediction methods in the ctrl_13 sample.\n\nctrl.sce$ref_gsea &lt;- alldata$ref_gsea[alldata$sample == \"ctrl.13\"]\n\nwrap_plots(\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"scmap_cell\"),\n    plotReducedDim(ctrl.sce, dimred = \"UMAP\", colour_by = \"singler.hpca\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\n\n\n7.2 With annotated gene sets\nWe have downloaded the celltype gene lists from http://bio-bigdata.hrbmu.edu.cn/CellMarker/CellMarker_download.html and converted the excel file to a csv for you. Read in the gene lists and do some filtering.\n\npath_file &lt;- file.path(\"data/human_cell_markers.txt\")\nif (!file.exists(path_file)) download.file(file.path(path_data, \"misc/cell_marker_human.csv\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\n\nmarkers &lt;- read.delim(\"data/human_cell_markers.txt\", sep = \";\")\nmarkers &lt;- markers[markers$speciesType == \"Human\", ]\nmarkers &lt;- markers[markers$cancerType == \"Normal\", ]\n\n# Filter by tissue (to reduce computational time and have tissue-specific classification)\n# sort(unique(markers$tissueType))\n# grep(\"blood\",unique(markers$tissueType),value = T)\n# markers &lt;- markers [ markers$tissueType %in% c(\"Blood\",\"Venous blood\",\n#                                                \"Serum\",\"Plasma\",\n#                                                \"Spleen\",\"Bone marrow\",\"Lymph node\"), ]\n\n\n# remove strange characters etc.\ncelltype_list &lt;- lapply(unique(markers$cellName), function(x) {\n    x &lt;- paste(markers$geneSymbol[markers$cellName == x], sep = \",\")\n    x &lt;- gsub(\"[[]|[]]| |-\", \",\", x)\n    x &lt;- unlist(strsplit(x, split = \",\"))\n    x &lt;- unique(x[!x %in% c(\"\", \"NA\", \"family\")])\n    x &lt;- casefold(x, upper = T)\n})\nnames(celltype_list) &lt;- unique(markers$cellName)\n# celltype_list &lt;- lapply(celltype_list , function(x) {x[1:min(length(x),50)]} )\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &lt; 100]\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &gt; 5]\n\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    x$logFC &lt;- rowSums(as.matrix(x[, grep(\"logFC\", colnames(x))]))\n    gene_rank &lt;- setNames(x$logFC, rownames(x))\n    fgseaRes &lt;- fgsea(pathways = celltype_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.01, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 5, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\n\n# show top 3 for each cluster.\nlapply(res, head, 3)\n\n$`1`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`10`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`11`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`12`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`2`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`3`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`4`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`5`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`6`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`7`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`8`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`9`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n\n#CT_GSEA8:\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\nalldata$cellmarker_gsea &lt;- new.cluster.ids[as.character(alldata$leiden_k20)]\n\nwrap_plots(\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"cellmarker_gsea\"),\n    plotReducedDim(alldata, dimred = \"UMAP\", colour_by = \"ref_gsea\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you think that the methods overlap well? Where do you see the most inconsistencies?\n\n\nIn this case we do not have any ground truth, and we cannot say which method performs best. You should keep in mind, that any celltype classification method is just a prediction, and you still need to use your common sense and knowledge of the biological system to judge if the results make sense.\nFinally, lets save the data with predictions.\n\nsaveRDS(ctrl.sce, \"data/covid/results/bioc_covid_qc_dr_int_cl_ct-ctrl13.rds\")"
  },
  {
    "objectID": "labs/bioc/bioc_06_celltyping.html#meta-session",
    "href": "labs/bioc/bioc_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "8 Session info",
    "text": "8 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] fgsea_1.28.0                celldex_1.12.0             \n [3] Seurat_5.1.0                SeuratObject_5.0.2         \n [5] sp_2.2-0                    SingleR_2.4.0              \n [7] scmap_1.24.0                scPred_1.9.2               \n [9] pheatmap_1.0.12             patchwork_1.3.0            \n[11] dplyr_1.1.4                 scran_1.30.0               \n[13] scater_1.30.1               ggplot2_3.5.1              \n[15] scuttle_1.12.0              SingleCellExperiment_1.24.0\n[17] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[19] GenomicRanges_1.54.1        GenomeInfoDb_1.38.1        \n[21] IRanges_2.36.0              S4Vectors_0.40.2           \n[23] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[25] matrixStats_1.5.0          \n\nloaded via a namespace (and not attached):\n  [1] spatstat.sparse_3.1-0         bitops_1.0-9                 \n  [3] lubridate_1.9.4               httr_1.4.7                   \n  [5] RColorBrewer_1.1-3            tools_4.3.3                  \n  [7] sctransform_0.4.1             R6_2.6.1                     \n  [9] lazyeval_0.2.2                uwot_0.2.2                   \n [11] withr_3.0.2                   gridExtra_2.3                \n [13] progressr_0.15.1              cli_3.6.4                    \n [15] spatstat.explore_3.3-4        fastDummies_1.7.5            \n [17] labeling_0.4.3                spatstat.data_3.1-4          \n [19] randomForest_4.7-1.2          proxy_0.4-27                 \n [21] ggridges_0.5.6                pbapply_1.7-2                \n [23] harmony_1.2.1                 parallelly_1.42.0            \n [25] limma_3.58.1                  RSQLite_2.3.9                \n [27] FNN_1.1.4.1                   generics_0.1.3               \n [29] ica_1.0-3                     spatstat.random_3.3-2        \n [31] Matrix_1.6-5                  ggbeeswarm_0.7.2             \n [33] abind_1.4-5                   lifecycle_1.0.4              \n [35] yaml_2.3.10                   edgeR_4.0.16                 \n [37] BiocFileCache_2.10.1          recipes_1.1.1                \n [39] SparseArray_1.2.2             Rtsne_0.17                   \n [41] blob_1.2.4                    grid_4.3.3                   \n [43] promises_1.3.2                dqrng_0.3.2                  \n [45] ExperimentHub_2.10.0          crayon_1.5.3                 \n [47] miniUI_0.1.1.1                lattice_0.22-6               \n [49] beachmat_2.18.0               cowplot_1.1.3                \n [51] KEGGREST_1.42.0               pillar_1.10.1                \n [53] knitr_1.49                    metapod_1.10.0               \n [55] future.apply_1.11.3           codetools_0.2-20             \n [57] fastmatch_1.1-6               leiden_0.4.3.1               \n [59] googleVis_0.7.3               glue_1.8.0                   \n [61] spatstat.univar_3.1-1         data.table_1.16.4            \n [63] vctrs_0.6.5                   png_0.1-8                    \n [65] spam_2.11-1                   gtable_0.3.6                 \n [67] cachem_1.1.0                  gower_1.0.1                  \n [69] xfun_0.50                     S4Arrays_1.2.0               \n [71] mime_0.12                     prodlim_2024.06.25           \n [73] survival_3.8-3                timeDate_4041.110            \n [75] iterators_1.0.14              hardhat_1.4.1                \n [77] lava_1.8.1                    statmod_1.5.0                \n [79] bluster_1.12.0                interactiveDisplayBase_1.40.0\n [81] fitdistrplus_1.2-2            ROCR_1.0-11                  \n [83] ipred_0.9-15                  nlme_3.1-167                 \n [85] bit64_4.5.2                   filelock_1.0.3               \n [87] RcppAnnoy_0.0.22              irlba_2.3.5.1                \n [89] vipor_0.4.7                   KernSmooth_2.23-26           \n [91] rpart_4.1.24                  DBI_1.2.3                    \n [93] colorspace_2.1-1              nnet_7.3-20                  \n [95] tidyselect_1.2.1              curl_6.0.1                   \n [97] bit_4.5.0.1                   compiler_4.3.3               \n [99] BiocNeighbors_1.20.0          DelayedArray_0.28.0          \n[101] plotly_4.10.4                 scales_1.3.0                 \n[103] lmtest_0.9-40                 rappdirs_0.3.3               \n[105] stringr_1.5.1                 digest_0.6.37                \n[107] goftest_1.2-3                 spatstat.utils_3.1-2         \n[109] rmarkdown_2.29                XVector_0.42.0               \n[111] htmltools_0.5.8.1             pkgconfig_2.0.3              \n[113] sparseMatrixStats_1.14.0      dbplyr_2.5.0                 \n[115] fastmap_1.2.0                 rlang_1.1.5                  \n[117] htmlwidgets_1.6.4             shiny_1.10.0                 \n[119] DelayedMatrixStats_1.24.0     farver_2.1.2                 \n[121] zoo_1.8-12                    jsonlite_1.8.9               \n[123] BiocParallel_1.36.0           ModelMetrics_1.2.2.2         \n[125] BiocSingular_1.18.0           RCurl_1.98-1.16              \n[127] magrittr_2.0.3                GenomeInfoDbData_1.2.11      \n[129] dotCall64_1.2                 munsell_0.5.1                \n[131] Rcpp_1.0.14                   viridis_0.6.5                \n[133] reticulate_1.40.0             stringi_1.8.4                \n[135] pROC_1.18.5                   zlibbioc_1.48.0              \n[137] MASS_7.3-60.0.1               AnnotationHub_3.10.0         \n[139] plyr_1.8.9                    parallel_4.3.3               \n[141] listenv_0.9.1                 ggrepel_0.9.6                \n[143] deldir_2.0-4                  Biostrings_2.70.1            \n[145] splines_4.3.3                 tensor_1.5                   \n[147] locfit_1.5-9.11               igraph_2.0.3                 \n[149] spatstat.geom_3.3-5           RcppHNSW_0.6.0               \n[151] reshape2_1.4.4                ScaledMatrix_1.10.0          \n[153] BiocVersion_3.18.1            evaluate_1.0.3               \n[155] BiocManager_1.30.25           foreach_1.5.2                \n[157] httpuv_1.6.15                 RANN_2.6.2                   \n[159] tidyr_1.3.1                   purrr_1.0.2                  \n[161] polyclip_1.10-7               future_1.34.0                \n[163] scattermore_1.2               rsvd_1.0.5                   \n[165] xtable_1.8-4                  e1071_1.7-16                 \n[167] RSpectra_0.16-2               later_1.4.1                  \n[169] viridisLite_0.4.2             class_7.3-23                 \n[171] tibble_3.2.1                  memoise_2.0.1                \n[173] AnnotationDbi_1.64.1          beeswarm_0.4.0               \n[175] cluster_2.1.8                 timechange_0.3.0             \n[177] globals_0.16.3                caret_6.0-94"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html",
    "href": "labs/scanpy/scanpy_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nIn this tutorial we will continue the analysis of the integrated dataset. We will use the scanpy enbedding to perform the clustering using graph community detection algorithms.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport subprocess\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=80)\n# download pre-computed data if missing or long compute\nfetch_data = True\n\n# url for source and intermediate data\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc_dr_int.h5ad\"\nif fetch_data and not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"covid/results_scanpy/scanpy_covid_qc_dr_int.h5ad\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 7332 × 3984\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n    uns: 'doublet_info_colors', 'hvg', 'leiden', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap'\n    obsm: 'Scanorama', 'X_pca', 'X_pca_combat', 'X_pca_harmony', 'X_tsne', 'X_tsne_bbknn', 'X_tsne_combat', 'X_tsne_harmony', 'X_tsne_scanorama', 'X_tsne_uncorr', 'X_umap', 'X_umap_bbknn', 'X_umap_combat', 'X_umap_harmony', 'X_umap_scanorama', 'X_umap_uncorr'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_graphclust",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps:\n- Build a kNN graph from the data.\n- Prune spurious connections from kNN graph (optional step). This is a SNN graph.\n- Find groups of cells that maximizes the connections within the group compared other groups.\nIn Scanpy we do not build an SNN graph, instead the community detection is done on the KNN graph which we construct using the command sc.pp.neighbors().\nThe main options to consider are:\n\nn_pcs - the number of dimensions from the initial reduction to include when calculating distances between cells.\nn_neighbors - the number of neighbors per cell to include in the KNN graph.\n\nIn this case, we will use the integrated data using Harmony. If you recall, we stored the harmony reduction in X_pca_harmony in the previous lab.\n\nsc.pp.neighbors(adata, n_neighbors=20, n_pcs=30, use_rep='X_pca_harmony')\n\n# We will also set the default umap to the one created with harmony\n# so that sc.pl.umap selects that embedding.\nadata.obsm[\"X_umap\"] = adata.obsm[\"X_umap_harmony\"]\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\n\n\nThe modularity optimization algoritm in Scanpy is Leiden. Previously ther was also Louvain, but since the Louvain algorithm is no longer maintained, using Leiden is recommended by the Scanpy community.\n\n1.1 Leiden\n\n# default resolution is 1.0, but we will try a few different values.\nsc.tl.leiden(adata, resolution = 0.4, key_added = \"leiden_0.4\")\nsc.tl.leiden(adata, resolution = 0.6, key_added = \"leiden_0.6\")\nsc.tl.leiden(adata, resolution = 1.0, key_added = \"leiden_1.0\")\nsc.tl.leiden(adata, resolution = 1.4, key_added = \"leiden_1.4\")\n\nrunning Leiden clustering\n    finished: found 9 clusters and added\n    'leiden_0.4', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Leiden clustering\n    finished: found 12 clusters and added\n    'leiden_0.6', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Leiden clustering\n    finished: found 16 clusters and added\n    'leiden_1.0', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Leiden clustering\n    finished: found 21 clusters and added\n    'leiden_1.4', the cluster labels (adata.obs, categorical) (0:00:00)\n\n\nPlot the clusters, as you can see, with increased resolution, we get higher granularity in the clustering.\n\nsc.pl.umap(adata, color=['leiden_0.4', 'leiden_0.6', 'leiden_1.0','leiden_1.4'], legend_fontsize=8)\n\n\n\n\n\n\nOnce we have done clustering, the relationships between clusters can be calculated as correlation in PCA space and we also visualize some of the marker genes that we used in the Dim Reduction lab onto the clusters. If we set dendrogram=True the clusters are ordered by the dendrogram in the dotplot.\n\nsc.tl.dendrogram(adata, groupby = \"leiden_0.6\")\nsc.pl.dendrogram(adata, groupby = \"leiden_0.6\")\n\ngenes  = [\"CD3E\", \"CD4\", \"CD8A\", \"GNLY\",\"NKG7\", \"MS4A1\",\"FCGR3A\",\"CD14\",\"LYZ\",\"CST3\",\"MS4A7\",\"FCGR1A\"]\nsc.pl.dotplot(adata, genes, groupby='leiden_0.6', dendrogram=True)\n\n    using 'X_pca' with n_pcs = 50\nStoring dendrogram info using `.uns['dendrogram_leiden_0.6']`"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_kmean",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans() function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\n\n# extract pca coordinates\nX_pca = adata.obsm['X_pca_harmony'] \n\n# kmeans with k=5\nkmeans = KMeans(n_clusters=5, random_state=0).fit(X_pca) \nadata.obs['kmeans5'] = kmeans.labels_.astype(str)\n\n# kmeans with k=10\nkmeans = KMeans(n_clusters=10, random_state=0).fit(X_pca) \nadata.obs['kmeans10'] = kmeans.labels_.astype(str)\n\n# kmeans with k=15\nkmeans = KMeans(n_clusters=15, random_state=0).fit(X_pca)\nadata.obs['kmeans15'] = kmeans.labels_.astype(str)\n\nsc.pl.umap(adata, color=['kmeans5', 'kmeans10', 'kmeans15'])\n\nadata.obsm\n\n\n\n\n\n\nAxisArrays with keys: Scanorama, X_pca, X_pca_combat, X_pca_harmony, X_tsne, X_tsne_bbknn, X_tsne_combat, X_tsne_harmony, X_tsne_scanorama, X_tsne_uncorr, X_umap, X_umap_bbknn, X_umap_combat, X_umap_harmony, X_umap_scanorama, X_umap_uncorr"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_hier",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\nHierarchical clustering is another generic form of clustering that can be applied also to scRNA-seq data. As K-means, it is typically applied to a reduced dimension representation of the data. Hierarchical clustering returns an entire hierarchy of partitionings (a dendrogram) that can be cut at different levels. Hierarchical clustering is done in these steps:\n\nDefine the distances between samples. The most common are Euclidean distance (a.k.a. straight line between two points) or correlation coefficients.\nDefine a measure of distances between clusters, called linkage criteria. It can for example be average distances between clusters. Commonly used methods are single, complete, average, median, centroid and ward.\nDefine the dendrogram among all samples using Bottom-up or Top-down approach. Bottom-up is where samples start with their own cluster which end up merged pair-by-pair until only one cluster is left. Top-down is where samples start all in the same cluster that end up being split by 2 until each sample has its own cluster.\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n\\[adj = \\frac{1- cor}{2}\\]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist() function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\nThe function AgglomerativeClustering has the option of running with disntance metrics “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. However, with ward linkage only euklidean distances works. Here we will try out euclidean distance and ward linkage calculated in PCA space.\n\nfrom sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters=5, linkage='ward')\nadata.obs['hclust_5'] = cluster.fit_predict(X_pca).astype(str)\n\ncluster = AgglomerativeClustering(n_clusters=10, linkage='ward')\nadata.obs['hclust_10'] = cluster.fit_predict(X_pca).astype(str)\n\ncluster = AgglomerativeClustering(n_clusters=15, linkage='ward')\nadata.obs['hclust_15'] = cluster.fit_predict(X_pca).astype(str)\n\nsc.pl.umap(adata, color=['hclust_5', 'hclust_10', 'hclust_15'])\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nadata.write_h5ad('./data/covid/results/scanpy_covid_qc_dr_int_cl.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_distribution",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_distribution",
    "title": " Clustering",
    "section": "4 Distribution of clusters",
    "text": "4 Distribution of clusters\nNow, we can select one of our clustering methods and compare the proportion of samples across the clusters.\nSelect the “leiden_0.6” and plot proportion of samples per cluster and also proportion covid vs ctrl.\nPlot proportion of cells from each condition per cluster.\n\ntmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['type'], normalize='index')\ntmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1), loc='upper right')\n\ntmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['sample'], normalize='index')\ntmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1),loc='upper right')\n\n&lt;matplotlib.legend.Legend at 0x7ffe8a4e6800&gt;\n\n\n\n\n\n\n\n\n\n\n\n\nIn this case we have quite good representation of each sample in each cluster. But there are clearly some biases with more cells from one sample in some clusters and also more covid cells in some of the clusters.\nWe can also plot it in the other direction, the proportion of each cluster per sample.\n\ntmp = pd.crosstab(adata.obs['sample'],adata.obs['leiden_0.6'], normalize='index')\ntmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.4, 1), loc='upper right')\n\n&lt;matplotlib.legend.Legend at 0x7ffe9223ca00&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated by quality metrics. Could it be explained biologically, or could there be a technical bias there?\n\n\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, groupby = 'leiden_0.6', rotation= 45)\n\n\n\n\n\n\nSome clusters that are clearly defined by higher number of genes and counts. These are either doublets or a larger celltype. And some clusters with low values on these metrics that are either low quality cells or a smaller celltype. You will have to explore these clusters in more detail to judge what you believe them to be."
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-clust_sub",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-clust_sub",
    "title": " Clustering",
    "section": "5 Subclustering of T and NK-cells",
    "text": "5 Subclustering of T and NK-cells\nIt is common that the subtypes of cells within a cluster is not so well separated when you have a heterogeneous dataset. In such a case it could be a good idea to run subclustering of individual celltypes. The main reason for subclustering is that the variable genes and the first principal components in the full analysis are mainly driven by differences between celltypes, while with subclustering we may detect smaller differences between subtypes within celltypes.\nSo first, lets find out where our T-cell and NK-cell clusters are. We know that T-cells express CD3E, and the main subtypes are CD4 and CD8, while NK-cells express GNLY.\n\n# check with the lowest resolution\nfig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(adata, color=\"leiden_0.4\", ax=axs[0,0], show=False, legend_loc = \"on data\")\nsc.pl.umap(adata, color=\"CD3E\", ax=axs[0,1], show=False)\nsc.pl.umap(adata, color=\"CD4\", ax=axs[0,2], show=False)\nsc.pl.umap(adata, color=\"CD8A\", ax=axs[1,0], show=False)\nsc.pl.umap(adata, color=\"GNLY\", ax=axs[1,1], show=False)\n\n&lt;Axes: title={'center': 'GNLY'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\nWe can clearly see what clusters are T-cell clusters, so lets subset the data for those cells\n\ntcells = adata[adata.obs[\"leiden_0.4\"].isin(['1','2','4','8']),:]\ntcells = tcells.raw.to_adata()\n\ntcells.obs[\"sample\"].value_counts()\n\nctrl_5      704\nctrl_13     624\nctrl_19     559\nctrl_14     523\ncovid_17    294\ncovid_1     287\ncovid_15    246\ncovid_16    132\nName: sample, dtype: int64\n\n\nIdeally we should rerun all steps of integration with that subset of cells instead of just taking the joint embedding. If you have too few cells per sample in the celltype that you want to cluster it may not be possible. We will start with selecting a new set of genes that better reflecs the variability within this celltype\n\nsc.pp.highly_variable_genes(tcells, min_mean=0.0125, max_mean=3, min_disp=0.5)\n\n\nprint(\"Full data:\" , sum(adata.var.highly_variable ))\nprint(\"Tcells:\" , sum(tcells.var.highly_variable))\nprint(\"Intersection:\" , sum(tcells.var.highly_variable & adata.var.highly_variable))\n\nextracting highly variable genes\n    finished (0:00:01)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\nFull data: 1926\nTcells: 2944\nIntersection: 945\n\n\nWe clearly have a very different geneset now, so hopefully it should better capture the variability within T-cells.\nNow we have to run the full pipeline with scaling, pca, integration and clustering on this subset of cells, using the new set of variable genes\n\nimport scanpy.external as sce \nimport harmonypy as hm \n\ntcells.raw = tcells\ntcells = tcells[:, tcells.var.highly_variable]\nsc.pp.regress_out(tcells, ['total_counts', 'pct_counts_mt'])\nsc.pp.scale(tcells, max_value=10)\nsc.tl.pca(tcells, svd_solver='arpack')\nsce.pp.harmony_integrate(tcells, 'sample')\nsc.pp.neighbors(tcells, n_neighbors=10, n_pcs=30, use_rep='X_pca_harmony')\nsc.tl.leiden(tcells, resolution = 0.6, key_added = \"tcells_0.6\")\nsc.tl.umap(tcells)\n\nregressing out ['total_counts', 'pct_counts_mt']\n    sparse input is densified and may lead to high memory use\n    finished (0:00:12)\ncomputing PCA\n    with n_comps=50\n    finished (0:00:06)\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\nrunning Leiden clustering\n    finished: found 12 clusters and added\n    'tcells_0.6', the cluster labels (adata.obs, categorical) (0:00:00)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:03)\n\n\n\nfig, axs = plt.subplots(2, 3, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(tcells, color=\"sample\", title=\"Tcell umap\", ax=axs[0,0], show=False)\nsc.pl.embedding(tcells, 'X_umap_harmony', color=\"sample\", title=\"Full umap\", ax=axs[1,0], show=False)\nsc.pl.umap(tcells, color=\"leiden_0.6\", title=\"Tcell umap, full clust\", ax=axs[0,1], show=False)\nsc.pl.embedding(tcells, 'X_umap_harmony', color=\"leiden_0.6\", title=\"Full umap, full clust\", ax=axs[1,1], show=False)\nsc.pl.umap(tcells, color=\"tcells_0.6\", title=\"Tcell umap, tcell clust\", ax=axs[0,2], show=False)\nsc.pl.embedding(tcells, 'X_umap_harmony', color=\"tcells_0.6\", title=\"Full umap, tcell clust\", ax=axs[1,2], show=False)\n\n&lt;Axes: title={'center': 'Full umap, tcell clust'}, xlabel='X_umap_harmony1', ylabel='X_umap_harmony2'&gt;\n\n\n\n\n\n\n\nAs you can see, we do have some new clusters that did not stand out before. But in general the separation looks very similar.\nWe can plot the subtype genes again. If you try plotting the genes with use_raw=False you will notice that some of the genes are not in the adata.X matrix. Since they are no longer included in the variable genes. So now we have to plot with use_raw=True.\n\nfig, axs = plt.subplots(2, 2, figsize=(10,8),constrained_layout=True)\nsc.pl.umap(tcells, color=\"CD3E\", ax=axs[0,0], show=False, use_raw=True)\nsc.pl.umap(tcells, color=\"CD4\", ax=axs[0,1], show=False, use_raw=True)\nsc.pl.umap(tcells, color=\"CD8A\", ax=axs[1,0], show=False, use_raw=True)\nsc.pl.umap(tcells, color=\"GNLY\", ax=axs[1,1], show=False, use_raw=True)\n\n&lt;Axes: title={'center': 'GNLY'}, xlabel='UMAP1', ylabel='UMAP2'&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the T-cells in the umaps with all cells or only T/NK cells. What are the main differences? Do you think it improved with subclustering? Also, there are some cells in these clusters that fall far away from the rest in the UMAPs, why do you think that is?"
  },
  {
    "objectID": "labs/scanpy/scanpy_04_clustering.html#meta-session",
    "href": "labs/scanpy/scanpy_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nasttokens           NA\ncffi                1.17.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nh5py                3.12.1\nharmonypy           0.0.10\nigraph              0.11.6\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npatsy               1.0.1\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nscipy               1.14.1\nseaborn             0.13.2\nsession_info        1.0.0\nsix                 1.17.0\nsklearn             1.6.1\nsparse              0.15.5\nstack_data          0.6.3\nstatsmodels         0.14.4\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:25"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html",
    "href": "labs/scanpy/scanpy_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each cell type.\nIdeally celltype predictions should be run on each sample separately and not using the integrated data. In this case we will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to, even if that celltype is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nHere we will use a reference PBMC dataset that we get from scanpy datasets and classify celltypes based on two methods:\nFirst, lets load required libraries\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport subprocess\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 2\nsc.settings.set_figure_params(dpi=80)\nLet’s read in the saved Covid-19 data object from the clustering step.\n# download pre-computed data if missing or long compute\nfetch_data = True\n\n# url for source and intermediate data\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_results = \"data/covid/results\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/covid/results/scanpy_covid_qc_dr_int_cl.h5ad\"\nif fetch_data and not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"covid/results_scanpy/scanpy_covid_qc_dr_int_cl.h5ad\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])    \n\nadata = sc.read_h5ad(path_file)\nadata\n\nAnnData object with n_obs × n_vars = 7332 × 3984\n    obs: 'type', 'sample', 'batch', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'n_genes', 'percent_chrY', 'XIST-counts', 'S_score', 'G2M_score', 'phase', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'leiden', 'leiden_0.4', 'leiden_0.6', 'leiden_1.0', 'leiden_1.4', 'kmeans5', 'kmeans10', 'kmeans15', 'hclust_5', 'hclust_10', 'hclust_15'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'\n    uns: 'dendrogram_leiden_0.6', 'doublet_info_colors', 'hclust_10_colors', 'hclust_15_colors', 'hclust_5_colors', 'hvg', 'kmeans10_colors', 'kmeans15_colors', 'kmeans5_colors', 'leiden', 'leiden_0.4', 'leiden_0.4_colors', 'leiden_0.6', 'leiden_0.6_colors', 'leiden_1.0', 'leiden_1.0_colors', 'leiden_1.4', 'leiden_1.4_colors', 'log1p', 'neighbors', 'pca', 'phase_colors', 'sample_colors', 'tsne', 'umap'\n    obsm: 'Scanorama', 'X_pca', 'X_pca_combat', 'X_pca_harmony', 'X_tsne', 'X_tsne_bbknn', 'X_tsne_combat', 'X_tsne_harmony', 'X_tsne_scanorama', 'X_tsne_uncorr', 'X_umap', 'X_umap_bbknn', 'X_umap_combat', 'X_umap_harmony', 'X_umap_scanorama', 'X_umap_uncorr'\n    varm: 'PCs'\n    obsp: 'connectivities', 'distances'\nadata.uns['log1p']['base']=None\nprint(adata.shape)\n# have only variable genes in X, use raw instead.\nadata = adata.raw.to_adata()\nprint(adata.shape)\n\n(7332, 3984)\n(7332, 19468)\nSubset one patient.\nadata = adata[adata.obs[\"sample\"] == \"ctrl_13\",:]\nprint(adata.shape)\n\n(1154, 19468)\nadata.obs[\"leiden_0.6\"].value_counts()\n\n1     276\n3     207\n0     200\n6     124\n2     123\n4      68\n5      49\n7      32\n8      23\n9      18\n10     18\n11     16\nName: leiden_0.6, dtype: int64\nSome clusters have very few cells from this individual, so any cluster comparisons may be biased by this.\nsc.pl.umap(\n    adata, color=[\"leiden_0.6\"], palette=sc.pl.palettes.default_20\n)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#meta-ct_ref",
    "href": "labs/scanpy/scanpy_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "1 Reference data",
    "text": "1 Reference data\nLoad the reference data from scanpy.datasets. It is the annotated and processed pbmc3k dataset from 10x.\n\nadata_ref = sc.datasets.pbmc3k_processed() \n\nadata_ref.obs['sample']='pbmc3k'\n\nprint(adata_ref.shape)\nadata_ref.obs\n\n(2638, 1838)\n\n\n\n\n\n\n\n\n\nn_genes\npercent_mito\nn_counts\nlouvain\nsample\n\n\nindex\n\n\n\n\n\n\n\n\n\nAAACATACAACCAC-1\n781\n0.030178\n2419.0\nCD4 T cells\npbmc3k\n\n\nAAACATTGAGCTAC-1\n1352\n0.037936\n4903.0\nB cells\npbmc3k\n\n\nAAACATTGATCAGC-1\n1131\n0.008897\n3147.0\nCD4 T cells\npbmc3k\n\n\nAAACCGTGCTTCCG-1\n960\n0.017431\n2639.0\nCD14+ Monocytes\npbmc3k\n\n\nAAACCGTGTATGCG-1\n522\n0.012245\n980.0\nNK cells\npbmc3k\n\n\n...\n...\n...\n...\n...\n...\n\n\nTTTCGAACTCTCAT-1\n1155\n0.021104\n3459.0\nCD14+ Monocytes\npbmc3k\n\n\nTTTCTACTGAGGCA-1\n1227\n0.009294\n3443.0\nB cells\npbmc3k\n\n\nTTTCTACTTCCTCG-1\n622\n0.021971\n1684.0\nB cells\npbmc3k\n\n\nTTTGCATGAGAGGC-1\n454\n0.020548\n1022.0\nB cells\npbmc3k\n\n\nTTTGCATGCCTCAC-1\n724\n0.008065\n1984.0\nCD4 T cells\npbmc3k\n\n\n\n\n2638 rows × 5 columns\n\n\n\nAs you can see, the celltype annotation is in the metadata column louvain, so that is the column we will have to use for classification.\n\nsc.pl.umap(adata_ref, color='louvain')\n\n\n\n\n\n\nMake sure we have the same genes in both datset by taking the intersection\n\n# before filtering genes, store the full matrix in raw.\nadata.raw = adata\n# also store the umap in a new slot as it will get overwritten\nadata.obsm[\"X_umap_uncorr\"] = adata.obsm[\"X_umap\"]\n\nprint(adata_ref.shape[1])\nprint(adata.shape[1])\nvar_names = adata_ref.var_names.intersection(adata.var_names)\nprint(len(var_names))\n\nadata_ref = adata_ref[:, var_names]\nadata = adata[:, var_names]\n\n1838\n19468\n1676\n\n\nFirst we need to rerun pca and umap with the same gene set for both datasets.\n\nsc.pp.pca(adata_ref)\nsc.pp.neighbors(adata_ref)\nsc.tl.umap(adata_ref)\nsc.pl.umap(adata_ref, color='louvain')\n\ncomputing PCA\n    with n_comps=50\n    finished (0:00:04)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 50\n    finished (0:00:07)\ncomputing UMAP\n    finished (0:00:03)\n\n\n\n\n\n\n\n\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.pl.umap(adata, color='leiden_0.6')\n\ncomputing PCA\n    with n_comps=50\n    finished (0:00:01)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 50\n    finished (0:00:00)\ncomputing UMAP\n    finished (0:00:01)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#integrate-with-scanorama",
    "href": "labs/scanpy/scanpy_06_celltyping.html#integrate-with-scanorama",
    "title": " Celltype prediction",
    "section": "2 Integrate with scanorama",
    "text": "2 Integrate with scanorama\n\nimport scanorama\n\n#subset the individual dataset to the same variable genes as in MNN-correct.\nalldata = dict()\nalldata['ctrl']=adata\nalldata['ref']=adata_ref\n\n#convert to list of AnnData objects\nadatas = list(alldata.values())\n\n# run scanorama.integrate\nscanorama.integrate_scanpy(adatas, dimred = 50)\n\nFound 1676 genes among all datasets\n[[0.         0.42894281]\n [0.         0.        ]]\nProcessing datasets (0, 1)\n\n\n\n# add in sample info\nadata_ref.obs['sample']='pbmc3k'\n\n# create a merged scanpy object and add in the scanorama \nadata_merged = alldata['ctrl'].concatenate(alldata['ref'], batch_key='sample', batch_categories=['ctrl','pbmc3k'])\n\nembedding = np.concatenate([ad.obsm['X_scanorama'] for ad in adatas], axis=0)\nadata_merged.obsm['Scanorama'] = embedding\n\n\n#run  umap.\nsc.pp.neighbors(adata_merged, n_pcs =50, use_rep = \"Scanorama\")\nsc.tl.umap(adata_merged)\n\ncomputing neighbors\n    finished (0:00:00)\ncomputing UMAP\n    finished (0:00:03)\n\n\n\nsc.pl.umap(adata_merged, color=[\"sample\",\"louvain\"])\n\n\n\n\n\n\n\n2.1 Label transfer\nUsing the functions from the Spatial tutorial from Scanpy we will calculate normalized cosine distances between the two datasets and tranfer labels to the celltype with the highest scores.\n\nfrom sklearn.metrics.pairwise import cosine_distances\n\ndistances = 1 - cosine_distances(\n    adata_merged[adata_merged.obs['sample'] == \"pbmc3k\"].obsm[\"Scanorama\"],\n    adata_merged[adata_merged.obs['sample'] == \"ctrl\"].obsm[\"Scanorama\"],\n)\n\ndef label_transfer(dist, labels, index):\n    lab = pd.get_dummies(labels)\n    class_prob = lab.to_numpy().T @ dist\n    norm = np.linalg.norm(class_prob, 2, axis=0)\n    class_prob = class_prob / norm\n    class_prob = (class_prob.T - class_prob.min(1)) / class_prob.ptp(1)\n    # convert to df\n    cp_df = pd.DataFrame(\n        class_prob, columns=lab.columns\n    )\n    cp_df.index = index\n    # classify as max score\n    m = cp_df.idxmax(axis=1)\n    \n    return m\n\nclass_def = label_transfer(distances, adata_ref.obs.louvain, adata.obs.index)\n\n# add to obs section of the original object\nadata.obs['label_trans'] = class_def\n\nsc.pl.umap(adata, color=\"label_trans\")\n\n\n\n\n\n\n\n# add to merged object.\nadata_merged.obs[\"label_trans\"] = pd.concat(\n    [class_def, adata_ref.obs[\"louvain\"]], axis=0\n).tolist()\n\nsc.pl.umap(adata_merged, color=[\"sample\",\"louvain\",'label_trans'])\n#plot only ctrl cells.\nsc.pl.umap(adata_merged[adata_merged.obs['sample']=='ctrl'], color='label_trans')\n\n\n\n\n\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\ntmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['label_trans'], normalize='index')\ntmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.8, 1),loc='upper right')\n\n&lt;matplotlib.legend.Legend at 0x7fffc3175720&gt;"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#ingest",
    "href": "labs/scanpy/scanpy_06_celltyping.html#ingest",
    "title": " Celltype prediction",
    "section": "3 Ingest",
    "text": "3 Ingest\nAnother method for celltype prediction is Ingest, for more information, please look at https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html\n\nsc.tl.ingest(adata, adata_ref, obs='louvain')\nsc.pl.umap(adata, color=['louvain','leiden_0.6'], wspace=0.5)\n\nrunning ingest\n    finished (0:00:16)\n\n\n\n\n\n\n\nAs you can see, ingest has created a new umap for us, so to get consistent plotting, lets revert back to the old one for further plotting:\n\nadata.obsm[\"X_umap\"] = adata.obsm[\"X_umap_uncorr\"]\n\nsc.pl.umap(adata, color=['louvain','leiden_0.6'], wspace=0.5)\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\ntmp = pd.crosstab(adata.obs['leiden_0.6'],adata.obs['louvain'], normalize='index')\ntmp.plot.bar(stacked=True).legend(bbox_to_anchor=(1.8, 1),loc='upper right')\n\n&lt;matplotlib.legend.Legend at 0x7ffe8aae2a40&gt;"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#celltypist",
    "href": "labs/scanpy/scanpy_06_celltyping.html#celltypist",
    "title": " Celltype prediction",
    "section": "4 Celltypist",
    "text": "4 Celltypist\nCelltypist provides pretrained models for classification for many different human tissues and celltypes. Here, we are following the steps of this tutorial, with some adaptations for this dataset. So please check out the tutorial for more detail.\n\nimport celltypist\nfrom celltypist import models\n\n# there are many different models, we will only download 2 of them for now.\nmodels.download_models(force_update = False, model = 'Immune_All_Low.pkl')\nmodels.download_models(force_update = False, model = 'Immune_All_High.pkl')\n\nNow select the model you want to use and show the info:\n\nmodel = models.Model.load(model = 'Immune_All_High.pkl')\n\nmodel\n\nCellTypist model with 32 cell types and 6639 features\n    date: 2022-07-16 08:53:00.959521\n    details: immune populations combined from 20 tissues of 18 studies\n    source: https://doi.org/10.1126/science.abl5197\n    version: v2\n    cell types: B cells, B-cell lineage, ..., pDC precursor\n    features: A1BG, A2M, ..., ZYX\n\n\nTo infer celltype labels to our cells, we first need to convert back to the full matrix. OBS! For celltypist we want to have log1p normalised expression to 10,000 counts per cell. Which we already have in adata.raw.X, check by summing up the data, it should sum to 10K.\n\nadata = adata.raw.to_adata() \nadata.X.expm1().sum(axis = 1)[:10]\n\nmatrix([[10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.],\n        [10000.]])\n\n\n\npredictions = celltypist.annotate(adata, model = 'Immune_All_High.pkl', majority_voting = True)\n\npredictions.predicted_labels\n\nrunning Leiden clustering\n    finished (0:00:00)\n\n\n\n\n\n\n\n\n\npredicted_labels\nover_clustering\nmajority_voting\n\n\n\n\nAGGTCATGTGCGAACA-13-5\nT cells\n15\nT cells\n\n\nCCTATCGGTCCCTCAT-13-5\nILC\n18\nILC\n\n\nTCCTCCCTCGTTCATT-13-5\nHSC/MPP\n23\nILC\n\n\nCAACCAATCATCTATC-13-5\nILC\n18\nILC\n\n\nTACGGTATCGGATTAC-13-5\nT cells\n5\nT cells\n\n\n...\n...\n...\n...\n\n\nTCCACCATCATAGCAC-13-5\nT cells\n15\nT cells\n\n\nGAGTTACAGTGAGTGC-13-5\nT cells\n11\nT cells\n\n\nATCATTCAGGCTCACC-13-5\nMonocytes\n20\nMonocytes\n\n\nAGCCACGCAACCCTAA-13-5\nT cells\n0\nT cells\n\n\nCTACCTGGTCAGGAGT-13-5\nILC\n32\nILC\n\n\n\n\n1154 rows × 3 columns\n\n\n\nThe first column predicted_labels is the predictions made for each individual cell, while majority_voting is done for local subclusters, the clustering identities are in column over_clustering.\nNow we convert the predictions to an anndata object.\n\nadata = predictions.to_adata()\n\nsc.pl.umap(adata, color = ['leiden_0.6', 'predicted_labels', 'majority_voting'], legend_loc = 'on data')\n\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nRerun predictions with Celltypist, but use another model, for instance Immune_All_High.pkl, or any other model you find relevant, you can find a list of models here. How do the results differ for you?\n\n\n\n4.1 Celltypist custom model\nWe can also train our own model on any reference data that we want to use. In this case we will use the pbmc data in adata_ref to train a model.\nCelltypist requires the data to be in the format of log1p normalised expression to 10,000 counts per cell, we can check if that is the case for the object we have:\n\nadata_ref.raw.X.expm1().sum(axis = 1)[:10]\n\nmatrix([[2419.],\n        [4903.],\n        [3147.],\n        [2639.],\n        [ 980.],\n        [2163.],\n        [2175.],\n        [2260.],\n        [1275.],\n        [1103.]], dtype=float32)\n\n\nThese should all sum up to 10K, which is not the case, probably since some genes were removed after normalizing. Wo we will have to start from the raw counts of that dataset instead. Before we selected the data pbmc3k_processed, but now we will instead use pbmc3k.\n\nadata_ref2 = sc.datasets.pbmc3k() \nadata_ref2\n\nAnnData object with n_obs × n_vars = 2700 × 32738\n    var: 'gene_ids'\n\n\nThis data is not annotated, so we will have to match the indices from the filtered and processed object. And add in the metadata with annotations.\n\nadata_ref2 = adata_ref2[adata_ref.obs_names,:]\nadata_ref2.obs = adata_ref.obs\nadata_ref2\n\nAnnData object with n_obs × n_vars = 2638 × 32738\n    obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'sample'\n    var: 'gene_ids'\n\n\nNow we can normalize the matrix:\n\nsc.pp.normalize_total(adata_ref2, target_sum = 1e4)\nsc.pp.log1p(adata_ref2)\n\n# check the sums again\nadata_ref2.X.expm1().sum(axis = 1)[:10]\n\nnormalizing counts per cell\n    finished (0:00:00)\n\n\nmatrix([[10000.   ],\n        [10000.   ],\n        [10000.   ],\n        [ 9999.998],\n        [ 9999.998],\n        [10000.   ],\n        [ 9999.999],\n        [10000.   ],\n        [10000.001],\n        [10000.   ]], dtype=float32)\n\n\nAnd finally train the model.\n\nnew_model = celltypist.train(adata_ref2, labels = 'louvain', n_jobs = 10, feature_selection = True)\n\nNow we can run predictions on our data\n\npredictions2 = celltypist.annotate(adata, model = new_model, majority_voting = True)\n\nrunning Leiden clustering\n    finished (0:00:00)\n\n\nInstead of converting the predictions to anndata we will just add another column in the adata.obs with these new predictions since the column names from the previous celltypist runs with clash.\n\nadata.obs[\"predicted_labels_ref\"] = predictions2.predicted_labels[\"predicted_labels\"]\nadata.obs[\"majority_voting_ref\"] = predictions2.predicted_labels[\"majority_voting\"]\n\n\nsc.pl.umap(adata, color = ['predicted_labels', 'majority_voting','predicted_labels_ref', 'majority_voting_ref'], legend_loc = 'on data', ncols=2)"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#compare-results",
    "href": "labs/scanpy/scanpy_06_celltyping.html#compare-results",
    "title": " Celltype prediction",
    "section": "5 Compare results",
    "text": "5 Compare results\nThe predictions from ingest is stored in the column ‘louvain’ while we named the label transfer with scanorama as ‘predicted’\n\nsc.pl.umap(adata, color=['louvain','label_trans','majority_voting', 'majority_voting_ref'], wspace=0.5, ncols=3)\n\n\n\n\n\n\nAs you can see, the main celltypes are generally the same, but there are clearly differences, especially with regards to the cells predicted as either ILC/NK/CD8 T-cells.\nThe only way to make sure which method you trust is to look at what genes the different celltypes express and use your biological knowledge to make decisions."
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#gene-set-analysis",
    "href": "labs/scanpy/scanpy_06_celltyping.html#gene-set-analysis",
    "title": " Celltype prediction",
    "section": "6 Gene set analysis",
    "text": "6 Gene set analysis\nAnother way of predicting celltypes is to use the differentially expressed genes per cluster and compare to lists of known cell marker genes. This requires a list of genes that you trust and that is relevant for the tissue you are working on.\nYou can either run it with a marker list from the ontology or a list of your choice as in the example below.\n\npath_file = 'data/human_cell_markers.txt'\nif not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"misc/human_cell_markers.txt\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])\n\n\ndf = pd.read_table(path_file)\ndf\n\nprint(df.shape)\n\n(2868, 15)\n\n\n\n# Filter for number of genes per celltype\ndf['nG'] = df.geneSymbol.str.split(\",\").str.len()\n\ndf = df[df['nG'] &gt; 5]\ndf = df[df['nG'] &lt; 100]\nd = df[df['cancerType'] == \"Normal\"]\nprint(df.shape)\n\n# convert to dict.\ndf.index = df.cellName\ngene_dict = df.geneSymbol.str.split(\",\").to_dict()\n\n(445, 16)\n\n\n\n# run differential expression per cluster\nsc.tl.rank_genes_groups(adata, 'leiden_0.6', method='wilcoxon', key_added = \"wilcoxon\")\n\nranking genes\n    finished (0:00:01)\n\n\n\n# do gene set overlap to the groups in the gene list and top 300 DEGs.\nimport gseapy\n\ngsea_res = dict()\npred = dict()\n\nfor cl in adata.obs['leiden_0.6'].cat.categories.tolist():\n    print(cl)\n    glist = sc.get.rank_genes_groups_df(adata, group=cl, key='wilcoxon')[\n        'names'].squeeze().str.strip().tolist()\n    enr_res = gseapy.enrichr(gene_list=glist[:300],\n                             organism='Human',\n                             gene_sets=gene_dict,\n                             background=adata.shape[1],\n                             cutoff=1)\n    if enr_res.results.shape[0] == 0:\n        pred[cl] = \"Unass\"\n    else:\n        enr_res.results.sort_values(\n            by=\"P-value\", axis=0, ascending=True, inplace=True)\n        print(enr_res.results.head(2))\n        gsea_res[cl] = enr_res\n        pred[cl] = enr_res.results[\"Term\"][0]\n\n0\n   Gene_set                   Term Overlap   P-value  Adjusted P-value  \\\n0  gs_ind_0  Cancer stem-like cell     1/6  0.088981          0.206048   \n5  gs_ind_0             Macrophage     1/6  0.088981          0.206048   \n\n   Odds Ratio  Combined Score  Genes  \n0   17.450448       42.218477  ANPEP  \n5   17.450448       42.218477   AIF1  \n1\n   Gene_set                      Term Overlap   P-value  Adjusted P-value  \\\n3  gs_ind_0  Parietal progenitor cell     1/7  0.103024          0.255621   \n0  gs_ind_0           Effector T cell    1/13  0.182865          0.255621   \n\n   Odds Ratio  Combined Score  Genes  \n3   14.764993       33.557802  ANXA1  \n0    7.675392       13.040543  IL2RB  \n2\n   Gene_set                    Term Overlap   P-value  Adjusted P-value  \\\n2  gs_ind_0  Effector memory T cell     1/7  0.103024          0.206048   \n5  gs_ind_0                Monocyte     1/7  0.103024          0.206048   \n\n   Odds Ratio  Combined Score Genes  \n2   14.764993       33.557802  IL7R  \n5   14.764993       33.557802  CD52  \n3\n   Gene_set                    Term Overlap   P-value  Adjusted P-value  \\\n3  gs_ind_0  Effector memory T cell     1/7  0.103024          0.215807   \n5  gs_ind_0                Monocyte     1/7  0.103024          0.215807   \n\n   Odds Ratio  Combined Score Genes  \n3   14.764993       33.557802  IL7R  \n5   14.764993       33.557802  CD52  \n4\n   Gene_set              Term Overlap   P-value  Adjusted P-value  Odds Ratio  \\\n2  gs_ind_0          Monocyte     1/7  0.103024          0.116851   14.764993   \n0  gs_ind_0  CD4-CD28+ T cell     1/8  0.116851          0.116851   12.795659   \n\n   Combined Score Genes  \n2       33.557802  CD52  \n0       27.470422  BCL2  \n5\n    Gene_set                      Term Overlap   P-value  Adjusted P-value  \\\n1   gs_ind_0     Cancer stem-like cell     1/6  0.088981          0.203113   \n21  gs_ind_0  Spermatogonial stem cell     1/6  0.088981          0.203113   \n\n    Odds Ratio  Combined Score  Genes  \n1    17.450448       42.218477  ANPEP  \n21   17.450448       42.218477   BCL6  \n6\n   Gene_set                             Term Overlap   P-value  \\\n1  gs_ind_0                       Macrophage     1/6  0.088981   \n2  gs_ind_0  Monocyte derived dendritic cell     1/8  0.116851   \n\n   Adjusted P-value  Odds Ratio  Combined Score  Genes  \n1          0.175277   17.450448       42.218477   AIF1  \n2          0.175277   12.795659       27.470422  ITGAX  \n7\n   Gene_set      Term Overlap   P-value  Adjusted P-value  Odds Ratio  \\\n0  gs_ind_0    B cell     1/6  0.088981          0.116851   17.450448   \n2  gs_ind_0  Monocyte     1/7  0.103024          0.116851   14.764993   \n\n   Combined Score Genes  \n0       42.218477  CD19  \n2       33.557802  CD52  \n8\n   Gene_set        Term Overlap   P-value  Adjusted P-value  Odds Ratio  \\\n2  gs_ind_0  Macrophage     1/6  0.088981          0.154536   17.450448   \n4  gs_ind_0  Myeloblast     1/6  0.088981          0.154536   17.450448   \n\n   Combined Score  Genes  \n2       42.218477   AIF1  \n4       42.218477  CSF3R  \n9\n   Gene_set             Term Overlap   P-value  Adjusted P-value  Odds Ratio  \\\n4  gs_ind_0    T helper cell    1/10  0.143872          0.319526   10.100782   \n1  gs_ind_0  Effector T cell    1/13  0.182865          0.319526    7.675392   \n\n   Combined Score  Genes  \n4       19.583741  ABCB1  \n1       13.040543  IL2RB  \n10\n   Gene_set                                 Term Overlap   P-value  \\\n1  gs_ind_0             PROM1Low progenitor cell     1/7  0.103024   \n0  gs_ind_0  Myeloid conventional dendritic cell    1/17  0.232116   \n\n   Adjusted P-value  Odds Ratio  Combined Score  Genes  \n1          0.206048   14.764993       33.557802  ALCAM  \n0          0.232116    5.813477        8.490677   CD1C  \n11\n    Gene_set                             Term Overlap   P-value  \\\n1   gs_ind_0            Cancer stem-like cell     1/6  0.088981   \n16  gs_ind_0  Myeloid-derived suppressor cell     1/6  0.088981   \n\n    Adjusted P-value  Odds Ratio  Combined Score  Genes  \n1           0.191829   17.450448       42.218477  ANPEP  \n16          0.191829   17.450448       42.218477  ITGAM  \n\n\n\n# prediction per cluster\npred\n\n{'0': 'Cancer stem-like cell',\n '1': 'Effector T cell',\n '2': 'CD4+ T cell',\n '3': 'CD4+ T cell',\n '4': 'CD4-CD28+ T cell',\n '5': 'CD16+ dendritic cell',\n '6': 'Conventional dendritic cell',\n '7': 'B cell',\n '8': 'Immune cell',\n '9': 'Circulating fetal cell',\n '10': 'Myeloid conventional dendritic cell',\n '11': 'CD16+ dendritic cell'}\n\n\n\nprediction = [pred[x] for x in adata.obs['leiden_0.6']]\nadata.obs[\"GS_overlap_pred\"] = prediction\n\nsc.pl.umap(adata, color='GS_overlap_pred')\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nAs you can see, it agrees to some extent with the predictions from the methods above, but there are clear differences, which do you think looks better?"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#meta-dimred_save",
    "href": "labs/scanpy/scanpy_06_celltyping.html#meta-dimred_save",
    "title": " Celltype prediction",
    "section": "7 Save data",
    "text": "7 Save data\nWe can finally save the object for use in future steps.\n\nadata.write_h5ad('data/covid/results/scanpy_covid_qc_dr_int_cl_ct-ctrl13.h5ad')"
  },
  {
    "objectID": "labs/scanpy/scanpy_06_celltyping.html#meta-session",
    "href": "labs/scanpy/scanpy_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "8 Session info",
    "text": "8 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nannoy               NA\narray_api_compat    1.10.0\nasttokens           NA\nbrotli              1.1.0\ncelltypist          1.6.3\ncertifi             2024.12.14\ncffi                1.17.1\ncharset_normalizer  3.4.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nfbpca               NA\ngseapy              1.1.3\nh5py                3.12.1\nidna                3.10\nigraph              0.11.6\nintervaltree        NA\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npatsy               1.0.1\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nrequests            2.32.3\nscanorama           1.7.4\nscipy               1.14.1\nsession_info        1.0.0\nsix                 1.17.0\nsklearn             1.6.1\nsocks               1.7.1\nsortedcontainers    2.4.0\nsparse              0.15.5\nstack_data          0.6.3\nstatsmodels         0.14.4\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nurllib3             2.3.0\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\nzstandard           0.23.0\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:26"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html",
    "href": "labs/scanpy/scanpy_07_trajectory.html",
    "title": " Trajectory inference using PAGA",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run Python commands unless it starts with %%bash, in which case, those chunks run shell commands.\nPartly following this PAGA tutorial with some modifications."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#loading-libraries",
    "href": "labs/scanpy/scanpy_07_trajectory.html#loading-libraries",
    "title": " Trajectory inference using PAGA",
    "section": "1 Loading libraries",
    "text": "1 Loading libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as pl\nfrom matplotlib import rcParams\nimport scanpy as sc\n\nimport scipy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\", category=Warning)\n\n# verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.verbosity = 3\nsc.settings.set_figure_params(dpi=100, frameon=False, figsize=(5, 5), facecolor='white', color_map = 'viridis_r')"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#preparing-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#preparing-data",
    "title": " Trajectory inference using PAGA",
    "section": "2 Preparing data",
    "text": "2 Preparing data\nIn order to speed up the computations during the exercises, we will be using a subset of a bone marrow dataset (originally containing about 100K cells). The bone marrow is the source of adult immune cells, and contains virtually all differentiation stages of cell from the immune system which later circulate in the blood to all other organs.\n\n\n\n\n\nIf you have been using the Seurat, Bioconductor or Scanpy toolkits with your own data, you need to reach to the point where can find get:\n\nA dimensionality reduction where to perform the trajectory (for example: PCA, ICA, MNN, harmony, Diffusion Maps, UMAP)\nThe cell clustering information (for example: from Louvain, k-means)\nA KNN/SNN graph (this is useful to inspect and sanity-check your trajectories)\n\nIn this case, all the data has been preprocessed with Seurat with standard pipelines. In addition there was some manual filtering done to remove clusters that are disconnected and cells that are hard to cluster, which can be seen in this script\nThe file trajectory_scanpy_filtered.h5ad was converted from the Seurat object using the SeuratDisk package. For more information on how it was done, have a look at the script: convert_to_h5ad.R in the github repo.\nYou can download the data with the commands:\n\nimport os\nimport subprocess\n\n# download pre-computed data if missing or long compute\nfetch_data = True\n\n# url for source and intermediate data\npath_data = \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass = \"zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_results = \"data/trajectory\"\nif not os.path.exists(path_results):\n    os.makedirs(path_results, exist_ok=True)\n\npath_file = \"data/trajectory/trajectory_seurat_filtered.h5ad\"\nif not os.path.exists(path_file):\n    file_url = os.path.join(path_data, \"trajectory/trajectory_seurat_filtered.h5ad\")\n    subprocess.call([\"curl\", \"-u\", curl_upass, \"-o\", path_file, file_url ])"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#reading-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#reading-data",
    "title": " Trajectory inference using PAGA",
    "section": "3 Reading data",
    "text": "3 Reading data\nWe already have pre-computed and subsetted the dataset (with 6688 cells and 3585 genes) following the analysis steps in this course. We then saved the objects, so you can use common tools to open and start to work with them (either in R or Python).\n\nadata = sc.read_h5ad(\"data/trajectory/trajectory_seurat_filtered.h5ad\")\nadata.var\n\n\n\n\n\n\n\n\nfeatures\n\n\n\n\n0610040J01Rik\n0610040J01Rik\n\n\n1190007I07Rik\n1190007I07Rik\n\n\n1500009L16Rik\n1500009L16Rik\n\n\n1700012B09Rik\n1700012B09Rik\n\n\n1700020L24Rik\n1700020L24Rik\n\n\n...\n...\n\n\nSqor\nSqor\n\n\nSting1\nSting1\n\n\nTent5a\nTent5a\n\n\nTlcd4\nTlcd4\n\n\nZnrd2\nZnrd2\n\n\n\n\n3585 rows × 1 columns\n\n\n\n\n# check what you have in the X matrix, should be lognormalized counts.\nprint(adata.X[:10,:10])\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 25 stored elements and shape (10, 10)&gt;\n  Coords    Values\n  (0, 4)    0.11622072805743532\n  (0, 8)    0.4800893970571722\n  (1, 8)    0.2478910541698065\n  (1, 9)    0.17188973970230348\n  (2, 1)    0.09413397843954842\n  (2, 7)    0.18016412971724202\n  (3, 1)    0.08438841021254412\n  (3, 4)    0.08438841021254412\n  (3, 7)    0.08438841021254412\n  (3, 8)    0.3648216463668793\n  (4, 1)    0.14198147850903975\n  (4, 8)    0.14198147850903975\n  (5, 1)    0.17953169693896723\n  (5, 8)    0.17953169693896723\n  (5, 9)    0.17953169693896723\n  (6, 4)    0.2319546390006887\n  (6, 8)    0.42010741700351195\n  (7, 1)    0.1775659421407816\n  (7, 8)    0.39593115482156394\n  (7, 9)    0.09271901219711086\n  (8, 1)    0.12089079757716388\n  (8, 8)    0.22873058755480363\n  (9, 1)    0.08915380247493314\n  (9, 4)    0.08915380247493314\n  (9, 8)    0.38270398718590104"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#explore-the-data",
    "href": "labs/scanpy/scanpy_07_trajectory.html#explore-the-data",
    "title": " Trajectory inference using PAGA",
    "section": "4 Explore the data",
    "text": "4 Explore the data\nThere is a umap and clusters provided with the object, first plot some information from the previous analysis onto the umap.\n\nsc.pl.umap(adata, color = ['clusters','dataset','batches','Phase'],legend_loc = 'on data', legend_fontsize = 'xx-small', ncols = 2)\n\n\n\n\n\n\nIt is crucial that you performing analysis of a dataset understands what is going on, what are the clusters you see in your data and most importantly How are the clusters related to each other?. Well, let’s explore the data a bit. With the help of this table, write down which cluster numbers in your dataset express these key markers.\n\n\n\nMarker\nCell Type\n\n\n\n\nCd34\nHSC progenitor\n\n\nMs4a1\nB cell lineage\n\n\nCd3e\nT cell lineage\n\n\nLtf\nGranulocyte lineage\n\n\nCst3\nMonocyte lineage\n\n\nMcpt8\nMast Cell lineage\n\n\nAlas2\nRBC lineage\n\n\nSiglech\nDendritic cell lineage\n\n\nC1qc\nMacrophage cell lineage\n\n\nPf4\nMegakaryocyte cell lineage\n\n\n\n\nmarkers = [\"Cd34\",\"Alas2\",\"Pf4\",\"Mcpt8\",\"Ltf\",\"Cst3\", \"Siglech\", \"C1qc\", \"Ms4a1\", \"Cd3e\", ]\nsc.pl.umap(adata, color = markers, use_raw = False, ncols = 4)"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#rerun-analysis-in-scanpy",
    "href": "labs/scanpy/scanpy_07_trajectory.html#rerun-analysis-in-scanpy",
    "title": " Trajectory inference using PAGA",
    "section": "5 Rerun analysis in Scanpy",
    "text": "5 Rerun analysis in Scanpy\nRedo clustering and umap using the basic Scanpy pipeline. Use the provided “X_harmony_Phase” dimensionality reduction as the staring point.\n\n# first, store the old umap with a new name so it is not overwritten\nadata.obsm['X_umap_old'] = adata.obsm['X_umap']\n\nsc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20, use_rep=\"X_harmony_Phase\")\nsc.tl.umap(adata, min_dist=0.4, spread=3)\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:08)\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm)\n    'umap', UMAP parameters (adata.uns) (0:00:06)\n\n\n\nsc.pl.umap(adata, color = ['clusters'],legend_loc = 'on data', legend_fontsize = 'xx-small', edges = True)\n\nsc.pl.umap(adata, color = markers, use_raw = False, ncols = 4)\n\n# Redo clustering as well\nsc.tl.leiden(adata, key_added = \"leiden_1.0\", resolution = 1.0) # default resolution in 1.0\nsc.tl.leiden(adata, key_added = \"leiden_1.2\", resolution = 1.2) # default resolution in 1.0\nsc.tl.leiden(adata, key_added = \"leiden_1.4\", resolution = 1.4) # default resolution in 1.0\n\n#sc.tl.louvain(adata, key_added = \"leiden_1.0\") # default resolution in 1.0\nsc.pl.umap(adata, color = ['leiden_1.0', 'leiden_1.2', 'leiden_1.4','clusters'],legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)\n\n\n\n\n\n\n\n\n\n\n\nrunning Leiden clustering\n    finished: found 16 clusters and added\n    'leiden_1.0', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Leiden clustering\n    finished: found 17 clusters and added\n    'leiden_1.2', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning Leiden clustering\n    finished: found 19 clusters and added\n    'leiden_1.4', the cluster labels (adata.obs, categorical) (0:00:00)\n\n\n\n\n\n\n\n\n#Rename clusters with really clear markers, the rest are left unlabelled.\n\nannot = pd.DataFrame(adata.obs['leiden_1.4'].astype('string'))\nannot[annot['leiden_1.4'] == '10'] = '10_megakaryo' #Pf4\nannot[annot['leiden_1.4'] == '17'] = '17_macro'  #C1qc\nannot[annot['leiden_1.4'] == '11'] = '11_eryth' #Alas2\nannot[annot['leiden_1.4'] == '18'] = '18_dend' #Siglech\nannot[annot['leiden_1.4'] == '13'] = '13_mast' #Mcpt8\nannot[annot['leiden_1.4'] == '0'] = '0_mono' #Cts3\nannot[annot['leiden_1.4'] == '1'] = '1_gran' #Ltf\nannot[annot['leiden_1.4'] == '9'] = '9_gran'\nannot[annot['leiden_1.4'] == '14'] = '14_TC' #Cd3e\nannot[annot['leiden_1.4'] == '16'] = '16_BC' #Ms4a1\nannot[annot['leiden_1.4'] == '8'] = '8_progen'  # Cd34\nannot[annot['leiden_1.4'] == '4'] = '4_progen' \nannot[annot['leiden_1.4'] == '5'] = '5_progen'\n\nadata.obs['annot']=annot['leiden_1.4'].astype('category')\n\nsc.pl.umap(adata, color = 'annot',legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)\n\nannot.value_counts()\n#type(annot)\n\n# astype('category')\n\n\n\n\n\n\nleiden_1.4  \n0_mono          509\n1_gran          487\n2               479\n3               463\n4_progen        387\n5_progen        384\n7               368\n6               368\n8_progen        367\n9_gran          366\n10_megakaryo    301\n11_eryth        294\n12              276\n13_mast         159\n14_TC           151\n15              128\n16_BC           124\n17_macro        116\n18_dend         101\ndtype: int64\n\n\n\n# plot onto the Seurat embedding:\nsc.pl.embedding(adata, basis='X_umap_old', color = 'annot',legend_loc = 'on data', legend_fontsize = 'xx-small', ncols =2)"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#run-paga",
    "href": "labs/scanpy/scanpy_07_trajectory.html#run-paga",
    "title": " Trajectory inference using PAGA",
    "section": "6 Run PAGA",
    "text": "6 Run PAGA\nUse the clusters from leiden clustering with leiden_1.4 and run PAGA. First we create the graph and initialize the positions using the umap.\n\n# use the umap to initialize the graph layout.\nsc.tl.draw_graph(adata, init_pos='X_umap')\nsc.pl.draw_graph(adata, color='annot', legend_loc='on data', legend_fontsize = 'xx-small')\nsc.tl.paga(adata, groups='annot')\nsc.pl.paga(adata, color='annot', edge_width_scale = 0.3)\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2-modified' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2-modified' (`pip install fa2-modified`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:02)\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\n\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, we have edges between many clusters that we know are are unrelated, so we may need to clean up the data a bit more."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#filtering-graph-edges",
    "href": "labs/scanpy/scanpy_07_trajectory.html#filtering-graph-edges",
    "title": " Trajectory inference using PAGA",
    "section": "7 Filtering graph edges",
    "text": "7 Filtering graph edges\nFirst, lets explore the graph a bit. So we plot the umap with the graph connections on top.\n\nsc.pl.umap(adata, edges=True, color = 'annot', legend_loc= 'on data', legend_fontsize= 'xx-small')\n\n\n\n\n\n\nWe have many edges in the graph between unrelated clusters, so lets try with fewer neighbors.\n\nsc.pp.neighbors(adata, n_neighbors=5,  use_rep = 'X_harmony_Phase', n_pcs = 30)\nsc.pl.umap(adata, edges=True, color = 'annot', legend_loc= 'on data', legend_fontsize= 'xx-small')\n\ncomputing neighbors\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n\n\n\n\n\n\n\n\n7.1 Rerun PAGA again on the data\n\nsc.tl.draw_graph(adata, init_pos='X_umap')\nsc.pl.draw_graph(adata, color='annot', legend_loc='on data', legend_fontsize = 'xx-small')\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2-modified' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2-modified' (`pip install fa2-modified`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:01)\n\n\n\n\n\n\n\n\nsc.tl.paga(adata, groups='annot')\nsc.pl.paga(adata, color='annot', edge_width_scale = 0.3)\n\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])"
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#embedding-using-paga-initialization",
    "href": "labs/scanpy/scanpy_07_trajectory.html#embedding-using-paga-initialization",
    "title": " Trajectory inference using PAGA",
    "section": "8 Embedding using PAGA-initialization",
    "text": "8 Embedding using PAGA-initialization\nWe can now redraw the graph using another starting position from the paga layout. The following is just as well possible for a UMAP.\n\nsc.tl.draw_graph(adata, init_pos='paga')\n\ndrawing single-cell graph using layout 'fa'\nWARNING: Package 'fa2-modified' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2-modified' (`pip install fa2-modified`).\n    finished: added\n    'X_draw_graph_fr', graph_drawing coordinates (adata.obsm) (0:00:10)\n\n\nNow we can see all marker genes also at single-cell resolution in a meaningful layout.\n\nsc.pl.draw_graph(adata, color=['annot'], legend_loc='on data', legend_fontsize=  'xx-small')\n\n\n\n\n\n\nCompare the 2 graphs\n\nsc.pl.paga_compare(\n    adata, threshold=0.03, title='', right_margin=0.2, size=10, edge_width_scale=0.5,\n    legend_fontsize=12, fontsize=12, frameon=False, edges=True)\n\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\n\n\n\n\n\n\n\n[&lt;Axes: xlabel='UMAP1', ylabel='UMAP2'&gt;, &lt;Axes: &gt;]\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDoes this graph fit the biological expectations given what you know of hematopoesis. Please have a look at the figure in Section 2 and compare to the paths you now have."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#gene-changes",
    "href": "labs/scanpy/scanpy_07_trajectory.html#gene-changes",
    "title": " Trajectory inference using PAGA",
    "section": "9 Gene changes",
    "text": "9 Gene changes\nWe can reconstruct gene changes along PAGA paths for a given set of genes\nChoose a root cell for diffusion pseudotime. We have 3 progenitor clusters, but cluster 5 seems the most clear.\n\nadata.uns['iroot'] = np.flatnonzero(adata.obs['annot']  == '5_progen')[0]\n\nsc.tl.dpt(adata)\n\nWARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.\ncomputing Diffusion Maps using n_comps=15(=n_dcs)\ncomputing transitions\n    finished (0:00:00)\n    eigenvalues of transition matrix\n    [1.         0.9989591  0.997628   0.9970365  0.9956704  0.99334306\n     0.9918951  0.9915921  0.99013233 0.98801893 0.9870309  0.9861044\n     0.9851118  0.9845008  0.9839531 ]\n    finished: added\n    'X_diffmap', diffmap coordinates (adata.obsm)\n    'diffmap_evals', eigenvalues of transition matrix (adata.uns) (0:00:00)\ncomputing Diffusion Pseudotime using n_dcs=10\n    finished: added\n    'dpt_pseudotime', the pseudotime (adata.obs) (0:00:00)\n\n\nUse the full raw data for visualization.\n\nsc.pl.draw_graph(adata, color=['annot', 'dpt_pseudotime'], legend_loc='on data', legend_fontsize= 'x-small')\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nThe pseudotime represents the distance of every cell to the starting cluster. Have a look at the pseudotime plot, how well do you think it represents actual developmental time? What does it represent?\n\n\nBy looking at the different know lineages and the layout of the graph we define manually some paths to the graph that corresponds to specific lineages.\n\n# Define paths\n\npaths = [('erythrocytes', ['5_progen', '8_progen', '6', '3', '7', '11_eryth']),\n         ('lympoid', ['5_progen', '12', '16_BC', '14_TC']),\n         ('granulo', ['5_progen', '4_progen', '2', '9_gran', '1_gran']),\n         ('mono', ['5_progen', '4_progen', '0_mono', '18_dend', '17_macro'])\n         ]\n\nadata.obs['distance'] = adata.obs['dpt_pseudotime']\n\nThen we select some genes that can vary in the lineages and plot onto the paths.\n\ngene_names = ['Gata2', 'Gata1', 'Klf1', 'Epor', 'Hba-a2',  # erythroid\n              'Elane', 'Cebpe', 'Gfi1',                    # neutrophil\n              'Irf8', 'Csf1r', 'Ctsg',                     # monocyte\n              'Itga2b','Prss34','Cma1','Procr',            # Megakaryo,Basophil,Mast,HPC\n              'C1qc','Siglech','Ms4a1','Cd3e','Cd34']\n\n\n_, axs = pl.subplots(ncols=4, figsize=(10, 4), gridspec_kw={\n                     'wspace': 0.05, 'left': 0.12})\npl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2)\nfor ipath, (descr, path) in enumerate(paths):\n    sc.pl.paga_path(\n        adata=adata, \n        nodes=path, \n        keys=gene_names,\n        show_node_names=False,\n        ax=axs[ipath],\n        ytick_fontsize=12,\n        left_margin=0.15,\n        n_avg=50,\n        annotations=['distance'],\n        show_yticks=True if ipath == 0 else False,\n        show_colorbar=False,\n        color_map='Greys',\n        groups_key='annot',\n        color_maps_annotations={'distance': 'viridis'},\n        title='{} path'.format(descr),\n        return_data=True,\n        use_raw=False,\n        show=False)\n\npl.show()\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nAs you can see, we can manipulate the trajectory quite a bit by selecting different number of neighbors, components etc. to fit with our assumptions on the development of these celltypes.\nPlease explore further how you can tweak the trajectory. For instance, can you create a PAGA trajectory using the orignial umap from Seurat instead? Hint, you first need to compute the neighbors on the umap."
  },
  {
    "objectID": "labs/scanpy/scanpy_07_trajectory.html#session-info",
    "href": "labs/scanpy/scanpy_07_trajectory.html#session-info",
    "title": " Trajectory inference using PAGA",
    "section": "10 Session info",
    "text": "10 Session info\n\n\nClick here\n\n\nsc.logging.print_versions()\n\n-----\nanndata     0.10.8\nscanpy      1.10.3\n-----\nPIL                 11.1.0\nasttokens           NA\ncffi                1.17.1\ncolorama            0.4.6\ncomm                0.2.2\ncycler              0.12.1\ncython_runtime      NA\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.1.0\nh5py                3.12.1\nigraph              0.11.6\nipykernel           6.29.5\njedi                0.19.2\njoblib              1.4.2\nkiwisolver          1.4.7\nlegacy_api_wrap     NA\nleidenalg           0.10.2\nllvmlite            0.43.0\nmatplotlib          3.9.2\nmatplotlib_inline   0.1.7\nmpl_toolkits        NA\nnatsort             8.4.0\nnetworkx            3.4\nnumba               0.60.0\nnumpy               1.26.4\npackaging           24.2\npandas              1.5.3\nparso               0.8.4\npickleshare         0.7.5\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npycparser           2.22\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npynndescent         0.5.13\npyparsing           3.2.1\npytz                2024.2\nscipy               1.14.1\nsession_info        1.0.0\nsix                 1.17.0\nsklearn             1.6.1\nsparse              0.15.5\nstack_data          0.6.3\ntexttable           1.7.0\nthreadpoolctl       3.5.0\ntorch               2.5.1.post207\ntorchgen            NA\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\numap                0.5.7\nwcwidth             0.2.13\nyaml                6.0.2\nzmq                 26.2.0\nzoneinfo            NA\n-----\nIPython             8.31.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:16:10) [GCC 13.3.0]\nLinux-6.10.14-linuxkit-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-10-20 19:27"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html",
    "href": "labs/seurat/seurat_04_clustering.html",
    "title": " Clustering",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nIn this tutorial, we will continue the analysis of the integrated dataset. We will use the integrated PCA or CCA to perform the clustering. First, we will construct a \\(k\\)-nearest neighbor graph in order to perform a clustering on the graph. We will also show how to perform hierarchical clustering and k-means clustering on the selected space.\nLet’s first load all necessary libraries and also the integrated dataset from the previous step.\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(clustree)\n})\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\n\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr_int.rds\"\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_seurat/seurat_covid_qc_dr_int.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nalldata &lt;- readRDS(path_file)\nprint(names(alldata@reductions))\n\n [1] \"pca\"               \"umap\"              \"tsne\"             \n [4] \"UMAP10_on_PCA\"     \"UMAP_on_ScaleData\" \"integrated_cca\"   \n [7] \"umap_cca\"          \"tsne_cca\"          \"harmony\"          \n[10] \"umap_harmony\"      \"scanorama\"         \"scanoramaC\"       \n[13] \"umap_scanorama\"    \"umap_scanoramaC\""
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_graphclust",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_graphclust",
    "title": " Clustering",
    "section": "1 Graph clustering",
    "text": "1 Graph clustering\nThe procedure of clustering on a Graph can be generalized as 3 main steps:\n- Build a kNN graph from the data.\n- Prune spurious connections from kNN graph (optional step). This is a SNN graph.\n- Find groups of cells that maximizes the connections within the group compared other groups.\n\n1.1 Building kNN / SNN graph\nThe first step into graph clustering is to construct a k-nn graph, in case you don’t have one. For this, we will use the PCA space. Thus, as done for dimensionality reduction, we will use ony the top N PCA dimensions for this purpose (the same used for computing UMAP / tSNE).\nAs we can see above, the Seurat function FindNeighbors() already computes both the KNN and SNN graphs, in which we can control the minimal percentage of shared neighbours to be kept. See ?FindNeighbors for additional options.\nThe main options to consider are:\n\ndims - the number of dimensions from the initial reduction to include when calculating distances between cells.\nk.param - the number of neighbors per cell to include in the KNN graph.\nprune.SNN - sets the cutoff for Jaccard index when pruning the graph.\n\n\n# use the CCA integration to create the neighborhood graph.\nalldata &lt;- FindNeighbors(alldata, dims = 1:30, k.param = 60, prune.SNN = 1 / 15, reduction =  \"integrated_cca\")\n\n# check the names for graphs in the object.\nnames(alldata@graphs)\n\n[1] \"RNA_nn\"  \"RNA_snn\"\n\n\nWe can take a look at the kNN and SNN graphs. The kNN graph is a matrix where every connection between cells is represented as \\(1\\)s. This is called a unweighted graph (default in Seurat). In the SNN graph on the other hand, some cell connections have more importance than others, and the graph scales from \\(0\\) to a maximum distance (in this case \\(1\\)). Usually, the smaller the distance, the closer two points are, and stronger is their connection. This is called a weighted graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (&gt; 100k cells).\n\npheatmap(alldata@graphs$RNA_nn[1:200, 1:200],\n    col = c(\"white\", \"black\"), border_color = \"grey90\", main = \"KNN graph\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\npheatmap(alldata@graphs$RNA_snn[1:200, 1:200],\n    col = colorRampPalette(c(\"white\", \"yellow\", \"red\"))(100),\n    border_color = \"grey90\", main = \"SNN graph\",\n    legend = F, cluster_rows = F, cluster_cols = F, fontsize = 2\n)\n\n\n\n\n\n\n\n\n\n\n1.2 Clustering on a graph\nOnce the graph is built, we can now perform graph clustering. The clustering is done respective to a resolution which can be interpreted as how coarse you want your cluster to be. Higher resolution means higher number of clusters.\nIn Seurat, the function FindClusters() will do a graph-based clustering using “Louvain” algorithim by default (algorithm = 1). To use the leiden algorithm, you need to set it to algorithm = 4. See ?FindClusters for additional options.\nBy default it will run clustering on the SNN graph we created in the previous step, but you can also specify different graphs for clustering with graph.name.\n\n# Clustering with louvain (algorithm 1) and a few different resolutions\nfor (res in c(0.1, 0.25, .5, 1, 1.5, 2)) {\n    alldata &lt;- FindClusters(alldata, graph.name = \"RNA_snn\", resolution = res, algorithm = 1)\n}\n\n# each time you run clustering, the data is stored in meta data columns:\n# seurat_clusters - lastest results only\n# RNA_snn_res.XX - for each different resolution you test.\n\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.0.1\", label=T) + ggtitle(\"louvain_0.1\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.0.25\", label=T) + ggtitle(\"louvain_0.25\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.0.5\", label=T) + ggtitle(\"louvain_0.5\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.1\", label=T) + ggtitle(\"louvain_1\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.2\", label=T) + ggtitle(\"louvain_2\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\nWe can now use the clustree package to visualize how cells are distributed between clusters depending on resolution.\n\nsuppressPackageStartupMessages(library(clustree))\nclustree(alldata@meta.data, prefix = \"RNA_snn_res.\")"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_kmean",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_kmean",
    "title": " Clustering",
    "section": "2 K-means clustering",
    "text": "2 K-means clustering\nK-means is a generic clustering algorithm that has been used in many application areas. In R, it can be applied via the kmeans() function. Typically, it is applied to a reduced dimension representation of the expression data (most often PCA, because of the interpretability of the low-dimensional distances). We need to define the number of clusters in advance. Since the results depend on the initialization of the cluster centers, it is typically recommended to run K-means with multiple starting configurations (via the nstart argument).\n\nfor (k in c(5, 7, 10, 12, 15, 17, 20)) {\n    alldata@meta.data[, paste0(\"kmeans_\", k)] &lt;- kmeans(x = Embeddings(alldata, \"integrated_cca\"), centers = k, nstart = 100)$cluster\n}\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"kmeans_5\", label=T) + ggtitle(\"kmeans_5\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"kmeans_10\", label=T) + ggtitle(\"kmeans_10\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"kmeans_15\", label=T) + ggtitle(\"kmeans_15\"),\n    ncol = 3\n)\n\n\n\n\n\n\n\n\n\nclustree(alldata@meta.data, prefix = \"kmeans_\")"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_hier",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_hier",
    "title": " Clustering",
    "section": "3 Hierarchical clustering",
    "text": "3 Hierarchical clustering\n\n3.1 Defining distance between cells\nThe base R stats package already contains a function dist that calculates distances between all pairs of samples. Since we want to compute distances between samples, rather than among genes, we need to transpose the data before applying it to the dist function. This can be done by simply adding the transpose function t() to the data. The distance methods available in dist are: ‘euclidean’, ‘maximum’, ‘manhattan’, ‘canberra’, ‘binary’ or ‘minkowski’.\n\nd &lt;- dist(Embeddings(alldata, \"integrated_cca\"), method = \"euclidean\")\n\nAs you might have realized, correlation is not a method implemented in the dist() function. However, we can create our own distances and transform them to a distance object. We can first compute sample correlations using the cor function.\nAs you already know, correlation range from -1 to 1, where 1 indicates that two samples are closest, -1 indicates that two samples are the furthest and 0 is somewhat in between. This, however, creates a problem in defining distances because a distance of 0 indicates that two samples are closest, 1 indicates that two samples are the furthest and distance of -1 is not meaningful. We thus need to transform the correlations to a positive scale (a.k.a. adjacency):\n\\[adj = \\frac{1- cor}{2}\\]\nOnce we transformed the correlations to a 0-1 scale, we can simply convert it to a distance object using as.dist() function. The transformation does not need to have a maximum of 1, but it is more intuitive to have it at 1, rather than at any other number.\n\n# Compute sample correlations\nsample_cor &lt;- cor(Matrix::t(Embeddings(alldata, \"integrated_cca\")))\n\n# Transform the scale from correlations\nsample_cor &lt;- (1 - sample_cor) / 2\n\n# Convert it to a distance object\nd2 &lt;- as.dist(sample_cor)\n\n\n\n3.2 Clustering cells\nAfter having calculated the distances between samples, we can now proceed with the hierarchical clustering per-se. We will use the function hclust() for this purpose, in which we can simply run it with the distance objects created above. The methods available are: ‘ward.D’, ‘ward.D2’, ‘single’, ‘complete’, ‘average’, ‘mcquitty’, ‘median’ or ‘centroid’. It is possible to plot the dendrogram for all cells, but this is very time consuming and we will omit for this tutorial.\n\n# euclidean\nh_euclidean &lt;- hclust(d, method = \"ward.D2\")\n\n# correlation\nh_correlation &lt;- hclust(d2, method = \"ward.D2\")\n\nOnce your dendrogram is created, the next step is to define which samples belong to a particular cluster. After identifying the dendrogram, we can now literally cut the tree at a fixed threshold (with cutree) at different levels to define the clusters. We can either define the number of clusters or decide on a height. We can simply try different clustering levels.\n\n# euclidean distance\nalldata$hc_euclidean_5 &lt;- cutree(h_euclidean, k = 5)\nalldata$hc_euclidean_10 &lt;- cutree(h_euclidean, k = 10)\nalldata$hc_euclidean_15 &lt;- cutree(h_euclidean, k = 15)\n\n# correlation distance\nalldata$hc_corelation_5 &lt;- cutree(h_correlation, k = 5)\nalldata$hc_corelation_10 &lt;- cutree(h_correlation, k = 10)\nalldata$hc_corelation_15 &lt;- cutree(h_correlation, k = 15)\n\nwrap_plots(\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_euclidean_5\", label=T) + ggtitle(\"hc_euc_5\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_euclidean_10\", label=T) + ggtitle(\"hc_euc_10\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_euclidean_15\", label=T) + ggtitle(\"hc_euc_15\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_corelation_5\", label=T) + ggtitle(\"hc_cor_5\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_corelation_10\", label=T) + ggtitle(\"hc_cor_10\"),\n    DimPlot(alldata, reduction = \"umap_cca\", group.by = \"hc_corelation_15\", label=T) + ggtitle(\"hc_cor_15\"),\n    ncol = 3\n) + plot_layout()\n\n\n\n\n\n\n\n\nFinally, lets save the clustered data for further analysis.\n\nsaveRDS(alldata, \"data/covid/results/seurat_covid_qc_dr_int_cl.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_distribution",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_distribution",
    "title": " Clustering",
    "section": "4 Distribution of clusters",
    "text": "4 Distribution of clusters\nNow, we can select one of our clustering methods and compare the proportion of samples across the clusters.\nSelect the RNA_snn_res.0.5 and plot proportion of samples per cluster and also proportion covid vs ctrl.\n\np1 &lt;- ggplot(alldata@meta.data, aes(x = RNA_snn_res.0.5, fill = orig.ident)) +\n    geom_bar(position = \"fill\")\np2 &lt;- ggplot(alldata@meta.data, aes(x = RNA_snn_res.0.5, fill = type)) +\n    geom_bar(position = \"fill\")\n\np1 + p2\n\n\n\n\n\n\n\n\nIn this case we have quite good representation of each sample in each cluster. But there are clearly some biases with more cells from one sample in some clusters and also more covid cells in some of the clusters.\nWe can also plot it in the other direction, the proportion of each cluster per sample.\n\nggplot(alldata@meta.data, aes(x = orig.ident, fill = RNA_snn_res.0.5)) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nBy now you should know how to plot different features onto your data. Take the QC metrics that were calculated in the first exercise, that should be stored in your data object, and plot it as violin plots per cluster using the clustering method of your choice. For example, plot number of UMIS, detected genes, percent mitochondrial reads. Then, check carefully if there is any bias in how your data is separated by quality metrics. Could it be explained biologically, or could there be a technical bias there?\n\n\n\nVlnPlot(alldata, group.by = \"RNA_snn_res.0.5\", features = c(\"nFeature_RNA\", \"percent_mito\"))\n\n\n\n\n\n\n\n\nSome clusters that are clearly defined by higher number of genes and counts. These are either doublets or a larger celltype. And some clusters with low values on these metrics that are either low quality cells or a smaller celltype. You will have to explore these clusters in more detail to judge what you believe them to be."
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-clust_sub",
    "href": "labs/seurat/seurat_04_clustering.html#meta-clust_sub",
    "title": " Clustering",
    "section": "5 Subclustering of T and NK-cells",
    "text": "5 Subclustering of T and NK-cells\nIt is common that the subtypes of cells within a cluster is not so well separated when you have a heterogeneous dataset. In such a case it could be a good idea to run subclustering of individual celltypes. The main reason for subclustering is that the variable genes and the first principal components in the full analysis are mainly driven by differences between celltypes, while with subclustering we may detect smaller differences between subtypes within celltypes.\nSo first, lets find out where our T-cell and NK-cell clusters are. We know that T-cells express CD3E, and the main subtypes are CD4 and CD8, while NK-cells express GNLY.\n\n# check with the lowest resolution\np1 = DimPlot(alldata, reduction = \"umap_cca\", group.by = \"RNA_snn_res.0.1\", label = T) + ggtitle(\"louvain_0.1\")\np2 = FeaturePlot(alldata, features = \"CD3E\", reduction = \"umap_cca\", order = T) \np3 = FeaturePlot(alldata, features = \"CD4\", reduction = \"umap_cca\", order = T) \np4 = FeaturePlot(alldata, features = \"CD8A\", reduction = \"umap_cca\", order = T) \np5 = FeaturePlot(alldata, features = \"GNLY\", reduction = \"umap_cca\", order = T) \n\n\nwrap_plots(p1,p2,p3,p4,p5, ncol=3) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nWe can clearly see what clusters are T-cell clusters, so lets subset the data for those cells\n\ntcells = alldata[,alldata$RNA_snn_res.0.1 %in% c(0,3)]\n\ntable(tcells$orig.ident)\n\n\n covid_1 covid_15 covid_16 covid_17  ctrl_13  ctrl_14  ctrl_19   ctrl_5 \n     280      241      130      292      634      521      562      704 \n\n\nIdeally we should rerun all steps of integration with that subset of cells instead of just taking the joint embedding. If you have too few cells per sample in the celltype that you want to cluster it may not be possible. We will start with selecting a new set of genes that better reflecs the variability within this celltype\n\ntcells = FindVariableFeatures(tcells, verbose = FALSE)\n\n# check overlap with the variable genes using all the data\nlength(intersect(VariableFeatures(alldata), VariableFeatures(tcells)))\n\n[1] 1247\n\n\nWe clearly have a very different geneset now, so hopefully it should better capture the variability within T-cells.\nNow we have to run the full pipeline with scaling, pca, integration and clustering on this subset of cells, using the new set of variable genes\n\n# run all the steps from before:\ntcells = ScaleData(tcells, vars.to.regress = c(\"percent_mito\", \"nFeature_RNA\"), assay = \"RNA\")\ntcells = RunPCA(tcells, npcs = 50, verbose = F)\n\ntcells &lt;- IntegrateLayers(object = tcells, \n                           method = CCAIntegration, orig.reduction = \"pca\", \n                           new.reduction = \"integrated_tcells\", verbose = FALSE)\n\ntcells &lt;- RunUMAP(tcells, reduction = \"integrated_tcells\", dims = 1:30, reduction.name = \"umap_tcells\")\n\ntcells &lt;- FindNeighbors(tcells, reduction = \"integrated_tcells\", dims = 1:30)\ntcells &lt;- FindClusters(tcells, graph.name = \"RNA_snn\", resolution = 0.5, algorithm = 1, cluster.name = \"tcell_0.5\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 3364\nNumber of edges: 192090\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8472\nNumber of communities: 7\nElapsed time: 0 seconds\n\n\n\nwrap_plots(\n  DimPlot(tcells, reduction = \"umap_cca\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"Full umap\"),\n  DimPlot(tcells, reduction = \"umap_cca\", group.by = \"RNA_snn_res.0.5\", label = T)+NoAxes()+ggtitle(\"Full umap, full clust\"),\n  DimPlot(tcells, reduction = \"umap_cca\", group.by = \"tcell_0.5\", label = T)+NoAxes()+ggtitle(\"Full umap, T-cell clust\"),\n  DimPlot(tcells, reduction = \"umap_tcells\", group.by = \"orig.ident\")+NoAxes()+ggtitle(\"T-cell umap, T-cell clust\"),\n  DimPlot(tcells, reduction = \"umap_tcells\", group.by = \"RNA_snn_res.0.5\", label=T)+NoAxes()+ggtitle(\"T-cell umap, full clust\"),\n  DimPlot(tcells, reduction = \"umap_tcells\", group.by = \"tcell_0.5\", label = T)+NoAxes()+ggtitle(\"T-cell umap\"),  \n  ncol = 3\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nAs you can see, we do have some new clusters that did not stand out before (clusters 6,7). But in general the separation looks very similar.\nLets also have a look at some genes in the new umap:\n\nwrap_plots(\n  FeaturePlot(tcells, features = \"CD3E\", reduction = \"umap_tcells\", order = T), \n  FeaturePlot(tcells, features = \"CD4\", reduction = \"umap_tcells\", order = T), \n  FeaturePlot(tcells, features = \"CD8A\", reduction = \"umap_tcells\", order = T), \n  FeaturePlot(tcells, features = \"GNLY\", reduction = \"umap_tcells\", order = T), \n  ncol = 2\n) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nHave a look at the T-cells in the umaps with all cells or only T/NK cells. What are the main differences? Do you think it improved with subclustering? Also, there are some cells in these clusters that fall far away from the rest in the UMAPs, why do you think that is?"
  },
  {
    "objectID": "labs/seurat/seurat_04_clustering.html#meta-session",
    "href": "labs/seurat/seurat_04_clustering.html#meta-session",
    "title": " Clustering",
    "section": "6 Session info",
    "text": "6 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] clustree_0.5.1     ggraph_2.2.1       pheatmap_1.0.12    ggplot2_3.5.1     \n[5] patchwork_1.3.0    Seurat_5.1.0       SeuratObject_5.0.2 sp_2.2-0          \n\nloaded via a namespace (and not attached):\n  [1] RColorBrewer_1.1-3     jsonlite_1.8.9         magrittr_2.0.3        \n  [4] ggbeeswarm_0.7.2       spatstat.utils_3.1-2   farver_2.1.2          \n  [7] rmarkdown_2.29         vctrs_0.6.5            ROCR_1.0-11           \n [10] memoise_2.0.1          spatstat.explore_3.3-4 htmltools_0.5.8.1     \n [13] sctransform_0.4.1      parallelly_1.42.0      KernSmooth_2.23-26    \n [16] htmlwidgets_1.6.4      ica_1.0-3              plyr_1.8.9            \n [19] plotly_4.10.4          zoo_1.8-12             cachem_1.1.0          \n [22] igraph_2.0.3           mime_0.12              lifecycle_1.0.4       \n [25] pkgconfig_2.0.3        Matrix_1.6-5           R6_2.6.1              \n [28] fastmap_1.2.0          fitdistrplus_1.2-2     future_1.34.0         \n [31] shiny_1.10.0           digest_0.6.37          colorspace_2.1-1      \n [34] tensor_1.5             RSpectra_0.16-2        irlba_2.3.5.1         \n [37] labeling_0.4.3         progressr_0.15.1       spatstat.sparse_3.1-0 \n [40] httr_1.4.7             polyclip_1.10-7        abind_1.4-5           \n [43] compiler_4.3.3         withr_3.0.2            backports_1.5.0       \n [46] viridis_0.6.5          fastDummies_1.7.5      ggforce_0.4.2         \n [49] MASS_7.3-60.0.1        tools_4.3.3            vipor_0.4.7           \n [52] lmtest_0.9-40          beeswarm_0.4.0         httpuv_1.6.15         \n [55] future.apply_1.11.3    goftest_1.2-3          glue_1.8.0            \n [58] nlme_3.1-167           promises_1.3.2         grid_4.3.3            \n [61] checkmate_2.3.2        Rtsne_0.17             cluster_2.1.8         \n [64] reshape2_1.4.4         generics_0.1.3         gtable_0.3.6          \n [67] spatstat.data_3.1-4    tidyr_1.3.1            data.table_1.16.4     \n [70] tidygraph_1.3.0        spatstat.geom_3.3-5    RcppAnnoy_0.0.22      \n [73] ggrepel_0.9.6          RANN_2.6.2             pillar_1.10.1         \n [76] stringr_1.5.1          spam_2.11-1            RcppHNSW_0.6.0        \n [79] later_1.4.1            splines_4.3.3          dplyr_1.1.4           \n [82] tweenr_2.0.3           lattice_0.22-6         survival_3.8-3        \n [85] deldir_2.0-4           tidyselect_1.2.1       miniUI_0.1.1.1        \n [88] pbapply_1.7-2          knitr_1.49             gridExtra_2.3         \n [91] scattermore_1.2        xfun_0.50              graphlayouts_1.2.2    \n [94] matrixStats_1.5.0      stringi_1.8.4          lazyeval_0.2.2        \n [97] yaml_2.3.10            evaluate_1.0.3         codetools_0.2-20      \n[100] tibble_3.2.1           cli_3.6.4              uwot_0.2.2            \n[103] xtable_1.8-4           reticulate_1.40.0      munsell_0.5.1         \n[106] Rcpp_1.0.14            globals_0.16.3         spatstat.random_3.3-2 \n[109] png_0.1-8              ggrastr_1.0.2          spatstat.univar_3.1-1 \n[112] parallel_4.3.3         dotCall64_1.2          listenv_0.9.1         \n[115] viridisLite_0.4.2      scales_1.3.0           ggridges_0.5.6        \n[118] leiden_0.4.3.1         purrr_1.0.2            rlang_1.1.5           \n[121] cowplot_1.1.3"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html",
    "href": "labs/seurat/seurat_06_celltyping.html",
    "title": " Celltype prediction",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified.\nCelltype prediction can either be performed on indiviudal cells where each cell gets a predicted celltype label, or on the level of clusters. All methods are based on similarity to other datasets, single cell or sorted bulk RNAseq, or uses known marker genes for each cell type.\nIdeally celltype predictions should be run on each sample separately and not using the integrated data. In this case we will select one sample from the Covid data, ctrl_13 and predict celltype by cell on that sample.\nSome methods will predict a celltype to each cell based on what it is most similar to, even if that celltype is not included in the reference. Other methods include an uncertainty so that cells with low similarity scores will be unclassified.\nThere are multiple different methods to predict celltypes, here we will just cover a few of those.\nWe will use a reference PBMC dataset from the scPred package which is provided as a Seurat object with counts. Unfortunately scPred has not been updated to run with Seurat v5, so we will not use it here. We will test classification based on Seurat labelTransfer, the SingleR method scPred and using Azimuth. Finally we will use gene set enrichment predict celltype based on the DEGs of each cluster."
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_read",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_read",
    "title": " Celltype prediction",
    "section": "1 Read data",
    "text": "1 Read data\nFirst, lets load required libraries\n\nsuppressPackageStartupMessages({\n    library(Seurat)\n    library(dplyr)\n    library(patchwork)\n    library(ggplot2)\n    library(pheatmap)\n    library(scPred)\n    library(celldex)\n    library(SingleR)\n    library(remotes)\n    remotes::install_github(\n        \"https://github.com/satijalab/seurat-data@4dc08e022f51c324bc7bf785b1b5771d2742701d\",\n        upgrade = FALSE,\n        dependencies = FALSE\n    )\n    library(SeuratData)\n    remotes::install_github(\n        \"https://github.com/immunogenomics/presto@7636b3d0465c468c35853f82f1717d3a64b3c8f6\",\n        upgrade = FALSE,\n        dependencies = FALSE\n    )\n    remotes::install_github(\n        \"https://github.com/mojaveazure/seurat-disk@877d4e18ab38c686f5db54f8cd290274ccdbe295\",\n        upgrade = FALSE,\n        dependencies = FALSE)\n    remotes::install_github(\n        \"https://github.com/satijalab/azimuth@243ee5db80fcbffa3452c944254a325a3da2ef9e\",\n        upgrade = FALSE,\n        dependencies = FALSE\n    )\n    library(Azimuth)\n})\n\n* checking for file ‘/tmp/RtmpDrS88e/remotes43120a3043/satijalab-seurat-data-3e51f44/DESCRIPTION’ ... OK\n* preparing ‘SeuratData’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘SeuratData_0.2.2.9002.tar.gz’\n\n\n* checking for file ‘/tmp/RtmpDrS88e/remotes4369a2670c/immunogenomics-presto-7636b3d/DESCRIPTION’ ... OK\n* preparing ‘presto’:\n* checking DESCRIPTION meta-information ... OK\n* cleaning src\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building ‘presto_1.0.0.tar.gz’\n\n\n* checking for file ‘/tmp/RtmpDrS88e/remotes43751c3c5d/mojaveazure-seurat-disk-877d4e1/DESCRIPTION’ ... OK\n* preparing ‘SeuratDisk’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘SeuratDisk_0.0.0.9021.tar.gz’\n\n\n* checking for file ‘/tmp/RtmpDrS88e/remotes4360bf25a0/satijalab-azimuth-243ee5d/DESCRIPTION’ ... OK\n* preparing ‘Azimuth’:\n* checking DESCRIPTION meta-information ... OK\n* cleaning src\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘Azimuth_0.5.0.tar.gz’\n\n\nLet’s read in the saved Covid-19 data object from the clustering step.\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\npath_file &lt;- \"data/covid/results/seurat_covid_qc_dr_int_cl.rds\"\n\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (fetch_data && !file.exists(path_file)) download.file(url = file.path(path_data, \"covid/results_seurat/seurat_covid_qc_dr_int_cl.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nalldata &lt;- readRDS(path_file)\n\nSubset one patient.\n\nctrl &lt;- alldata[, alldata$orig.ident == \"ctrl_13\"]"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_ref",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_ref",
    "title": " Celltype prediction",
    "section": "2 Reference data",
    "text": "2 Reference data\nLoad the reference dataset with annotated labels that is provided by the scPred package, it is a subsampled set of cells from human PBMCs.\n\nreference &lt;- scPred::pbmc_1\nreference\n\nAn object of class Seurat \n32838 features across 3500 samples within 1 assay \nActive assay: RNA (32838 features, 0 variable features)\n 2 layers present: counts, data\n\n\nRerun analysis pipeline. Run normalization, feature selection and dimensionality reduction\nHere, we will run all the steps that we did in previous labs in one go using the magittr package with the pipe-operator %&gt;%.\n\nreference &lt;- reference %&gt;%\n    NormalizeData() %&gt;%\n    FindVariableFeatures() %&gt;%\n    ScaleData() %&gt;%\n    RunPCA(verbose = F) %&gt;%\n    RunUMAP(dims = 1:30)\n\n\nDimPlot(reference, group.by = \"cell_type\", label = TRUE, repel = TRUE) + NoAxes()\n\n\n\n\n\n\n\n\nRun all steps of the analysis for the ctrl sample as well. Use the clustering from the integration lab with resolution 0.5.\n\n# Set the identity as louvain with resolution 0.5\nctrl &lt;- SetIdent(ctrl, value = \"RNA_snn_res.0.5\")\n\nctrl &lt;- ctrl %&gt;%\n    NormalizeData() %&gt;%\n    FindVariableFeatures() %&gt;%\n    ScaleData() %&gt;%\n    RunPCA(verbose = F) %&gt;%\n    RunUMAP(dims = 1:30)\n\n\nDimPlot(ctrl, label = TRUE, repel = TRUE) + NoAxes()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#label-transfer",
    "href": "labs/seurat/seurat_06_celltyping.html#label-transfer",
    "title": " Celltype prediction",
    "section": "3 Label transfer",
    "text": "3 Label transfer\nFirst we will run label transfer using a similar method as in the integration exercise. But, instead of CCA, which is the default for the FindTransferAnchors() function, we will use pcaproject, ie; the query dataset is projected onto the PCA of the reference dataset. Then, the labels of the reference data are predicted.\n\ntransfer.anchors &lt;- FindTransferAnchors(\n    reference = reference, query = ctrl,\n    dims = 1:30\n)\npredictions &lt;- TransferData(\n    anchorset = transfer.anchors, refdata = reference$cell_type,\n    dims = 1:30\n)\nctrl &lt;- AddMetaData(object = ctrl, metadata = predictions)\n\n\nDimPlot(ctrl, group.by = \"predicted.id\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\n\nNow plot how many cells of each celltypes can be found in each cluster.\n\nggplot(ctrl@meta.data, aes(x = RNA_snn_res.0.5, fill = predicted.id)) +\n    geom_bar() +\n    theme_classic()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_singler",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_singler",
    "title": " Celltype prediction",
    "section": "4 SinlgeR",
    "text": "4 SinlgeR\nSingleR is performs unbiased cell type recognition from single-cell RNA sequencing data, by leveraging reference transcriptomic datasets of pure cell types to infer the cell of origin of each single cell independently.\nWe first have to convert the Seurat object to a SingleCellExperiment object.\n\nsce = as.SingleCellExperiment(ctrl)\n\nThere are multiple datasets included in the celldex package that can be used for celltype prediction, here we will test two different ones, the DatabaseImmuneCellExpressionData and the HumanPrimaryCellAtlasData. In addition we will use the same reference dataset that we used for label transfer above but using SingleR instead.\n\n4.1 Immune cell reference\n\nimmune = celldex::DatabaseImmuneCellExpressionData()\nsingler.immune &lt;- SingleR(test = sce, ref = immune, assay.type.test=1,\n    labels = immune$label.main)\n\nhead(singler.immune)\n\nDataFrame with 6 rows and 4 columns\n                                                       scores        labels\n                                                     &lt;matrix&gt;   &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13  0.0679680:0.0760411:0.186694:... T cells, CD4+\nctrl_13_CCTATCGGTCCCTCAT-13  0.0027079:0.0960641:0.386088:...      NK cells\nctrl_13_TCCTCCCTCGTTCATT-13  0.0361115:0.1067465:0.394579:...      NK cells\nctrl_13_CAACCAATCATCTATC-13  0.0342030:0.1345967:0.402377:...      NK cells\nctrl_13_TACGGTATCGGATTAC-13 -0.0131813:0.0717678:0.283882:...      NK cells\nctrl_13_AATAGAGAGTTCGGTT-13  0.0841091:0.1367749:0.273738:... T cells, CD4+\n                            delta.next pruned.labels\n                             &lt;numeric&gt;   &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13  0.1375513 T cells, CD4+\nctrl_13_CCTATCGGTCCCTCAT-13  0.1490740      NK cells\nctrl_13_TCCTCCCTCGTTCATT-13  0.1220681      NK cells\nctrl_13_CAACCAATCATCTATC-13  0.1513308      NK cells\nctrl_13_TACGGTATCGGATTAC-13  0.0620657      NK cells\nctrl_13_AATAGAGAGTTCGGTT-13  0.0660296 T cells, CD4+\n\n\n\n\n4.2 HPCA reference\n\nhpca &lt;- celldex::HumanPrimaryCellAtlasData()\nsingler.hpca &lt;- SingleR(test = sce, ref = hpca, assay.type.test=1,\n    labels = hpca$label.main)\n\nhead(singler.hpca)\n\nDataFrame with 6 rows and 4 columns\n                                                    scores      labels\n                                                  &lt;matrix&gt; &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13 0.141378:0.310009:0.275987:...     T_cells\nctrl_13_CCTATCGGTCCCTCAT-13 0.145926:0.300045:0.277827:...     NK_cell\nctrl_13_TCCTCCCTCGTTCATT-13 0.132119:0.311754:0.274127:...     NK_cell\nctrl_13_CAACCAATCATCTATC-13 0.157184:0.302219:0.284496:...     NK_cell\nctrl_13_TACGGTATCGGATTAC-13 0.125120:0.283118:0.250322:...     T_cells\nctrl_13_AATAGAGAGTTCGGTT-13 0.191441:0.374422:0.329988:...     T_cells\n                            delta.next pruned.labels\n                             &lt;numeric&gt;   &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13  0.4918992       T_cells\nctrl_13_CCTATCGGTCCCTCAT-13  0.3241970       NK_cell\nctrl_13_TCCTCCCTCGTTCATT-13  0.0640608       NK_cell\nctrl_13_CAACCAATCATCTATC-13  0.2012408       NK_cell\nctrl_13_TACGGTATCGGATTAC-13  0.1545913       T_cells\nctrl_13_AATAGAGAGTTCGGTT-13  0.5063484       T_cells\n\n\n\n\n4.3 With own reference data\n\nsce.ref = as.SingleCellExperiment(reference)\nsingler.ref &lt;- SingleR(test=sce, ref=sce.ref, labels=sce.ref$cell_type, de.method=\"wilcox\")\nhead(singler.ref)\n\nDataFrame with 6 rows and 4 columns\n                                                    scores      labels\n                                                  &lt;matrix&gt; &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13 0.740975:0.838990:0.805340:...  CD4 T cell\nctrl_13_CCTATCGGTCCCTCAT-13 0.647281:0.735248:0.815289:...     NK cell\nctrl_13_TCCTCCCTCGTTCATT-13 0.668322:0.732251:0.822483:...     NK cell\nctrl_13_CAACCAATCATCTATC-13 0.645869:0.719972:0.799716:...  CD8 T cell\nctrl_13_TACGGTATCGGATTAC-13 0.701719:0.772023:0.802647:...  CD8 T cell\nctrl_13_AATAGAGAGTTCGGTT-13 0.724356:0.846323:0.815530:...  CD4 T cell\n                            delta.next pruned.labels\n                             &lt;numeric&gt;   &lt;character&gt;\nctrl_13_AGGTCATGTGCGAACA-13  0.0383797    CD4 T cell\nctrl_13_CCTATCGGTCCCTCAT-13  0.0743326       NK cell\nctrl_13_TCCTCCCTCGTTCATT-13  0.0318152       NK cell\nctrl_13_CAACCAATCATCTATC-13  0.0394666    CD8 T cell\nctrl_13_TACGGTATCGGATTAC-13  0.0743317    CD8 T cell\nctrl_13_AATAGAGAGTTCGGTT-13  0.0377684    CD4 T cell\n\n\nCompare results:\n\nctrl$singler.immune = singler.immune$pruned.labels\nctrl$singler.hpca = singler.hpca$pruned.labels\nctrl$singler.ref = singler.ref$pruned.labels\n\nDimPlot(ctrl, group.by = c(\"singler.hpca\", \"singler.immune\", \"singler.ref\"), ncol = 2)"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_azimuth",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_azimuth",
    "title": " Celltype prediction",
    "section": "5 Azimuth",
    "text": "5 Azimuth\nThere are multiple online resources with large curated datasets with methods to integrate and do label transfer. One such resource is Azimuth another one is Disco.\nHere we will use the PBMC reference provided with Azimuth. Which in principle runs label transfer of your dataset onto a large curated reference. The first time you run the command, the pbmcref dataset will be downloaded to your local computer.\n\noptions(future.globals.maxSize = 1e9)\n\n# will install the pbmcref dataset first time you run it.\nctrl &lt;- RunAzimuth(ctrl, reference = \"pbmcref\")\n\nThis dataset has predictions at 3 different levels of annotation wiht l1 being the more broad celltypes and l3 more detailed annotation.\n\nDimPlot(ctrl, group.by = \"predicted.celltype.l1\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\nDimPlot(ctrl, group.by = \"predicted.celltype.l2\", label = T, repel = T) + NoAxes()\n\n\n\n\n\n\n\nDimPlot(ctrl, group.by = \"predicted.celltype.l3\", label = T, repel = T) + NoAxes()"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_compare",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_compare",
    "title": " Celltype prediction",
    "section": "6 Compare results",
    "text": "6 Compare results\nNow we will compare the output of the two methods using the convenient function in scPred crossTab() that prints the overlap between two metadata slots.\n\ncrossTab(ctrl, \"predicted.id\", \"singler.hpca\")\n\n\n\n  \n\n\n\nWe can also plot all the different predictions side by side\n\nwrap_plots(\n    DimPlot(ctrl, label = T, group.by = \"predicted.id\") + NoAxes() + ggtitle(\"LabelTransfer\"),\n    DimPlot(ctrl, label = T, group.by = \"singler.hpca\") + NoAxes() + ggtitle(\"SingleR HPCA\"),\n    DimPlot(ctrl, label = T, group.by = \"singler.ref\") + NoAxes() + ggtitle(\"SingleR Ref\"),\n    DimPlot(ctrl, label = T, group.by = \"predicted.celltype.l1\") + NoAxes() + ggtitle(\"Azimuth l1\"),\n    ncol = 2\n)"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-ct_gsea",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-ct_gsea",
    "title": " Celltype prediction",
    "section": "7 GSEA with celltype markers",
    "text": "7 GSEA with celltype markers\nAnother option, where celltype can be classified on cluster level is to use gene set enrichment among the DEGs with known markers for different celltypes. Similar to how we did functional enrichment for the DEGs in the differential expression exercise. There are some resources for celltype gene sets that can be used. Such as CellMarker, PanglaoDB or celltype gene sets at MSigDB. We can also look at overlap between DEGs in a reference dataset and the dataset you are analyzing.\n\n7.1 DEG overlap\nFirst, lets extract top DEGs for our Covid-19 dataset and the reference dataset. When we run differential expression for our dataset, we want to report as many genes as possible, hence we set the cutoffs quite lenient.\n\n# run differential expression in our dataset, using clustering at resolution 0.5\n# first we need to join the layers\nalldata@active.assay = \"RNA\"\nalldata &lt;- JoinLayers(object = alldata, layers = c(\"data\",\"counts\"))\n\n# set the clustering you want to use as the identity class.\nalldata &lt;- SetIdent(alldata, value = \"RNA_snn_res.0.5\")\nDGE_table &lt;- FindAllMarkers(\n    alldata,\n    logfc.threshold = 0,\n    test.use = \"wilcox\",\n    min.pct = 0.1,\n    min.diff.pct = 0,\n    only.pos = TRUE,\n    max.cells.per.ident = 100,\n    return.thresh = 1,\n    assay = \"RNA\"\n)\n\n# split into a list\nDGE_list &lt;- split(DGE_table, DGE_table$cluster)\n\nunlist(lapply(DGE_list, nrow))\n\n   0    1    2    3    4    5    6    7    8    9 \n3257 4295 3413 2599 2189 2649 3544 2449 2408 3687 \n\n\n\n# Compute differential gene expression in reference dataset (that has cell annotation)\nreference &lt;- SetIdent(reference, value = \"cell_type\")\nreference_markers &lt;- FindAllMarkers(\n    reference,\n    min.pct = .1,\n    min.diff.pct = .2,\n    only.pos = T,\n    max.cells.per.ident = 20,\n    return.thresh = 1\n)\n\n# Identify the top cell marker genes in reference dataset\n# select top 50 with hihgest foldchange among top 100 signifcant genes.\nreference_markers &lt;- reference_markers[order(reference_markers$avg_log2FC, decreasing = T), ]\nreference_markers %&gt;%\n    group_by(cluster) %&gt;%\n    top_n(-100, p_val) %&gt;%\n    top_n(50, avg_log2FC) -&gt; top50_cell_selection\n\n# Transform the markers into a list\nref_list &lt;- split(top50_cell_selection$gene, top50_cell_selection$cluster)\n\nunlist(lapply(ref_list, length))\n\n CD8 T cell  CD4 T cell       cMono      B cell     NK cell         pDC \n         30          15          50          50          50          50 \n     ncMono         cDC Plasma cell \n         50          50          50 \n\n\nNow we can run GSEA for the DEGs from our dataset and check for enrichment of top DEGs in the reference dataset.\n\nsuppressPackageStartupMessages(library(fgsea))\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    gene_rank &lt;- setNames(x$avg_log2FC, x$gene)\n    fgseaRes &lt;- fgsea(pathways = ref_list, stats = gene_rank, nperm = 10000)\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.1, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 2, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\nres\n\n$`0`\n   pathway        pval       padj        ES      NES nMoreExtreme  size\n    &lt;char&gt;       &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:   cMono 0.000099990 0.00030000 0.8689362 2.051353            0    48\n2:     cDC 0.000100000 0.00030000 0.7093023 1.652056            0    39\n3:  ncMono 0.000099990 0.00030000 0.6649161 1.563192            0    45\n4:     pDC 0.007420778 0.01669675 0.6428686 1.432278           73    22\n    leadingEdge\n         &lt;list&gt;\n1: S100A12,....\n2: LYZ, LGA....\n3: SLC11A1,....\n4: MS4A6A, ....\n\n$`1`\n       pathway         pval         padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:     NK cell 0.0001000000 0.0004523977 0.9240127 2.547921            0    47\n2:  CD8 T cell 0.0001005328 0.0004523977 0.8575103 2.221204            0    25\n3: Plasma cell 0.0041368177 0.0124104530 0.6422487 1.638063           40    22\n4:      ncMono 0.0347544022 0.0781974050 0.7418541 1.502067          299     6\n5:         pDC 0.0642025681 0.1155646226 0.7369654 1.432726          534     5\n    leadingEdge\n         &lt;list&gt;\n1: SH2D1B, ....\n2: PRF1, GZ....\n3: CD38, SL....\n4: FCGR3A, RHOC\n5: C12orf75....\n\n$`2`\n       pathway         pval         padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:  CD8 T cell 0.0001001101 0.0006006607 0.8527572 2.150491            0    29\n2:  CD4 T cell 0.0030076863 0.0056490083 0.8302412 1.698944           26     7\n3:     NK cell 0.0006003602 0.0018010806 0.6508566 1.649983            5    31\n4:         pDC 0.0037660055 0.0056490083 0.9107144 1.641885           29     4\n5: Plasma cell 0.0379848866 0.0379848866 0.5881496 1.420176          376    19\n    leadingEdge\n         &lt;list&gt;\n1: CD8B, CD....\n2: CD3D, CD....\n3: CCL4, XC....\n4: PTMS, C1....\n5: FKBP11, ....\n\n$`3`\n       pathway         pval         padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:      B cell 0.0001000000 0.0009000000 0.8694924 2.005656            0    46\n2:         pDC 0.0002013288 0.0009059795 0.7905510 1.711851            1    19\n3: Plasma cell 0.0034987277 0.0078721374 0.8273023 1.637764           32     9\n4:         cDC 0.0017211704 0.0051635112 0.7546744 1.606086           16    16\n    leadingEdge\n         &lt;list&gt;\n1: TCL1A, F....\n2: TSPAN13,....\n3: PLPP5, D....\n4: ADAM28, ....\n\n$`4`\n      pathway         pval        padj        ES      NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;       &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: CD4 T cell 0.0001015744 0.000507872 0.8858246 1.852216            0    14\n2: CD8 T cell 0.0016283109 0.004070777 0.8747418 1.652309           14     7\n    leadingEdge\n         &lt;list&gt;\n1: MAL, IL7....\n2: CD3D, CD....\n\n$`5`\n       pathway         pval         padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:      B cell 0.0000999900 0.0004033071 0.8396953 1.854592            0    46\n2:         pDC 0.0001008268 0.0004033071 0.8368880 1.726199            0    17\n3: Plasma cell 0.0003024803 0.0008066142 0.8179182 1.687071            2    17\n4:         cDC 0.0005031193 0.0010062387 0.8040438 1.667569            4    18\n    leadingEdge\n         &lt;list&gt;\n1: LINC0178....\n2: SPIB, JC....\n3: TNFRSF13....\n4: ADAM28, ....\n\n$`6`\n   pathway       pval       padj        ES      NES nMoreExtreme  size\n    &lt;char&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:  ncMono 0.00009999 0.00040004 0.8554947 2.052586            0    49\n2:   cMono 0.00010001 0.00040004 0.7153561 1.667552            0    32\n3: NK cell 0.03237952 0.06475904 0.7437448 1.469663          300     8\n4:     cDC 0.00390039 0.01040104 0.6227887 1.464411           38    36\n5:     pDC 0.08649746 0.13839594 0.6110028 1.323896          851    15\n    leadingEdge\n         &lt;list&gt;\n1: CDKN1C, ....\n2: AIF1, SE....\n3: FCGR3A, ....\n4: LST1, CO....\n5: PLD4, CD....\n\n$`7`\n      pathway         pval         padj        ES      NES nMoreExtreme  size\n       &lt;char&gt;        &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: CD4 T cell 0.0001024905 0.0006149431 0.8279619 1.903518            0    14\n    leadingEdge\n         &lt;list&gt;\n1: TSHZ2, L....\n\n$`8`\nEmpty data.table (0 rows and 8 cols): pathway,pval,padj,ES,NES,nMoreExtreme...\n\n$`9`\n       pathway         pval        padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;        &lt;num&gt;       &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:         pDC 0.0022591908 0.007907168 0.7534531 1.636376           21    13\n2: Plasma cell 0.0002001001 0.001400700 0.6867348 1.635854            1    32\n    leadingEdge\n         &lt;list&gt;\n1: MYBL2, J....\n2: JCHAIN, ....\n\n\nSelecting top significant overlap per cluster, we can now rename the clusters according to the predicted labels. OBS! Be aware that if you have some clusters that have non-significant p-values for all the gene sets, the cluster label will not be very reliable. Also, the gene sets you are using may not cover all the celltypes you have in your dataset and hence predictions may just be the most similar celltype. Also, some of the clusters have very similar p-values to multiple celltypes, for instance the ncMono and cMono celltypes are equally good for some clusters.\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\n\nannot = new.cluster.ids[as.character(alldata@active.ident)]\nnames(annot) = colnames(alldata)\nalldata$ref_gsea &lt;- annot\n\nwrap_plots(\n    DimPlot(alldata, label = T, group.by = \"RNA_snn_res.0.5\") + NoAxes(),\n    DimPlot(alldata, label = T, group.by = \"ref_gsea\") + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\nCompare the results with the other celltype prediction methods in the ctrl_13 sample.\n\nctrl$ref_gsea &lt;- alldata$ref_gsea[alldata$orig.ident == \"ctrl_13\"]\n\nwrap_plots(\n    DimPlot(ctrl, label = T, group.by = \"ref_gsea\") + NoAxes() + ggtitle(\"GSEA\"),\n    DimPlot(ctrl, label = T, group.by = \"predicted.id\") + NoAxes() + ggtitle(\"LabelTransfer\"),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n7.2 With annotated gene sets\nWe have downloaded the celltype gene lists from http://bio-bigdata.hrbmu.edu.cn/CellMarker/CellMarker_download.html and converted the excel file to a csv for you. Read in the gene lists and do some filtering.\n\npath_file &lt;- file.path(\"data/cell_marker_human.csv\")\nif (!file.exists(path_file)) download.file(file.path(path_data, \"misc/cell_marker_human.csv\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\n\n# Load the human marker table\nmarkers &lt;- read.delim(\"data/cell_marker_human.csv\", sep = \";\")\nmarkers &lt;- markers[markers$species == \"Human\", ]\nmarkers &lt;- markers[markers$cancer_type == \"Normal\", ]\n\n# Filter by tissue (to reduce computational time and have tissue-specific classification)\nsort(unique(markers$tissue_type))\n\n  [1] \"Abdomen\"                        \"Abdominal adipose tissue\"      \n  [3] \"Abdominal fat pad\"              \"Acinus\"                        \n  [5] \"Adipose tissue\"                 \"Adrenal gland\"                 \n  [7] \"Adventitia\"                     \"Airway\"                        \n  [9] \"Airway epithelium\"              \"Allocortex\"                    \n [11] \"Alveolus\"                       \"Amniotic fluid\"                \n [13] \"Amniotic membrane\"              \"Ampullary\"                     \n [15] \"Anogenital tract\"               \"Antecubital vein\"              \n [17] \"Anterior cruciate ligament\"     \"Anterior presomitic mesoderm\"  \n [19] \"Aorta\"                          \"Aortic valve\"                  \n [21] \"Artery\"                         \"Arthrosis\"                     \n [23] \"Articular Cartilage\"            \"Ascites\"                       \n [25] \"Atrium\"                         \"Auditory cortex\"               \n [27] \"Basilar membrane\"               \"Beige Fat\"                     \n [29] \"Bile duct\"                      \"Biliary tract\"                 \n [31] \"Bladder\"                        \"Blood\"                         \n [33] \"Blood vessel\"                   \"Bone\"                          \n [35] \"Bone marrow\"                    \"Brain\"                         \n [37] \"Breast\"                         \"Bronchial vessel\"              \n [39] \"Bronchiole\"                     \"Bronchoalveolar lavage\"        \n [41] \"Bronchoalveolar system\"         \"Bronchus\"                      \n [43] \"Brown adipose tissue\"           \"Calvaria\"                      \n [45] \"Capillary\"                      \"Cardiac atrium\"                \n [47] \"Cardiovascular system\"          \"Carotid artery\"                \n [49] \"Carotid plaque\"                 \"Cartilage\"                     \n [51] \"Caudal cortex\"                  \"Caudal forebrain\"              \n [53] \"Caudal ganglionic eminence\"     \"Cavernosum\"                    \n [55] \"Central amygdala\"               \"Central nervous system\"        \n [57] \"Central Nervous System\"         \"Cerebellum\"                    \n [59] \"Cerebral organoid\"              \"Cerebrospinal fluid\"           \n [61] \"Choriocapillaris\"               \"Chorionic villi\"               \n [63] \"Chorionic villus\"               \"Choroid\"                       \n [65] \"Choroid plexus\"                 \"Colon\"                         \n [67] \"Colon epithelium\"               \"Colorectum\"                    \n [69] \"Cornea\"                         \"Corneal endothelium\"           \n [71] \"Corneal epithelium\"             \"Coronary artery\"               \n [73] \"Corpus callosum\"                \"Corpus luteum\"                 \n [75] \"Cortex\"                         \"Cortical layer\"                \n [77] \"Cortical thymus\"                \"Decidua\"                       \n [79] \"Deciduous tooth\"                \"Dental pulp\"                   \n [81] \"Dermis\"                         \"Diencephalon\"                  \n [83] \"Distal airway\"                  \"Dorsal forebrain\"              \n [85] \"Dorsal root ganglion\"           \"Dorsolateral prefrontal cortex\"\n [87] \"Ductal tissue\"                  \"Duodenum\"                      \n [89] \"Ectocervix\"                     \"Ectoderm\"                      \n [91] \"Embryo\"                         \"Embryoid body\"                 \n [93] \"Embryonic brain\"                \"Embryonic heart\"               \n [95] \"Embryonic Kidney\"               \"Embryonic prefrontal cortex\"   \n [97] \"Embryonic stem cell\"            \"Endocardium\"                   \n [99] \"Endocrine\"                      \"Endoderm\"                      \n[101] \"Endometrium\"                    \"Endometrium stroma\"            \n[103] \"Entorhinal cortex\"              \"Epidermis\"                     \n[105] \"Epithelium\"                     \"Esophagus\"                     \n[107] \"Eye\"                            \"Fat pad\"                       \n[109] \"Fetal brain\"                    \"Fetal gonad\"                   \n[111] \"Fetal heart\"                    \"Fetal ileums\"                  \n[113] \"Fetal kidney\"                   \"Fetal Leydig\"                  \n[115] \"Fetal liver\"                    \"Fetal lung\"                    \n[117] \"Fetal pancreas\"                 \"Fetal thymus\"                  \n[119] \"Fetal umbilical cord\"           \"Fetus\"                         \n[121] \"Foreskin\"                       \"Frontal cortex\"                \n[123] \"Fundic gland\"                   \"Gall bladder\"                  \n[125] \"Gastric corpus\"                 \"Gastric epithelium\"            \n[127] \"Gastric gland\"                  \"Gastrointestinal tract\"        \n[129] \"Germ\"                           \"Gingiva\"                       \n[131] \"Gonad\"                          \"Gut\"                           \n[133] \"Hair follicle\"                  \"Heart\"                         \n[135] \"Heart muscle\"                   \"Hippocampus\"                   \n[137] \"Ileum\"                          \"Inferior colliculus\"           \n[139] \"Interfollicular epidermis\"      \"Intervertebral disc\"           \n[141] \"Intestinal crypt\"               \"Intestine\"                     \n[143] \"Intrahepatic cholangio\"         \"Jejunum\"                       \n[145] \"Kidney\"                         \"Lacrimal gland\"                \n[147] \"Large intestine\"                \"Laryngeal squamous epithelium\" \n[149] \"Lateral ganglionic eminence\"    \"Ligament\"                      \n[151] \"Limb bud\"                       \"Limbal epithelium\"             \n[153] \"Liver\"                          \"Lumbar vertebra\"               \n[155] \"Lung\"                           \"Lymph\"                         \n[157] \"Lymph node\"                     \"Lymphatic vessel\"              \n[159] \"Lymphoid tissue\"                \"Malignant pleural effusion\"    \n[161] \"Mammary epithelium\"             \"Mammary gland\"                 \n[163] \"Medial ganglionic eminence\"     \"Medullary thymus\"              \n[165] \"Meniscus\"                       \"Mesoblast\"                     \n[167] \"Mesoderm\"                       \"Microvascular endothelium\"     \n[169] \"Microvessel\"                    \"Midbrain\"                      \n[171] \"Middle temporal gyrus\"          \"Milk\"                          \n[173] \"Molar\"                          \"Muscle\"                        \n[175] \"Myenteric plexus\"               \"Myocardium\"                    \n[177] \"Myometrium\"                     \"Nasal concha\"                  \n[179] \"Nasal epithelium\"               \"Nasal mucosa\"                  \n[181] \"Nasal polyp\"                    \"Neocortex\"                     \n[183] \"Nerve\"                          \"Nose\"                          \n[185] \"Nucleus pulposus\"               \"Olfactory neuroepithelium\"     \n[187] \"Optic nerve\"                    \"Oral cavity\"                   \n[189] \"Oral mucosa\"                    \"Osteoarthritic cartilage\"      \n[191] \"Ovarian cortex\"                 \"Ovarian follicle\"              \n[193] \"Ovary\"                          \"Oviduct\"                       \n[195] \"Pancreas\"                       \"Pancreatic acinar tissue\"      \n[197] \"Pancreatic duct\"                \"Pancreatic islet\"              \n[199] \"Periodontal ligament\"           \"Periodontium\"                  \n[201] \"Periosteum\"                     \"Peripheral blood\"              \n[203] \"Peritoneal fluid\"               \"Peritoneum\"                    \n[205] \"Pituitary\"                      \"Placenta\"                      \n[207] \"Plasma\"                         \"Pluripotent stem cell\"         \n[209] \"Polyp\"                          \"Posterior presomitic mesoderm\" \n[211] \"Prefrontal cortex\"              \"Premolar\"                      \n[213] \"Presomitic mesoderm\"            \"Primitive streak\"              \n[215] \"Prostate\"                       \"Pulmonary arteriy\"             \n[217] \"Pyloric gland\"                  \"Rectum\"                        \n[219] \"Renal glomerulus\"               \"Respiratory tract\"             \n[221] \"Retina\"                         \"Retinal organoid\"              \n[223] \"Retinal pigment epithelium\"     \"Right ventricle\"               \n[225] \"Saliva\"                         \"Salivary gland\"                \n[227] \"Scalp\"                          \"Sclerocorneal tissue\"          \n[229] \"Seminal plasma\"                 \"Septum transversum\"            \n[231] \"Serum\"                          \"Sinonasal mucosa\"              \n[233] \"Sinus tissue\"                   \"Skeletal muscle\"               \n[235] \"Skin\"                           \"Small intestinal crypt\"        \n[237] \"Small intestine\"                \"Soft tissue\"                   \n[239] \"Sperm\"                          \"Spinal cord\"                   \n[241] \"Spleen\"                         \"Splenic red pulp\"              \n[243] \"Sputum\"                         \"Stomach\"                       \n[245] \"Subcutaneous adipose tissue\"    \"Submandibular gland\"           \n[247] \"Subpallium\"                     \"Subplate\"                      \n[249] \"Subventricular zone\"            \"Superior frontal gyrus\"        \n[251] \"Sympathetic ganglion\"           \"Synovial fluid\"                \n[253] \"Synovium\"                       \"Taste bud\"                     \n[255] \"Tendon\"                         \"Testis\"                        \n[257] \"Thalamus\"                       \"Thymus\"                        \n[259] \"Thyroid\"                        \"Tonsil\"                        \n[261] \"Tooth\"                          \"Trachea\"                       \n[263] \"Tracheal airway epithelium\"     \"Transformed artery\"            \n[265] \"Trophoblast\"                    \"Umbilical cord\"                \n[267] \"Umbilical cord blood\"           \"Umbilical vein\"                \n[269] \"Undefined\"                      \"Urine\"                         \n[271] \"Urothelium\"                     \"Uterine cervix\"                \n[273] \"Uterus\"                         \"Vagina\"                        \n[275] \"Vein\"                           \"Venous blood\"                  \n[277] \"Ventral thalamus\"               \"Ventricle\"                     \n[279] \"Ventricular and atrial\"         \"Ventricular zone\"              \n[281] \"Visceral adipose tissue\"        \"Vocal fold\"                    \n[283] \"Whartons jelly\"                 \"White adipose tissue\"          \n[285] \"White matter\"                   \"Yolk sac\"                      \n\ngrep(\"blood\", unique(markers$tissue_type), value = T)\n\n[1] \"Peripheral blood\"     \"Umbilical cord blood\" \"Venous blood\"        \n\nmarkers &lt;- markers[markers$tissue_type %in% c(\n    \"Blood\", \"Venous blood\",\n    \"Serum\", \"Plasma\",\n    \"Spleen\", \"Bone marrow\", \"Lymph node\"\n), ]\n\n# remove strange characters etc.\ncelltype_list &lt;- lapply(unique(markers$cell_name), function(x) {\n    x &lt;- paste(markers$Symbol[markers$cell_name == x], sep = \",\")\n    x &lt;- gsub(\"[[]|[]]| |-\", \",\", x)\n    x &lt;- unlist(strsplit(x, split = \",\"))\n    x &lt;- unique(x[!x %in% c(\"\", \"NA\", \"family\")])\n    x &lt;- casefold(x, upper = T)\n})\nnames(celltype_list) &lt;- unique(markers$cell_name)\n\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &lt; 100]\ncelltype_list &lt;- celltype_list[unlist(lapply(celltype_list, length)) &gt; 5]\n\n\n# run fgsea for each of the clusters in the list\nres &lt;- lapply(DGE_list, function(x) {\n    gene_rank &lt;- setNames(x$avg_log2FC, x$gene)\n    fgseaRes &lt;- fgsea(pathways = celltype_list, stats = gene_rank, nperm = 10000, scoreType = \"pos\")\n    return(fgseaRes)\n})\nnames(res) &lt;- names(DGE_list)\n\n# You can filter and resort the table based on ES, NES or pvalue\nres &lt;- lapply(res, function(x) {\n    x[x$pval &lt; 0.01, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[x$size &gt; 5, ]\n})\nres &lt;- lapply(res, function(x) {\n    x[order(x$NES, decreasing = T), ]\n})\n\n# show top 3 for each cluster.\nlapply(res, head, 3)\n\n$`0`\n                  pathway      pval        padj        ES      NES nMoreExtreme\n                   &lt;char&gt;     &lt;num&gt;       &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt;\n1: CD1C+_B dendritic cell 9.999e-05 0.001819818 0.7922325 1.862226            0\n2:             Eosinophil 9.999e-05 0.001819818 0.8167906 1.717127            0\n3:             Neutrophil 9.999e-05 0.001819818 0.7731768 1.711836            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    48 S100A12,....\n2:    12 S100A8, ....\n3:    21 S100A8, ....\n\n$`1`\n               pathway      pval         padj        ES      NES nMoreExtreme\n                &lt;char&gt;     &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt;\n1: Natural killer cell 9.999e-05 0.0006070821 0.9238337 2.517711            0\n2:    Cytotoxic T cell 9.999e-05 0.0006070821 0.9848450 2.191117            0\n3:           Leukocyte 9.999e-05 0.0006070821 0.8795907 2.181436            0\n    size  leadingEdge\n   &lt;int&gt;       &lt;list&gt;\n1:    38 KLRC2, K....\n2:     6 PRF1, GZ....\n3:    15 NCAM1, P....\n\n$`2`\n       pathway      pval         padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;     &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:      T cell 9.999e-05 0.0007082625 0.8316394 2.121435            0    32\n2: CD4+ T cell 9.999e-05 0.0007082625 0.9212028 2.107935            0    11\n3: CD8+ T cell 9.999e-05 0.0007082625 0.8999258 2.081181            0    12\n    leadingEdge\n         &lt;list&gt;\n1: CD8B, GZ....\n2: CD8A, CD....\n3: CD8B, CD....\n\n$`3`\n             pathway      pval       padj        ES      NES nMoreExtreme  size\n              &lt;char&gt;     &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1:            B cell 9.999e-05 0.00249975 0.8792222 1.959773            0    29\n2: Follicular B cell 9.999e-05 0.00249975 0.9451526 1.943990            0    10\n3:      Naive B cell 9.999e-05 0.00249975 0.9208823 1.932096            0    13\n    leadingEdge\n         &lt;list&gt;\n1: TCL1A, I....\n2: TCL1A, I....\n3: TCL1A, I....\n\n$`4`\n                    pathway      pval       padj        ES      NES\n                     &lt;char&gt;     &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1:                   T cell 9.999e-05 0.00076356 0.8397280 1.892152\n2: Regulatory T (Treg) cell 9.999e-05 0.00076356 0.9267856 1.883378\n3:                Leukocyte 9.999e-05 0.00076356 0.9057388 1.876635\n   nMoreExtreme  size  leadingEdge\n          &lt;num&gt; &lt;int&gt;       &lt;list&gt;\n1:            0    31 IL2RA, C....\n2:            0     9 CCR4, RT....\n3:            0    11 CCR4, IL....\n\n$`5`\n         pathway      pval       padj        ES      NES nMoreExtreme  size\n          &lt;char&gt;     &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: Memory B cell 9.999e-05 0.00189981 0.9290884 1.908277            0    15\n2:   Plasma cell 9.999e-05 0.00189981 0.9157815 1.862844            0    13\n3:        B cell 9.999e-05 0.00189981 0.8391832 1.829292            0    37\n    leadingEdge\n         &lt;list&gt;\n1: KLK1, EB....\n2: IGHA2, C....\n3: CD80, CD....\n\n$`6`\n          pathway       pval       padj        ES      NES nMoreExtreme  size\n           &lt;char&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: CD16+ monocyte 0.00189981 0.05849415 0.8829187 1.777026           18     6\n2:     Macrophage 0.00009999 0.00899910 0.7726731 1.753670            0    23\n3:       Monocyte 0.00259974 0.05849415 0.6653597 1.528222           25    27\n    leadingEdge\n         &lt;list&gt;\n1: TCF7L2, ....\n2: C1QA, C1....\n3: MS4A7, L....\n\n$`7`\n                      pathway      pval         padj        ES      NES\n                       &lt;char&gt;     &lt;num&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1: Central memory CD8+ T cell 9.999e-05 0.0009624038 0.9261536 2.111816\n2:           Naive CD8 T cell 9.999e-05 0.0009624038 0.9178157 2.049312\n3: Central memory CD4+ T cell 9.999e-05 0.0009624038 0.9050628 2.041971\n   nMoreExtreme  size  leadingEdge\n          &lt;num&gt; &lt;int&gt;       &lt;list&gt;\n1:            0    12 TSHZ2, L....\n2:            0    10 TSHZ2, L....\n3:            0    11 TSHZ2, L....\n\n$`8`\n                   pathway       pval       padj        ES      NES\n                    &lt;char&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1:           Megakaryocyte 0.00009999 0.00869913 0.9501823 1.843444\n2: Hematopoietic stem cell 0.00039996 0.01739826 0.8620497 1.659678\n3:                Platelet 0.00179982 0.05219478 0.7627798 1.503843\n   nMoreExtreme  size  leadingEdge\n          &lt;num&gt; &lt;int&gt;       &lt;list&gt;\n1:            0    16 GP9, PF4....\n2:            3    14 ESAM, MM....\n3:           17    21 GP9, PF4....\n\n$`9`\n       pathway       pval       padj        ES      NES nMoreExtreme  size\n        &lt;char&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;    &lt;num&gt;        &lt;num&gt; &lt;int&gt;\n1: Plasma cell 0.00009999 0.00409959 0.8977052 1.962962            0    12\n2:      B cell 0.00009999 0.00409959 0.8678405 1.961982            0    17\n3: Plasmablast 0.00019998 0.00546612 0.8385769 1.860972            1    14\n    leadingEdge\n         &lt;list&gt;\n1: IGHA1, I....\n2: CDC20, C....\n3: IGHA1, I....\n\n\nLet’s plot the results.\n\nnew.cluster.ids &lt;- unlist(lapply(res, function(x) {\n    as.data.frame(x)[1, 1]\n}))\nannot = new.cluster.ids[as.character(alldata@active.ident)]\nnames(annot) = colnames(alldata)\nalldata$cellmarker_gsea &lt;- annot\n\nwrap_plots(\n    DimPlot(alldata, label = T, group.by = \"ref_gsea\") + NoAxes(),\n    DimPlot(alldata, label = T, group.by = \"cellmarker_gsea\") + NoAxes(),\n    ncol = 2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDo you think that the methods overlap well? Where do you see the most inconsistencies?\n\n\nIn this case we do not have any ground truth, and we cannot say which method performs best. You should keep in mind, that any celltype classification method is just a prediction, and you still need to use your common sense and knowledge of the biological system to judge if the results make sense.\nFinally, lets save the data with predictions.\n\nsaveRDS(ctrl, \"data/covid/results/seurat_covid_qc_dr_int_cl_ct-ctrl13.rds\")"
  },
  {
    "objectID": "labs/seurat/seurat_06_celltyping.html#meta-session",
    "href": "labs/seurat/seurat_06_celltyping.html#meta-session",
    "title": " Celltype prediction",
    "section": "8 Session info",
    "text": "8 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] fgsea_1.28.0                pbmcref.SeuratData_1.0.0   \n [3] Azimuth_0.5.0               shinyBS_0.61.1             \n [5] SeuratData_0.2.2.9002       remotes_2.5.0              \n [7] SingleR_2.4.0               celldex_1.12.0             \n [9] SummarizedExperiment_1.32.0 Biobase_2.62.0             \n[11] GenomicRanges_1.54.1        GenomeInfoDb_1.38.1        \n[13] IRanges_2.36.0              S4Vectors_0.40.2           \n[15] BiocGenerics_0.48.1         MatrixGenerics_1.14.0      \n[17] matrixStats_1.5.0           scPred_1.9.2               \n[19] pheatmap_1.0.12             ggplot2_3.5.1              \n[21] patchwork_1.3.0             dplyr_1.1.4                \n[23] Seurat_5.1.0                SeuratObject_5.0.2         \n[25] sp_2.2-0                   \n\nloaded via a namespace (and not attached):\n  [1] R.methodsS3_1.8.2                 progress_1.2.3                   \n  [3] nnet_7.3-20                       poweRlaw_1.0.0                   \n  [5] goftest_1.2-3                     DT_0.33                          \n  [7] Biostrings_2.70.1                 vctrs_0.6.5                      \n  [9] spatstat.random_3.3-2             digest_0.6.37                    \n [11] png_0.1-8                         ggrepel_0.9.6                    \n [13] deldir_2.0-4                      parallelly_1.42.0                \n [15] MASS_7.3-60.0.1                   Signac_1.14.0                    \n [17] reshape2_1.4.4                    httpuv_1.6.15                    \n [19] foreach_1.5.2                     withr_3.0.2                      \n [21] xfun_0.50                         survival_3.8-3                   \n [23] EnsDb.Hsapiens.v86_2.99.0         memoise_2.0.1                    \n [25] ggbeeswarm_0.7.2                  zoo_1.8-12                       \n [27] gtools_3.9.5                      pbapply_1.7-2                    \n [29] R.oo_1.27.0                       prettyunits_1.2.0                \n [31] KEGGREST_1.42.0                   promises_1.3.2                   \n [33] httr_1.4.7                        restfulr_0.0.15                  \n [35] rhdf5filters_1.14.1               globals_0.16.3                   \n [37] fitdistrplus_1.2-2                rhdf5_2.46.1                     \n [39] miniUI_0.1.1.1                    generics_0.1.3                   \n [41] curl_6.0.1                        zlibbioc_1.48.0                  \n [43] ScaledMatrix_1.10.0               polyclip_1.10-7                  \n [45] GenomeInfoDbData_1.2.11           ExperimentHub_2.10.0             \n [47] SparseArray_1.2.2                 interactiveDisplayBase_1.40.0    \n [49] xtable_1.8-4                      stringr_1.5.1                    \n [51] evaluate_1.0.3                    S4Arrays_1.2.0                   \n [53] BiocFileCache_2.10.1              hms_1.1.3                        \n [55] irlba_2.3.5.1                     colorspace_2.1-1                 \n [57] filelock_1.0.3                    hdf5r_1.3.11                     \n [59] ROCR_1.0-11                       harmony_1.2.1                    \n [61] reticulate_1.40.0                 spatstat.data_3.1-4              \n [63] magrittr_2.0.3                    lmtest_0.9-40                    \n [65] readr_2.1.5                       later_1.4.1                      \n [67] lattice_0.22-6                    spatstat.geom_3.3-5              \n [69] future.apply_1.11.3               scuttle_1.12.0                   \n [71] scattermore_1.2                   XML_3.99-0.17                    \n [73] cowplot_1.1.3                     RcppAnnoy_0.0.22                 \n [75] class_7.3-23                      pillar_1.10.1                    \n [77] nlme_3.1-167                      iterators_1.0.14                 \n [79] caTools_1.18.3                    compiler_4.3.3                   \n [81] beachmat_2.18.0                   RSpectra_0.16-2                  \n [83] stringi_1.8.4                     gower_1.0.1                      \n [85] tensor_1.5                        lubridate_1.9.4                  \n [87] GenomicAlignments_1.38.0          plyr_1.8.9                       \n [89] crayon_1.5.3                      abind_1.4-5                      \n [91] BiocIO_1.12.0                     googledrive_2.1.1                \n [93] locfit_1.5-9.11                   bit_4.5.0.1                      \n [95] fastmatch_1.1-6                   codetools_0.2-20                 \n [97] recipes_1.1.1                     BiocSingular_1.18.0              \n [99] plotly_4.10.4                     mime_0.12                        \n[101] splines_4.3.3                     Rcpp_1.0.14                      \n[103] fastDummies_1.7.5                 dbplyr_2.5.0                     \n[105] sparseMatrixStats_1.14.0          cellranger_1.1.0                 \n[107] knitr_1.49                        blob_1.2.4                       \n[109] BiocVersion_3.18.1                seqLogo_1.68.0                   \n[111] AnnotationFilter_1.26.0           fs_1.6.5                         \n[113] listenv_0.9.1                     DelayedMatrixStats_1.24.0        \n[115] tibble_3.2.1                      Matrix_1.6-5                     \n[117] statmod_1.5.0                     tzdb_0.4.0                       \n[119] pkgconfig_2.0.3                   tools_4.3.3                      \n[121] cachem_1.1.0                      RSQLite_2.3.9                    \n[123] viridisLite_0.4.2                 DBI_1.2.3                        \n[125] fastmap_1.2.0                     rmarkdown_2.29                   \n[127] scales_1.3.0                      grid_4.3.3                       \n[129] ica_1.0-3                         shinydashboard_0.7.2             \n[131] Rsamtools_2.18.0                  AnnotationHub_3.10.0             \n[133] BiocManager_1.30.25               dotCall64_1.2                    \n[135] RANN_2.6.2                        rpart_4.1.24                     \n[137] farver_2.1.2                      yaml_2.3.10                      \n[139] rtracklayer_1.62.0                cli_3.6.4                        \n[141] purrr_1.0.2                       leiden_0.4.3.1                   \n[143] lifecycle_1.0.4                   caret_6.0-94                     \n[145] uwot_0.2.2                        bluster_1.12.0                   \n[147] presto_1.0.0                      lava_1.8.1                       \n[149] BSgenome.Hsapiens.UCSC.hg38_1.4.5 BiocParallel_1.36.0              \n[151] annotate_1.80.0                   timechange_0.3.0                 \n[153] gtable_0.3.6                      rjson_0.2.23                     \n[155] ggridges_0.5.6                    progressr_0.15.1                 \n[157] limma_3.58.1                      parallel_4.3.3                   \n[159] pROC_1.18.5                       edgeR_4.0.16                     \n[161] jsonlite_1.8.9                    RcppHNSW_0.6.0                   \n[163] TFBSTools_1.40.0                  bitops_1.0-9                     \n[165] bit64_4.5.2                       Rtsne_0.17                       \n[167] BiocNeighbors_1.20.0              spatstat.utils_3.1-2             \n[169] CNEr_1.38.0                       metapod_1.10.0                   \n[171] dqrng_0.3.2                       shinyjs_2.1.0                    \n[173] SeuratDisk_0.0.0.9021             spatstat.univar_3.1-1            \n[175] R.utils_2.12.3                    timeDate_4041.110                \n[177] lazyeval_0.2.2                    shiny_1.10.0                     \n[179] htmltools_0.5.8.1                 GO.db_3.18.0                     \n[181] sctransform_0.4.1                 rappdirs_0.3.3                   \n[183] ensembldb_2.26.0                  glue_1.8.0                       \n[185] TFMPvalue_0.0.9                   spam_2.11-1                      \n[187] googlesheets4_1.1.1               XVector_0.42.0                   \n[189] RCurl_1.98-1.16                   scran_1.30.0                     \n[191] BSgenome_1.70.1                   gridExtra_2.3                    \n[193] JASPAR2020_0.99.10                igraph_2.0.3                     \n[195] R6_2.6.1                          SingleCellExperiment_1.24.0      \n[197] tidyr_1.3.1                       labeling_0.4.3                   \n[199] RcppRoll_0.3.1                    GenomicFeatures_1.54.1           \n[201] cluster_2.1.8                     Rhdf5lib_1.24.0                  \n[203] gargle_1.5.2                      ipred_0.9-15                     \n[205] DirichletMultinomial_1.44.0       DelayedArray_0.28.0              \n[207] tidyselect_1.2.1                  vipor_0.4.7                      \n[209] ProtGenerics_1.34.0               xml2_1.3.6                       \n[211] AnnotationDbi_1.64.1              future_1.34.0                    \n[213] ModelMetrics_1.2.2.2              rsvd_1.0.5                       \n[215] munsell_0.5.1                     KernSmooth_2.23-26               \n[217] data.table_1.16.4                 htmlwidgets_1.6.4                \n[219] RColorBrewer_1.1-3                biomaRt_2.58.0                   \n[221] rlang_1.1.5                       spatstat.sparse_3.1-0            \n[223] spatstat.explore_3.3-4            hardhat_1.4.1                    \n[225] beeswarm_0.4.0                    prodlim_2024.06.25"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html",
    "href": "labs/seurat/seurat_07_trajectory.html",
    "title": " Trajectory inference using Slingshot",
    "section": "",
    "text": "Note\n\n\n\nCode chunks run R commands unless otherwise specified."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#loading-libraries",
    "href": "labs/seurat/seurat_07_trajectory.html#loading-libraries",
    "title": " Trajectory inference using Slingshot",
    "section": "1 Loading libraries",
    "text": "1 Loading libraries\n\nsuppressPackageStartupMessages({\n  library(Seurat)\n  library(plotly)\n  options(rgl.printRglwidget = TRUE)\n  library(Matrix)\n  library(sparseMatrixStats)\n  library(slingshot)\n  library(tradeSeq)\n  library(patchwork)\n})\n\n# Define some color palette\npal &lt;- c(scales::hue_pal()(8), RColorBrewer::brewer.pal(9, \"Set1\"), RColorBrewer::brewer.pal(8, \"Set2\"))\nset.seed(1)\npal &lt;- rep(sample(pal, length(pal)), 200)\n\nNice function to easily draw a graph:\n\n# Add graph to the base R graphics plot\ndraw_graph &lt;- function(layout, graph, lwd = 0.2, col = \"grey\") {\n  res &lt;- rep(x = 1:(length(graph@p) - 1), times = (graph@p[-1] - graph@p[-length(graph@p)]))\n  segments(\n    x0 = layout[graph@i + 1, 1], x1 = layout[res, 1],\n    y0 = layout[graph@i + 1, 2], y1 = layout[res, 2], lwd = lwd, col = col\n  )\n}"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#preparing-data",
    "href": "labs/seurat/seurat_07_trajectory.html#preparing-data",
    "title": " Trajectory inference using Slingshot",
    "section": "2 Preparing data",
    "text": "2 Preparing data\nIf you have been using the Seurat, Bioconductor or Scanpy toolkits with your own data, you need to reach to the point where you have:\n\nA dimensionality reduction on which to run the trajectory (for example: PCA, ICA, MNN, harmony, Diffusion Maps, UMAP)\nThe cell clustering information (for example: from Louvain, K-means)\nA KNN/SNN graph (this is useful to inspect and sanity-check your trajectories)\n\nWe will be using a subset of a bone marrow dataset (originally containing about 100K cells) for this exercise on trajectory inference.\nThe bone marrow is the source of adult immune cells, and contains virtually all differentiation stages of cell from the immune system which later circulate in the blood to all other organs.\n\n\n\n\n\nYou can download the data:\n\n# download pre-computed data if missing or long compute\nfetch_data &lt;- TRUE\n\npath_trajectory &lt;- \"./data/trajectory\"\nif (!dir.exists(path_trajectory)) dir.create(path_trajectory, recursive = T)\n\n# url for source and intermediate data\npath_data &lt;- \"https://nextcloud.dc.scilifelab.se/public.php/webdav\"\ncurl_upass &lt;- \"-u zbC5fr2LbEZ9rSE:scRNAseq2025\"\npath_file &lt;- \"data/trajectory/trajectory_seurat_filtered.rds\"\n\nif (!dir.exists(dirname(path_file))) dir.create(dirname(path_file), recursive = TRUE)\nif (!file.exists(path_file)) download.file(url = file.path(path_data, \"trajectory/trajectory_seurat_filtered.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n\nWe already have pre-computed and subsetted the dataset (with 6688 cells and 3585 genes) following the analysis steps in this course. We then saved the objects, so you can use common tools to open and start to work with them (either in R or Python).\nIn addition there was some manual filtering done to remove clusters that are disconnected and cells that are hard to cluster, which can be seen in this script"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#reading-data",
    "href": "labs/seurat/seurat_07_trajectory.html#reading-data",
    "title": " Trajectory inference using Slingshot",
    "section": "3 Reading data",
    "text": "3 Reading data\n\nobj &lt;- readRDS(\"data/trajectory/trajectory_seurat_filtered.rds\")\n\n# Calculate cluster centroids (for plotting the labels later)\nmm &lt;- sparse.model.matrix(~ 0 + factor(obj$clusters_use))\ncolnames(mm) &lt;- levels(factor(obj$clusters_use))\ncentroids2d &lt;- as.matrix(t(t(obj@reductions$umap@cell.embeddings) %*% mm) / Matrix::colSums(mm))\n\nLet’s visualize which clusters we have in our dataset:\n\nvars &lt;- c(\"batches\", \"dataset\", \"clusters_use\", \"Phase\")\npl &lt;- list()\n\nfor (i in vars) {\n  pl[[i]] &lt;- DimPlot(obj, group.by = i, label = T) + theme_void() + NoLegend()\n}\nwrap_plots(pl)\n\n\n\n\n\n\n\n\nYou can check, for example, the number of cells in each cluster:\n\ntable(obj$clusters_use)\n\n\n  1  11  12  13  15  16  17  18   2  20  21  25  26  27  28  29  32  33  34  35 \n128 130 132 168 299 140 256 435  71  98 149  56 154  98  76 125 150 295 147 150 \n 36  38  43  44  46  47  49   5  53  54  55  58  59   6  60   7   8   9 \n135 128 260 110 140 113 217 100 129  57 247 127 101 160 120 147 120 160"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#exploring-the-data",
    "href": "labs/seurat/seurat_07_trajectory.html#exploring-the-data",
    "title": " Trajectory inference using Slingshot",
    "section": "4 Exploring the data",
    "text": "4 Exploring the data\nIt is crucial that you have some understanding of the dataset being analyzed. What are the clusters you see in your data and most importantly How are the clusters related to each other?. Well, let’s explore the data a bit. With the help of this table, write down which cluster numbers in your dataset express these key markers.\n\n\n\nMarker\nCell Type\n\n\n\n\nCd34\nHSC progenitor\n\n\nMs4a1\nB cell lineage\n\n\nCd3e\nT cell lineage\n\n\nLtf\nGranulocyte lineage\n\n\nCst3\nMonocyte lineage\n\n\nMcpt8\nMast Cell lineage\n\n\nAlas2\nRBC lineage\n\n\nSiglech\nDendritic cell lineage\n\n\nC1qc\nMacrophage cell lineage\n\n\nPf4\nMegakaryocyte cell lineage\n\n\n\n\nvars &lt;- c(\"Cd34\", \"Ms4a1\", \"Cd3e\", \"Ltf\", \"Cst3\", \"Mcpt8\", \"Alas2\", \"Siglech\", \"C1qc\", \"Pf4\")\npl &lt;- list()\n\npl &lt;- list(DimPlot(obj, group.by = \"clusters_use\", label = T) + theme_void() + NoLegend())\nfor (i in vars) {\n  pl[[i]] &lt;- FeaturePlot(obj, features = i, order = T) + theme_void() + NoLegend()\n}\nwrap_plots(pl)\n\n\n\n\n\n\n\n\nTo make it easier to interpret the data, we will add in some labels to the most important clusters.\n\nnew_clust = as.character(obj$clusters_use)\nnew_clust[new_clust == \"34\"] = \"34-Prog\" # progenitors\nnew_clust[new_clust == \"17\"] = \"17-Gran\" # granulocytes\nnew_clust[new_clust == \"27\"] = \"27-DC\" # dendritic cells\nnew_clust[new_clust == \"25\"] = \"25-Mac\" # macrophage\nnew_clust[new_clust == \"16\"] = \"16-TC\" # T-cells\nnew_clust[new_clust == \"20\"] = \"20-BC\" # B-cells\nnew_clust[new_clust == \"26\"] = \"26-Mast\" # Mast cells\nnew_clust[new_clust == \"53\"] = \"53-Mega\" # Megakaryocytes\nnew_clust[new_clust == \"49\"] = \"49-RBC\" # Red blood cells\n\nobj$clust_annot = factor(new_clust)\n\nDimPlot(obj, group.by = \"clust_annot\", label = T) + theme_void() + NoLegend()\n\n\n\n\n\n\n\n\nAnother way to better explore your data is to look in higher dimensions, to really get a sense for what is right or wrong. As mentioned in the dimensionality reduction exercises, here we ran UMAP with 3 dimensions.\n\n\n\n\n\n\nImportant\n\n\n\nThe UMAP needs to be computed to results in exactly 3 dimensions\n\n\nSince the steps below are identical to both Seurat and Bioconductor toolkits, we will extract the matrices from both, so it is clear what is being used where and to remove long lines of code used to get those matrices. We will use them all. Plot in 3D with Plotly:\n\ndf &lt;- data.frame(obj@reductions$umap3d@cell.embeddings, variable = factor(obj$clust_annot))\ncolnames(df)[1:3] &lt;- c(\"UMAP_1\", \"UMAP_2\", \"UMAP_3\")\np_State &lt;- plot_ly(df, x = ~UMAP_1, y = ~UMAP_2, z = ~UMAP_3, color = ~variable, colors = pal, size = .5)  %&gt;% add_markers()\np_State\n\n\n\n\n\n\n# to save interactive plot and open in a new tab\ntry(htmlwidgets::saveWidget(p_State, selfcontained = T, \"data/trajectory/umap_3d_clustering_plotly.html\"), silent = T)\nutils::browseURL(\"data/trajectory/umap_3d_clustering_plotly.html\")\n\nWe can now compute the lineages on these dataset.\n\n# Define lineage ends\nENDS &lt;- c(\"17-Gran\", \"27-DC\", \"25-Mac\", \"16-TC\", \"26-Mast\", \"53-Mega\", \"49-RBC\")\n\nset.seed(1)\nlineages &lt;- as.SlingshotDataSet(getLineages(\n  data           = obj@reductions$umap3d@cell.embeddings,\n  clusterLabels  = obj$clust_annot,\n  dist.method    = \"mnn\", # It can be: \"simple\", \"scaled.full\", \"scaled.diag\", \"slingshot\" or \"mnn\"\n  end.clus       = ENDS, # You can also define the ENDS!\n  start.clus     = \"34-Prog\"\n)) # define where to START the trajectories\n\n\n# IF NEEDED, ONE CAN ALSO MANULALLY EDIT THE LINEAGES, FOR EXAMPLE:\n# sel &lt;- sapply( lineages@lineages, function(x){rev(x)[1]} ) %in% ENDS\n# lineages@lineages &lt;- lineages@lineages[ sel ]\n# names(lineages@lineages) &lt;- paste0(\"Lineage\",1:length(lineages@lineages))\n# lineages\n\n\n# Change the reduction to our \"fixed\" UMAP2d (FOR VISUALISATION ONLY)\nlineages@reducedDim &lt;- obj@reductions$umap@cell.embeddings\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clust_annot], cex = .5, pch = 16)\n  lines(lineages, lwd = 1, col = \"black\", cex = 2)\n  text(centroids2d, labels = rownames(centroids2d), cex = 0.8, font = 2, col = \"white\")\n}"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#defining-principal-curves",
    "href": "labs/seurat/seurat_07_trajectory.html#defining-principal-curves",
    "title": " Trajectory inference using Slingshot",
    "section": "5 Defining Principal Curves",
    "text": "5 Defining Principal Curves\nOnce the clusters are connected, Slingshot allows you to transform them to a smooth trajectory using principal curves. This is an algorithm that iteratively changes an initial curve to better match the data points. It was developed for linear data. To apply it to single-cell data, slingshot adds two enhancements:\n\nIt will run principal curves for each ‘lineage’, which is a set of clusters that go from a defined start cluster to some end cluster\nLineages with a same set of clusters will be constrained so that their principal curves remain bundled around the overlapping clusters\n\nSince the function getCurves() takes some time to run, we can speed up the convergence of the curve fitting process by reducing the amount of cells to use in each lineage. Ideally you could all cells, but here we had set approx_points to 300 to speed up. Feel free to adjust that for your dataset.\n\n# Define curves\ncurves &lt;- as.SlingshotDataSet(getCurves(\n  data          = lineages,\n  thresh        = 1e-1,\n  stretch       = 1e-1,\n  allow.breaks  = F,\n  approx_points = 100\n))\n\ncurves\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5828          2\n\nlineages: 7 \nLineage1: 34-Prog  18  36  33  55  59  44  60  58  29  8  43  47  49-RBC  \nLineage2: 34-Prog  18  11  15  46  9  1  2  5  13  28  17-Gran  \nLineage3: 34-Prog  18  11  15  35  7  32  6  54  25-Mac  \nLineage4: 34-Prog  18  11  15  35  7  32  6  27-DC  \nLineage5: 34-Prog  18  36  21  12  20-BC  16-TC  \nLineage6: 34-Prog  18  36  33  55  38  53-Mega  \nLineage7: 34-Prog  18  36  26-Mast  \n\ncurves: 7 \nCurve1: Length: 6.7241  Samples: 2161.05\nCurve2: Length: 7.3487  Samples: 2097.02\nCurve3: Length: 3.5349  Samples: 1502.25\nCurve4: Length: 2.5623  Samples: 1387.66\nCurve5: Length: 2.9268  Samples: 979.78\nCurve6: Length: 2.8976  Samples: 1086.34\nCurve7: Length: 2.1323  Samples: 644.86\n\n# Plots\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clust_annot], pch = 16)\n  lines(curves, lwd = 2, col = \"black\")\n  text(centroids2d, labels = levels(obj$clust_annot), cex = 1, font = 2)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nDoes these lineages fit the biological expectations given what you know of hematopoesis. Please have a look at the figure in Section 2 and compare to the paths you now have.\n\n\nWith those results in hands, we can now compute the differentiation pseudotime.\n\npseudotime &lt;- slingPseudotime(curves, na = FALSE)\ncellWeights &lt;- slingCurveWeights(curves)\n\nx &lt;- rowMeans(pseudotime)\nx &lt;- x / max(x)\no &lt;- order(x)\n\n{\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(\"pseudotime\"), pch = 16, cex = 0.4, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"grey70\", \"orange3\", \"firebrick\", \"purple4\"))(99)[x[o] * 98 + 1]\n  )\n  points(centroids2d, cex = 2.5, pch = 16, col = \"#FFFFFF99\")\n  text(centroids2d, labels = levels(obj$clust_annot), cex = 1, font = 2)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nThe pseudotime represents the distance of every cell to the starting cluster. Have a look at the pseudotime plot, how well do you think it represents actual developmental time? What does it represent?"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#finding-differentially-expressed-genes",
    "href": "labs/seurat/seurat_07_trajectory.html#finding-differentially-expressed-genes",
    "title": " Trajectory inference using Slingshot",
    "section": "6 Finding differentially expressed genes",
    "text": "6 Finding differentially expressed genes\nThe main way to interpret a trajectory is to find genes that change along the trajectory. There are many ways to define differential expression along a trajectory:\n\nExpression changes along a particular path (i.e. change with pseudotime)\nExpression differences between branches\nExpression changes at branch points\nExpression changes somewhere along the trajectory\n…\n\ntradeSeq is a recently proposed algorithm to find trajectory differentially expressed genes. It works by smoothing the gene expression along the trajectory by fitting a smoother using generalized additive models (GAMs), and testing whether certain coefficients are statistically different between points in the trajectory.\n\nBiocParallel::register(BiocParallel::MulticoreParam())\n\nThe fitting of GAMs can take quite a while, so for demonstration purposes we first do a very stringent filtering of the genes.\n\n\n\n\n\n\nTip\n\n\n\nIn an ideal experiment, you would use all the genes, or at least those defined as being variable.\n\n\n\nsel_cells &lt;- split(colnames(obj@assays$RNA@data), obj$clust_annot)\nsel_cells &lt;- unlist(lapply(sel_cells, function(x) {\n  set.seed(1)\n  return(sample(x, 20))\n}))\n\ngv &lt;- as.data.frame(na.omit(scran::modelGeneVar(obj@assays$RNA@data[, sel_cells])))\ngv &lt;- gv[order(gv$bio, decreasing = T), ]\nsel_genes &lt;- sort(rownames(gv)[1:500])\n\nFitting the model:\n\n\n\n\n\n\nCaution\n\n\n\nThis is a slow compute intensive step, we will not run this now and instead use a pre-computed file in the step below.\n\n\n\npath_file &lt;- \"data/trajectory/seurat_scegam.rds\"\n\n# fetch_data is defined at the top of this document\nif (!fetch_data) {\n  sceGAM &lt;- fitGAM(\n    counts = drop0(obj@assays$RNA@data[sel_genes, sel_cells]),\n    pseudotime = pseudotime[sel_cells, ],\n    cellWeights = cellWeights[sel_cells, ],\n    nknots = 5, verbose = T, parallel = T, sce = TRUE,\n    BPPARAM = BiocParallel::MulticoreParam()\n  )\n  saveRDS(sceGAM, path_file)\n}\n\nDownload the precomputed file.\n\npath_file &lt;- \"data/trajectory/seurat_scegam.rds\"\n\n# fetch_data is defined at the top of this document\nif (fetch_data) {\n  if (!file.exists(path_file)) download.file(url = file.path(path_data, \"trajectory/seurat_scegam.rds\"), destfile = path_file, method = \"curl\", extra = curl_upass)\n}\n\n\n# read data\nsceGAM &lt;- readRDS(path_file)\n\n\nplotGeneCount(curves, clusters = obj$clust_annot, models = sceGAM)\n\n\n\n\n\n\n\nlineages\n\nclass: SlingshotDataSet \n\n Samples Dimensions\n    5828          2\n\nlineages: 7 \nLineage1: 34-Prog  18  36  33  55  59  44  60  58  29  8  43  47  49-RBC  \nLineage2: 34-Prog  18  11  15  46  9  1  2  5  13  28  17-Gran  \nLineage3: 34-Prog  18  11  15  35  7  32  6  54  25-Mac  \nLineage4: 34-Prog  18  11  15  35  7  32  6  27-DC  \nLineage5: 34-Prog  18  36  21  12  20-BC  16-TC  \nLineage6: 34-Prog  18  36  33  55  38  53-Mega  \nLineage7: 34-Prog  18  36  26-Mast  \n\ncurves: 0 \n\n\n\nlc &lt;- sapply(lineages@lineages, function(x) {\n  rev(x)[1]\n})\nnames(lc) &lt;- gsub(\"Lineage\", \"L\", names(lc))\nlc.idx = match(lc, levels(obj$clust_annot))\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clust_annot], pch = 16)\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc.idx, ], col = \"black\", pch = 16, cex = 4)\n  text(centroids2d[lc.idx, ], labels = names(lc), cex = 1, font = 2, col = \"white\")\n}\n\n\n\n\n\n\n\n\n\n6.1 Genes that change with pseudotime\nWe can first look at general trends of gene expression across pseudotime.\n\nset.seed(8)\nres &lt;- na.omit(associationTest(sceGAM, contrastType = \"consecutive\"))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, ]\n\n\n\n  \n\n\n\nWe can plot their expression:\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc.idx, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc.idx, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nvars &lt;- rownames(res[1:15, ])\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\n\n\n6.2 Genes that change between two pseudotime points\nWe can define custom pseudotime values of interest if we’re interested in genes that change between particular point in pseudotime. By default, we can look at differences between start and end:\n\nres &lt;- na.omit(startVsEndTest(sceGAM, pseudotimeValues = c(0, 1)))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, 1:6]\n\n\n\n  \n\n\n\nYou can see now that there are several more columns, one for each lineage. This table represents the differential expression within each lineage, to identify which genes go up or down. Let’s check lineage 1:\n\n# Get the top UP and Down regulated in lineage 1\nres_lin1 &lt;- sort(setNames(res$logFClineage1, rownames(res)))\nvars &lt;- names(c(rev(res_lin1)[1:7], res_lin1[1:8]))\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc.idx, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc.idx, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\n\n\n6.3 Genes that are different between lineages\nMore interesting are genes that are different between two branches. We may have seen some of these genes already pop up in previous analyses of pseudotime. There are several ways to define “different between branches”, and each have their own functions:\n\nDifferent at the end points, using diffEndTest()\nDifferent at the branching point, using earlyDETest()\nDifferent somewhere in pseudotime the branching point, using patternTest()\n\nNote that the last function requires that the pseudotimes between two lineages are aligned.\n\nres &lt;- na.omit(diffEndTest(sceGAM))\nres &lt;- res[res$pvalue &lt; 1e-3, ]\nres &lt;- res[res$waldStat &gt; mean(res$waldStat), ]\nres &lt;- res[order(res$waldStat, decreasing = T), ]\nres[1:10, ]\n\n\n\n  \n\n\n\nYou can see now that there are even more columns, one for the pairwise comparison between each lineage. Let’s check lineage 1 vs lineage 2:\n\n# Get the top UP and Down regulated in lineage 1 vs 2\nres_lin1_2 &lt;- sort(setNames(res$logFC1_2, rownames(res)))\nvars &lt;- names(c(rev(res_lin1_2)[1:7], res_lin1_2[1:8]))\nvars &lt;- na.omit(vars[vars != \"NA\"])\n\npar(mfrow = c(4, 4), mar = c(.1, .1, 2, 1))\n{\n  plot(obj@reductions$umap@cell.embeddings, col = pal[obj$clusters_use], cex = .5, pch = 16, axes = F, xlab = \"\", ylab = \"\")\n  lines(curves, lwd = 2, col = \"black\")\n  points(centroids2d[lc.idx, ], col = \"black\", pch = 15, cex = 3, xpd = T)\n  text(centroids2d[lc.idx, ], labels = names(lc), cex = 1, font = 2, col = \"white\", xpd = T)\n}\n\nfor (i in vars) {\n  x &lt;- drop0(obj@assays$RNA@data)[i, ]\n  x &lt;- (x - min(x)) / (max(x) - min(x))\n  o &lt;- order(x)\n  plot(obj@reductions$umap@cell.embeddings[o, ],\n    main = paste0(i), pch = 16, cex = 0.5, axes = F, xlab = \"\", ylab = \"\",\n    col = colorRampPalette(c(\"lightgray\", \"grey60\", \"navy\"))(99)[x[o] * 98 + 1]\n  )\n}\n\n\n\n\n\n\n\n\nCheck out this vignette for a more in-depth overview of tradeSeq and many other differential expression tests."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#generating-batch-corrected-data-for-differential-gene-expression",
    "href": "labs/seurat/seurat_07_trajectory.html#generating-batch-corrected-data-for-differential-gene-expression",
    "title": " Trajectory inference using Slingshot",
    "section": "7 Generating batch-corrected data for differential gene expression",
    "text": "7 Generating batch-corrected data for differential gene expression\nBefore computing differential gene expression, sometimes it is a good idea to make sure our dataset is somewhat homogeneous (without very strong batch effects). In this dataset, we actually used data from 4 different technologies (Drop-seq, SmartSeq2 and 10X) and therefore massive differences in read counts can be observed:\nIf you want to know more about how to control for this issue, please have a look at batch_corrected_counts.Rmd"
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#references",
    "href": "labs/seurat/seurat_07_trajectory.html#references",
    "title": " Trajectory inference using Slingshot",
    "section": "8 References",
    "text": "8 References\nCannoodt, Robrecht, Wouter Saelens, and Yvan Saeys. 2016. “Computational Methods for Trajectory Inference from Single-Cell Transcriptomics.” European Journal of Immunology 46 (11): 2496–2506. doi.\nSaelens, Wouter, Robrecht Cannoodt, Helena Todorov, and Yvan Saeys. 2019. “A Comparison of Single-Cell Trajectory Inference Methods.” Nature Biotechnology 37 (5): 547–54. doi."
  },
  {
    "objectID": "labs/seurat/seurat_07_trajectory.html#session-info",
    "href": "labs/seurat/seurat_07_trajectory.html#session-info",
    "title": " Trajectory inference using Slingshot",
    "section": "9 Session info",
    "text": "9 Session info\n\n\nClick here\n\n\nsessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.6 LTS\n\nMatrix products: default\nBLAS/LAPACK: /usr/local/conda/envs/seurat/lib/libopenblasp-r0.3.28.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] patchwork_1.3.0             tradeSeq_1.16.0            \n [3] slingshot_2.10.0            TrajectoryUtils_1.10.0     \n [5] SingleCellExperiment_1.24.0 SummarizedExperiment_1.32.0\n [7] Biobase_2.62.0              GenomicRanges_1.54.1       \n [9] GenomeInfoDb_1.38.1         IRanges_2.36.0             \n[11] S4Vectors_0.40.2            BiocGenerics_0.48.1        \n[13] princurve_2.1.6             sparseMatrixStats_1.14.0   \n[15] MatrixGenerics_1.14.0       matrixStats_1.5.0          \n[17] Matrix_1.6-5                plotly_4.10.4              \n[19] ggplot2_3.5.1               Seurat_5.1.0               \n[21] SeuratObject_5.0.2          sp_2.2-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.22          splines_4.3.3            \n  [3] later_1.4.1               bitops_1.0-9             \n  [5] tibble_3.2.1              polyclip_1.10-7          \n  [7] fastDummies_1.7.5         lifecycle_1.0.4          \n  [9] edgeR_4.0.16              globals_0.16.3           \n [11] lattice_0.22-6            MASS_7.3-60.0.1          \n [13] crosstalk_1.2.1           magrittr_2.0.3           \n [15] limma_3.58.1              rmarkdown_2.29           \n [17] yaml_2.3.10               metapod_1.10.0           \n [19] httpuv_1.6.15             sctransform_0.4.1        \n [21] spam_2.11-1               spatstat.sparse_3.1-0    \n [23] reticulate_1.40.0         cowplot_1.1.3            \n [25] pbapply_1.7-2             RColorBrewer_1.1-3       \n [27] abind_1.4-5               zlibbioc_1.48.0          \n [29] Rtsne_0.17                purrr_1.0.2              \n [31] RCurl_1.98-1.16           GenomeInfoDbData_1.2.11  \n [33] ggrepel_0.9.6             irlba_2.3.5.1            \n [35] listenv_0.9.1             spatstat.utils_3.1-2     \n [37] goftest_1.2-3             RSpectra_0.16-2          \n [39] spatstat.random_3.3-2     dqrng_0.3.2              \n [41] fitdistrplus_1.2-2        parallelly_1.42.0        \n [43] DelayedMatrixStats_1.24.0 leiden_0.4.3.1           \n [45] codetools_0.2-20          DelayedArray_0.28.0      \n [47] scuttle_1.12.0            tidyselect_1.2.1         \n [49] farver_2.1.2              ScaledMatrix_1.10.0      \n [51] viridis_0.6.5             spatstat.explore_3.3-4   \n [53] jsonlite_1.8.9            BiocNeighbors_1.20.0     \n [55] progressr_0.15.1          ggridges_0.5.6           \n [57] survival_3.8-3            tools_4.3.3              \n [59] ica_1.0-3                 Rcpp_1.0.14              \n [61] glue_1.8.0                gridExtra_2.3            \n [63] SparseArray_1.2.2         xfun_0.50                \n [65] mgcv_1.9-1                dplyr_1.1.4              \n [67] withr_3.0.2               fastmap_1.2.0            \n [69] bluster_1.12.0            digest_0.6.37            \n [71] rsvd_1.0.5                R6_2.6.1                 \n [73] mime_0.12                 colorspace_2.1-1         \n [75] scattermore_1.2           tensor_1.5               \n [77] spatstat.data_3.1-4       tidyr_1.3.1              \n [79] generics_0.1.3            data.table_1.16.4        \n [81] httr_1.4.7                htmlwidgets_1.6.4        \n [83] S4Arrays_1.2.0            uwot_0.2.2               \n [85] pkgconfig_2.0.3           gtable_0.3.6             \n [87] lmtest_0.9-40             XVector_0.42.0           \n [89] htmltools_0.5.8.1         dotCall64_1.2            \n [91] scales_1.3.0              png_0.1-8                \n [93] spatstat.univar_3.1-1     scran_1.30.0             \n [95] knitr_1.49                reshape2_1.4.4           \n [97] nlme_3.1-167              zoo_1.8-12               \n [99] stringr_1.5.1             KernSmooth_2.23-26       \n[101] parallel_4.3.3            miniUI_0.1.1.1           \n[103] pillar_1.10.1             grid_4.3.3               \n[105] vctrs_0.6.5               RANN_2.6.2               \n[107] promises_1.3.2            BiocSingular_1.18.0      \n[109] beachmat_2.18.0           xtable_1.8-4             \n[111] cluster_2.1.8             evaluate_1.0.3           \n[113] cli_3.6.4                 locfit_1.5-9.11          \n[115] compiler_4.3.3            rlang_1.1.5              \n[117] crayon_1.5.3              future.apply_1.11.3      \n[119] labeling_0.4.3            plyr_1.8.9               \n[121] stringi_1.8.4             viridisLite_0.4.2        \n[123] deldir_2.0-4              BiocParallel_1.36.0      \n[125] munsell_0.5.1             lazyeval_0.2.2           \n[127] spatstat.geom_3.3-5       RcppHNSW_0.6.0           \n[129] future_1.34.0             statmod_1.5.0            \n[131] shiny_1.10.0              ROCR_1.0-11              \n[133] igraph_2.0.3"
  },
  {
    "objectID": "home_contents.html#lecture-recordings",
    "href": "home_contents.html#lecture-recordings",
    "title": "Contents",
    "section": "Lecture recordings",
    "text": "Lecture recordings\nThe lectures from the 2025 course can be found on the NBIS YouTube channel."
  }
]