[
  {
    "objectID": "lectures/gsa/index.html#what-is-gene-set-analysis",
    "href": "lectures/gsa/index.html#what-is-gene-set-analysis",
    "title": "Gene set analysis",
    "section": "What is gene set analysis?",
    "text": "What is gene set analysis?\n\n\nGene-level data -&gt; Gene set data\n\n\nWe focus on transcriptomics and DGE, but in principle applies to any genome-wide data\n\nMany different kinds of genome wide analyses such differential gene expression, differential binding (chip-seq), differential methylation etc. could all end up here at functional analysis."
  },
  {
    "objectID": "lectures/gsa/index.html#why-gene-set-analysis",
    "href": "lectures/gsa/index.html#why-gene-set-analysis",
    "title": "Gene set analysis",
    "section": "Why gene set analysis?",
    "text": "Why gene set analysis?\n  \nPredict the functional changes of cells based on differential gene expression analysis\n\nMake sense of a long list of DEGs\n\nWhat is the function of those genes?\nWhat is the biological consequence of over/under expression of genes?\n\nConnect your DEGs and thereby your experiment to pathway activity\nSmall differences in many genes may have a bigger impact than large differences in one genes\nLess sensitive to false positive DEGs"
  },
  {
    "objectID": "lectures/gsa/index.html#requirements",
    "href": "lectures/gsa/index.html#requirements",
    "title": "Gene set analysis",
    "section": "Requirements",
    "text": "Requirements\n  \n\nDE results\n+\nGene set(s) (list(s) of genes)\n+\nStatistical test"
  },
  {
    "objectID": "lectures/gsa/index.html#where-to-get-gene-sets",
    "href": "lectures/gsa/index.html#where-to-get-gene-sets",
    "title": "Gene set analysis",
    "section": "Where to get gene sets?",
    "text": "Where to get gene sets?\n\nDatabases\n\nGene Ontology\nKEGG\nReactome\nMSigDB\n…\n\nPrevious studies\n\nMarkers of a population of interest\nTargets of a transcription factor of interest\nDE genes from another analysis"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-ontology",
    "href": "lectures/gsa/index.html#gene-ontology",
    "title": "Gene set analysis",
    "section": "Gene ontology",
    "text": "Gene ontology\n\n\n\n\n\n\nNetwork graph, loosely hierarchical\nThree ontologies\n\nBiological process (e.g. Neutrophil Chemotaxis, Cell proliferation)\nMolecular Function (e.g. Histone acetylation, Phosphorylation)\nCellular compartment (e.g. Nucleus, Cytoplasm, Plasma membrane)\n\nGenes can belong to multiple terms"
  },
  {
    "objectID": "lectures/gsa/index.html#kegg",
    "href": "lectures/gsa/index.html#kegg",
    "title": "Gene set analysis",
    "section": "Kegg",
    "text": "Kegg\n\n\n\n\nFewer and smaller ontology\nHighly curated\n\n\nPathview"
  },
  {
    "objectID": "lectures/gsa/index.html#overrepresentation-analysis-ora",
    "href": "lectures/gsa/index.html#overrepresentation-analysis-ora",
    "title": "Gene set analysis",
    "section": "Overrepresentation analysis (ORA)",
    "text": "Overrepresentation analysis (ORA)\n\n\nHypergeometric test (Fisher’s exact test)"
  },
  {
    "objectID": "lectures/gsa/index.html#overrepresentation-analysis-ora-1",
    "href": "lectures/gsa/index.html#overrepresentation-analysis-ora-1",
    "title": "Gene set analysis",
    "section": "Overrepresentation analysis (ORA)",
    "text": "Overrepresentation analysis (ORA)\n\nBackground can be all genes or all genes expressed in your cell population\nRequires arbitrary cut-off\nOmits actual gene-level statistics\nComputationally fast\nGenerally works for few genes with strong effects"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea",
    "href": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea",
    "title": "Gene set analysis",
    "section": "Gene set enrichment analysis (GSEA)",
    "text": "Gene set enrichment analysis (GSEA)\n\nSubramanian et al. (2005)"
  },
  {
    "objectID": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea-1",
    "href": "lectures/gsa/index.html#gene-set-enrichment-analysis-gsea-1",
    "title": "Gene set analysis",
    "section": "Gene set enrichment analysis (GSEA)",
    "text": "Gene set enrichment analysis (GSEA)\n\n\n\n\n\nEnrichment score (ES)\nNormalized enrichment score (NES)\nNo need for cut-offs\nTakes gene-level stats into account\nMore sensitive to subtle changes\n\nGSEA User Guide"
  },
  {
    "objectID": "lectures/gsa/index.html#tools",
    "href": "lectures/gsa/index.html#tools",
    "title": "Gene set analysis",
    "section": "Tools",
    "text": "Tools\nOnline\n\nEnrichr\nGorilla\nWebgestalt\n\nCode\n\nfgsea (R)\nclusterProfiler (R)\nmsigdbr (R)\ngseapy (Python)"
  },
  {
    "objectID": "lectures/gsa/index.html#considerations",
    "href": "lectures/gsa/index.html#considerations",
    "title": "Gene set analysis",
    "section": "Considerations",
    "text": "Considerations\n\nBias in curation - highly researched topics will be over-represented\nGene set names can be misleading\nSpecific vs general gene sets\nMultifunctional genes\nTranslation of gene ids\nDatabases change\nCuration is organism-specific\nCritical evaluation is required"
  },
  {
    "objectID": "lectures/gsa/index.html#references",
    "href": "lectures/gsa/index.html#references",
    "title": "Gene set analysis",
    "section": "References",
    "text": "References\n\n\nSubramanian, A., Tamayo, P., Mootha, V. K., Mukherjee, S., Ebert, B. L., Gillette, M. A., Paulovich, A., Pomeroy, S. L., Golub, T. R., Lander, E. S., et al. (2005). Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences, 102(43), 15545–15550. https://www.pnas.org/doi/abs/10.1073/pnas.0506580102"
  },
  {
    "objectID": "lectures/gsa/index.html#acknowledgements",
    "href": "lectures/gsa/index.html#acknowledgements",
    "title": "Gene set analysis",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nAdapted from previous presentations by Leif Wigge, Paulo Czarnewski and Roy Francis."
  },
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-seurat",
    "href": "labs/index.html#fa-brands-r-project-seurat",
    "title": "Labs",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-r-project-bioconductor",
    "href": "labs/index.html#fa-brands-r-project-bioconductor",
    "title": "Labs",
    "section": " Bioconductor",
    "text": "Bioconductor\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/index.html#fa-brands-python-scanpy",
    "href": "labs/index.html#fa-brands-python-scanpy",
    "title": "Labs",
    "section": " Scanpy",
    "text": "Scanpy\n\n\n\n\n\n\n\n\n\n\n Quality Control\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dimensionality Reduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Data Integration\n\n\n\n\n\n\n\n\n\n\n\n\n\n Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\n Differential gene expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n Celltype prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n Trajectory inference using PAGA\n\n\n\n\n\n\n\n\n\n\n\n\n\n Spatial Transcriptomics\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "other/containers-spatial.html",
    "href": "other/containers-spatial.html",
    "title": "Run labs in container",
    "section": "",
    "text": "Important\n\n\n\nThe docker containers are not tested on Microsoft Windows OS.\n\n\n\n\nCreate a new directory at a suitable location. Now you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs to work on labs.\ngit clone --depth 1 --single-branch --branch main https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\nIf the git command is not available, you can simply go to https://github.com/NBISweden/workshop-scRNAseq and download the repo as a zip file and unzip it in a suitable location.\n\n\n\nSeparate Docker images to run the spatial analysis are made available for Seurat, Bioconductor and Scanpy toolkits. All images follow the registry/username/image:tag convention. The image is always ghcr.io/nbisweden/workshop-scrnaseq. Add the appropriate tag based on the lab you are running.\nAn overview of the available docker images. Note the space requirements.\n\n\n\nTopic\nImage Tag\nSize (GB)\n\n\n\n\nSeurat spatial\n2024-seurat_spatial-r4.3.0\n6.85\n\n\nBioconductor spatial\n2024-bioconductor_spatial-r4.3.0\n6.47\n\n\nScanpy spatial\n2024-scanpy_spatial-py3.10\n3.68\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8788:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8788.\nUse the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\nRStudio login screen\n\n\n\n\n\nRStudio preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8789:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8789. Use the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\nDo not close the terminal. At the end of the prompt, you will see a URL that starts with http://127.0.0.1, similar to the one below:\nhttp://127.0.0.1:8888/lab?token=0a1d9ec51b91528a1d1fe2ad2c74f59ecb94c47070c2911d\nNote that your token value will be different. Copy the entire URL (with the token) and paste it in your browser.\n\n\n\n\n\nJupyterLab home\n\n\n\n\n\nJupyterLab preview"
  },
  {
    "objectID": "other/containers-spatial.html#run-docker-locally",
    "href": "other/containers-spatial.html#run-docker-locally",
    "title": "Run labs in container",
    "section": "",
    "text": "Important\n\n\n\nThe docker containers are not tested on Microsoft Windows OS.\n\n\n\n\nCreate a new directory at a suitable location. Now you can fetch the scripts for the labs. You can either download individual .qmd or .ipynb files from the Contents page or clone the whole repo. If you clone the repo, navigate to compiled/labs to work on labs.\ngit clone --depth 1 --single-branch --branch main https://github.com/nbisweden/workshop-scRNAseq.git\ncd workshop-scRNAseq/compiled/labs\nIf the git command is not available, you can simply go to https://github.com/NBISweden/workshop-scRNAseq and download the repo as a zip file and unzip it in a suitable location.\n\n\n\nSeparate Docker images to run the spatial analysis are made available for Seurat, Bioconductor and Scanpy toolkits. All images follow the registry/username/image:tag convention. The image is always ghcr.io/nbisweden/workshop-scrnaseq. Add the appropriate tag based on the lab you are running.\nAn overview of the available docker images. Note the space requirements.\n\n\n\nTopic\nImage Tag\nSize (GB)\n\n\n\n\nSeurat spatial\n2024-seurat_spatial-r4.3.0\n6.85\n\n\nBioconductor spatial\n2024-bioconductor_spatial-r4.3.0\n6.47\n\n\nScanpy spatial\n2024-scanpy_spatial-py3.10\n3.68\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8788:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-seurat_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8788.\nUse the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\nRStudio login screen\n\n\n\n\n\nRStudio preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\ndocker run --platform=linux/amd64 --rm -p 8789:8787 -e PASSWORD=scrnaseq -v ${PWD}:/home/rstudio/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-bioconductor_spatial-r4.3.0\nDo not close the terminal. In the browser, go to localhost:8789. Use the following credentials to log in to the RStudio Server:\n\nUser: rstudio\nPassword: scrnaseq\n\nNavigate to /home/rstudio/workdir/ and open qmd files\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/workdir ghcr.io/nbisweden/workshop-scrnaseq:2024-scanpy_spatial-py3.10\nDo not close the terminal. At the end of the prompt, you will see a URL that starts with http://127.0.0.1, similar to the one below:\nhttp://127.0.0.1:8888/lab?token=0a1d9ec51b91528a1d1fe2ad2c74f59ecb94c47070c2911d\nNote that your token value will be different. Copy the entire URL (with the token) and paste it in your browser.\n\n\n\n\n\nJupyterLab home\n\n\n\n\n\nJupyterLab preview"
  },
  {
    "objectID": "other/containers.html",
    "href": "other/containers.html",
    "title": "Run labs in container",
    "section": "",
    "text": "Note\n\n\n\nThree different toolkits, namely Seurat (R/RStudio), Bioconductor (R/RStudio) and Scanpy (Python/Jupyter) are available to perform the scRNAseq analysis. The labs can be run on SciLifeLab Serve or on your local machine using Docker. Both options provide the necessary environment to run the analysis.\nIf you use SciLifeLab Serve, you do not need any local installation or setup on your system but you need a SciLifeLab Serve account. If you use Docker, you will need to set up and run Docker yourself."
  },
  {
    "objectID": "other/containers.html#option-a-run-labs-on-scilifelab-serve-recommended",
    "href": "other/containers.html#option-a-run-labs-on-scilifelab-serve-recommended",
    "title": "Run labs in container",
    "section": "1 Option A: Run labs on SciLifeLab Serve (Recommended)",
    "text": "1 Option A: Run labs on SciLifeLab Serve (Recommended)\n\nLog in with your university email account to SciLifeLab Serve.\n\n\n\n\n\n\n\nImportant\n\n\n\nThis step requires that you are registered, and your account was given access to the course materials. If you did not register yet, please follow the precourse information and send an email to serve@scilifelab.se and let them know that you completed the registration.\n\n\n\nSelect My projects from the main menu. You should see a project called SCRNASEQ_VT25. Click Open.\n\n\n\n\n\n\n\nIn the SCRNASEQ_VT25 project, you can create an RStudio (for Seurat/Bioconductor) or JupyterLab (for Scanpy) notebook server instance, depending on which toolkit you choose to work with, by clicking the Create button.\n\n\n\n\n\n\n\nYou will now see a form to configure a notebook server. Under Name put the name of your choice, e.g. the toolkit. Leave the rest of the fields unchanged. Now click Submit.\n\n\n\n\n\n\n\nThe notebook server will now be created for you. Wait a few minutes to see the status Running in green. You can now click on its name to open it in a new tab.\n\n\n\n\n\n\n\nNote\n\n\n\nFor JupyterLab you will need to use the password scrnaseq.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the status does not turn to Running within 5 minutes click on the three dots under Actions and then Delete. Wait a few minutes until you see the status Deleted. Now you can refresh the page and create a new instance starting from step 3.\nIn rare cases it may happen that your notebook server suddenly restarts. This could be due to an error that affected the notebook globally (for example, it ran out of temporary memory). You will see this on the page where you are working. A new notebook will start for you at the same URL within a few minutes.\n\n\nIn the case of both JupyterLab and RStudio you have access to persistent storage. This is mounted to the folder /home/jovyan/work. Files stored in this folder (NB: only in this folder) will be available even if a notebook suddenly restarts. You can also view, download these files or upload other files that will become visible in your instance through a File Manager that can be launched from the bottom of the Project overview page.\n\nInside the notebook server the script download-labs.sh is provided that will download the corresponding labs. It creates a labs folder with .qmd files (Seurat/Bioconductor) or .ipynb files (Scanpy). In the terminal, run any of the usage examples below:\n\n\nSeurat\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"seurat\" \"work/labs\"\n\nBioconductor\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"bioc\" \"work/labs\"\n\nScanpy\n\nconda activate scanpy\n~/work/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"scanpy\" \"work/labs\"\n\n\n\n\n\n\nImportant\n\n\n\nRemember that data is only saved inside the /home/jovyan/work folder. If you run the labs outside this folder, all the labs and data files will be lost in case the JupyterLab server restarts or gets deleted (this can happen e.g. if it runs out of memory). It is recommended that at the end of each session you save the notebooks locally. You can do this by dowloading them through the File Manager interface available at the bottom of the project dashboard.\n\n\n\nWhen you are done with a particular notebook server, you need to delete it before you can create a new one. Click on the three dots under Actions, and then click on Delete. Wait a few minutes until you see the status Deleted. Now you can refresh the page and start over."
  },
  {
    "objectID": "other/containers.html#option-b-run-docker-locally",
    "href": "other/containers.html#option-b-run-docker-locally",
    "title": "Run labs in container",
    "section": "2 Option B: Run Docker Locally",
    "text": "2 Option B: Run Docker Locally\n\n2.1 Local Setup\nIf you don’t have Docker installed locally, please follow these instructions.\n\n\n2.2 Images\nSeparate Docker images are made available for Seurat/Bioconductor and Scanpy toolkits. Below you find an overview of the available docker images. Note the space requirements!\n\n\n\n\n\n\n\n\nTopic\nImage\nSize (GB)\n\n\n\n\nSeurat/Bioconductor\nghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\n13.1GB\n\n\nScanpy\nghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\n16.9GB\n\n\n\n\n\n2.3 Seurat/Bioconductor\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart R (Session &gt; Restart R) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\ndocker run --platform=linux/amd64 --rm -p 8787:8787 -v ${PWD}:/home/jovyan/work ghcr.io/nbisweden/workshop-scrnaseq-seurat:20250320-2311\nDo not close the terminal! In the browser, go to localhost:8787.\nInside RStudio, the script download-scripts-lab.sh is provided that will download the corresponding labs. It creates a labs folder with .qmd files. In the terminal, run the commands below:\n\nSeurat\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"seurat\" \"work/labs\"\n\nBioconductor\n\nconda activate seurat\n~/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"bioc\" \"work/labs\"\nNavigate to /home/jovyan/work/labs/ and open the .qmd files.\n\n\n2.4 Scanpy\n\n\n\n\n\n\nTip\n\n\n\nTo avoid running out of memory, restart the kernel (Kernel &gt; Restart Kernel) after each lab.\n\n\ncd /path/to/labs  # replace this with the full path to the workshop compiled lab folder\ndocker pull --platform=linux/amd64 ghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\ndocker run --platform=linux/amd64 --rm -p 8888:8888 -v ${PWD}:/home/jovyan/work/work ghcr.io/nbisweden/workshop-scrnaseq-scanpy:20250325-2256\nDo not close the terminal! In the browser, go to localhost:8888. Use the following credentials to log in to the JupyterLab server:\n\nPassword: scrnaseq\n\nInside JupyterLab, the script download-scripts-lab.sh is provided that will download the corresponding labs. It creates a labs folder with .ipynb files. In the terminal, run the commands below:\nconda activate scanpy\n~/work/download-labs.sh \"https://github.com/NBISweden\" \"workshop-scRNAseq\" \"compiled/labs\" \"scanpy\" \"work/labs\"\nNavigate to /home/jovyan/work/labs/ and open the .ipynb files."
  },
  {
    "objectID": "other/data.html",
    "href": "other/data.html",
    "title": "Data",
    "section": "",
    "text": "The data we are using in the first 6 tutorials is 10x data of peripheral blood mononuclear cells (PBMCs) from Covid patients and healthy controls from the paper “Immunophenotyping of COVID-19 and influenza highlights the role of type I interferons in development of severe COVID-19” in Science.\nA peripheral blood mononuclear cell (PBMC) is any peripheral blood cell having a round nucleus. These cells consist of lymphocytes (T cells, B cells, NK cells), monocytes and dendritic cells, whereas erythrocytes and platelets have no nuclei, and granulocytes (neutrophils, basophils, and eosinophils) have multi-lobed nuclei.\nData was downloaded from GEO GSE149689 entry. For the tutorials we have selected 4 of the severe patients and 4 controls from that dataset. Each donor was then downsampled to 1500 cells per individual just to speed up the processing times in the labs. The script used to select samples and downsampling can be found in our GitHub repo."
  },
  {
    "objectID": "other/data.html#covid-19-data",
    "href": "other/data.html#covid-19-data",
    "title": "Data",
    "section": "",
    "text": "The data we are using in the first 6 tutorials is 10x data of peripheral blood mononuclear cells (PBMCs) from Covid patients and healthy controls from the paper “Immunophenotyping of COVID-19 and influenza highlights the role of type I interferons in development of severe COVID-19” in Science.\nA peripheral blood mononuclear cell (PBMC) is any peripheral blood cell having a round nucleus. These cells consist of lymphocytes (T cells, B cells, NK cells), monocytes and dendritic cells, whereas erythrocytes and platelets have no nuclei, and granulocytes (neutrophils, basophils, and eosinophils) have multi-lobed nuclei.\nData was downloaded from GEO GSE149689 entry. For the tutorials we have selected 4 of the severe patients and 4 controls from that dataset. Each donor was then downsampled to 1500 cells per individual just to speed up the processing times in the labs. The script used to select samples and downsampling can be found in our GitHub repo."
  },
  {
    "objectID": "other/data.html#hematopoesis-data",
    "href": "other/data.html#hematopoesis-data",
    "title": "Data",
    "section": "2 Hematopoesis data",
    "text": "2 Hematopoesis data\nIn the trajectory exercise we continue with immune cells but to get the full development of the different lineages we need to have bone marrow data. The dataset we are using is an integrated object with bone marrow data from multiple studies.\nThe data was integrated with Harmony and saved as a Seurat object. We already have subsetted the dataset (with 6688 cells and 3585 genes). In addition there was some manual filtering done to remove clusters that are disconnected and cells that are hard to cluster, which can be seen in this script"
  },
  {
    "objectID": "other/data.html#spatial-transcriptomics-data-optional-topic",
    "href": "other/data.html#spatial-transcriptomics-data-optional-topic",
    "title": "Data",
    "section": "3 Spatial transcriptomics data (optional topic)",
    "text": "3 Spatial transcriptomics data (optional topic)\nFor the spatial transcriptomics tutorial we are using public Visium data from the 10x website that has been included in the data resources for the Seurat and Scanpy packages. We are using tow sections of the mouse brain (Sagittal).\nThe single cell data that we are using for mapping of celltypes onto the spatial data is a mouse cortex dataset from Allen brain institute."
  },
  {
    "objectID": "other/docker.html",
    "href": "other/docker.html",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Macs with Apple Silicon, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#install-docker",
    "href": "other/docker.html#install-docker",
    "title": "Docker Set Up",
    "section": "",
    "text": "Ensure that you install Docker or Docker Desktop before the course starts. If you do not have admin rights to install software on your laptop, talk to your local IT for help.\n\n\nFollow the installation instructions for your OS:\n\nUbuntu\nDebian\nFedora\n\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Mac with Apple Silicon or Intel Chip and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\n\n\n\n\n\n\nImportant\n\n\n\nOn Macs with Apple Silicon, in Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon.\n\n\n\n\n\nVisit this page to ensure you have the requirements necessary.\nDownload Docker Desktop for Windows and follow the installation instructions.\nAfter Docker Desktop starts, open the Dashboard and go to Settings ( in the top-right) &gt; General. Follow the instructions in the General section.\nAfter installation, open a PowerShell terminal and try to run docker --version. If that works, Docker is set up."
  },
  {
    "objectID": "other/docker.html#test-installation",
    "href": "other/docker.html#test-installation",
    "title": "Docker Set Up",
    "section": "2 Test installation",
    "text": "2 Test installation\nFrom the terminal, type:\ndocker --version\nand then run your first image by typing:\ndocker run hello-world\nIf both work as expected, you successfully installed Docker Desktop!"
  },
  {
    "objectID": "other/docker.html#allocate-resources",
    "href": "other/docker.html#allocate-resources",
    "title": "Docker Set Up",
    "section": "3 Allocate resources",
    "text": "3 Allocate resources\nOpen the Docker Dashboard when Docker Desktop starts and go to Settings ( in the top-right) &gt; Resources to allocate the following resources:\n\nCPU limit: 8\n\nMemory limit: 12 GB\n\nSwap: 2 GB\n\nOn Windows, if WSL engine is used, you might not be able to change resources directly."
  },
  {
    "objectID": "other/faq.html",
    "href": "other/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#command-line-developer-tools-not-found",
    "href": "other/faq.html#command-line-developer-tools-not-found",
    "title": "FAQ",
    "section": "",
    "text": "If you don’t yet have Mac OSX command line developer tools, please install it using:\nxcode-select --install"
  },
  {
    "objectID": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "href": "other/faq.html#error-umap-learn-not-found-or-other-python-packages",
    "title": "FAQ",
    "section": "2 Error: umap-learn not found, or other python packages",
    "text": "2 Error: umap-learn not found, or other python packages\n\nIf your R does not find the correct python version, it will complain that umap-learn is not installed and ask you to install it. Here are some tips on how to find the correct python version that was installed in the conda environment.\nTry selecting the correct conda env in R. In this example the conda environment is named myenv.\nlibrary(reticulate)\nreticulate::use_conda(\"myenv\")\nThen check what python you have in R:\nreticulate::py_config()\n# should read at top:\npython:         /Users/asbj/miniconda3/envs/myenv/bin/python\nIf that still is not right, you may have an r-reticulate python installation as well and need to perform the steps below.\n\nRestart R and select python version\nFirst, find out what path you have to your conda python (in TERMINAL):\n\nwhich python\n/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\n\nThen in R (after restarting):\n\nreticulate::use_python(\"/Users/asbj/miniconda3/envs/scRNAseq2021/bin/python\", required=T)\n\nThen check again with py_config if correct version of python is used:\n\nreticulate::py_config()\n\nIf you have the correct version now, you should be able to run UMAP without issues."
  },
  {
    "objectID": "other/faq.html#unable-to-load-stringi.so",
    "href": "other/faq.html#unable-to-load-stringi.so",
    "title": "FAQ",
    "section": "3 Unable to load stringi.so",
    "text": "3 Unable to load stringi.so\n \nYou can install stringi in R using:\ninstall.packages('stringi')"
  },
  {
    "objectID": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "href": "other/faq.html#error-failed-building-wheel-for-gevent-macosx10.9.sdk-missing",
    "title": "FAQ",
    "section": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing",
    "text": "4 ERROR: Failed building wheel for gevent / MacOSX10.9.sdk missing\n\nThis is a problem with the MacOSX compiler, in which conda is unable to find it.\n#Download MacOSX10.9.sdk from Github\ncurl -o MacOSX10.9.sdk.tar.gz \"https://github.com/phracker/MacOSX-SDKs/releases/download/11.3/MacOSX10.9.sdk.tar.xz\"\n\n#extract\nsudo tar -xzf MacOSX10.9.sdk.tar.xz\n\n#copy\nsudo cp -r MacOSX10.9.sdk /opt/\n\n#give executable permissions\nsudo chmod -R a+rX /opt\n\n#Link the path where conda looks to where the file is\nln -s /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk /opt/MacOSX10.9.sdk"
  },
  {
    "objectID": "other/faq.html#error-option-error-has-null-value",
    "href": "other/faq.html#error-option-error-has-null-value",
    "title": "FAQ",
    "section": "5 ERROR: option error has NULL value",
    "text": "5 ERROR: option error has NULL value\n\nThis error happens when running code inline. One possible solution is to restart Rstudio and type.\nif(interactive()) { options(error = utils::recover)}\nPlease try other solutions listed here. If none of those work, you can click on the wheel engine symbol and check Chunk output in console."
  },
  {
    "objectID": "other/faq.html#r-crashes-due-to-memory-issues",
    "href": "other/faq.html#r-crashes-due-to-memory-issues",
    "title": "FAQ",
    "section": "6 R crashes due to memory issues",
    "text": "6 R crashes due to memory issues\n\nIf R crashes due to memory issues, it may be a good idea to increase the vector size R_MAX_VSIZE. Put in the file .Renviron either in your home directory or the folder you are launching Rstudio from:\nR_MAX_VSIZE=70Gb\nOr to whatever value matches your computer, the default size is 16Gb."
  },
  {
    "objectID": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "href": "other/faq.html#docker-run-fails-on-mac-apple-silicon",
    "title": "FAQ",
    "section": "7 Docker run fails on Mac apple silicon",
    "text": "7 Docker run fails on Mac apple silicon\n\nDocker run on Apple Mac M1/M2/M3 processors experience this error when running docker run ... on an image not built on Apple silicon.\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n[s6-init] ensuring user provided files have correct perms...exited 0.\n[fix-attrs.d] applying ownership & permissions fixes...\n[fix-attrs.d] done.\n[cont-init.d] executing container initialization scripts...\n[cont-init.d] 01_set_env: executing...\nskipping /var/run/s6/container_environment/HOME\nskipping /var/run/s6/container_environment/PASSWORD\nskipping /var/run/s6/container_environment/RSTUDIO_VERSION\n[cont-init.d] 01_set_env: exited 0.\n[cont-init.d] 02_userconf: executing...\n[cont-init.d] 02_userconf: exited 0.\n[cont-init.d] done.\n[services.d] starting services\n[services.d] done.\nTTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\nrserver[1195]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\n\n2023-11-28T14:31:03.943703Z [rserver] ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: void rstudio::server::pam_auth::{anonymous}::assumeRootPriv() src/cpp/server/ServerPAMAuth.cpp:59\nrserver[1199]: ERROR system error 1 (Operation not permitted); OCCURRED AT rstudio::core::Error rstudio::core::system::posix::{anonymous}::restorePrivilegesImpl(uid_t) src/cpp/shared_core/system/PosixSystem.cpp:97; LOGGED FROM: rstudio::core::Error rstudio::core::system::launchChildProcess(std::string, std::string, rstudio::core::system::ProcessConfig, rstudio::core::system::ProcessConfigFilter, PidType*) src/cpp/core/system/PosixSystem.cpp:2195\nIn Docker Settings &gt; General, check Use Rosetta for x86/amd64 emulation on Apple Silicon."
  },
  {
    "objectID": "other/faq.html#open-multiple-files-simultaneously-in-rstudio",
    "href": "other/faq.html#open-multiple-files-simultaneously-in-rstudio",
    "title": "FAQ",
    "section": "8 Open multiple files simultaneously in RStudio",
    "text": "8 Open multiple files simultaneously in RStudio\n\nOpen all qmd files in the current working directory.\n\n\n\nR\n\nlapply(list.files(pattern = \"\\\\.qmd$\"), rstudioapi::documentOpen)"
  },
  {
    "objectID": "other/scilifelab-serve.html",
    "href": "other/scilifelab-serve.html",
    "title": "Using Scilifelab Serve",
    "section": "",
    "text": "In order to be able to access the lab notebooks for this course you need to have access to SciLifeLab Serve.\nPlease register with your university email address. In the registration form there is a field called “Do you require support?”, in here please write that you are registering to take part in the course SCRNASEQ_V25. Do not forget to also confirm your e-mail address by clicking on a link in the activation email. This needs to be done before Monday 24th March so that the SciLifeLab Serve admins can set up your account in the way that is required by the course."
  },
  {
    "objectID": "other/scilifelab-serve.html#apply-for-an-account",
    "href": "other/scilifelab-serve.html#apply-for-an-account",
    "title": "Using Scilifelab Serve",
    "section": "",
    "text": "In order to be able to access the lab notebooks for this course you need to have access to SciLifeLab Serve.\nPlease register with your university email address. In the registration form there is a field called “Do you require support?”, in here please write that you are registering to take part in the course SCRNASEQ_V25. Do not forget to also confirm your e-mail address by clicking on a link in the activation email. This needs to be done before Monday 24th March so that the SciLifeLab Serve admins can set up your account in the way that is required by the course."
  },
  {
    "objectID": "other/scilifelab-serve.html#launching-practicals",
    "href": "other/scilifelab-serve.html#launching-practicals",
    "title": "Using Scilifelab Serve",
    "section": "2 Launching practicals",
    "text": "2 Launching practicals\nFor launching practicals please follow the instructions here."
  },
  {
    "objectID": "other/uppmax.html",
    "href": "other/uppmax.html",
    "title": "UPPMAX Account Guide",
    "section": "",
    "text": "Caution\n\n\n\nDo these steps well in advance as it can take up to 2 weeks for UPPMAX accounts to be approved. If this is incomplete, you may not be able to follow the labs during the workshop.\nThese are the basic steps in this process:"
  },
  {
    "objectID": "other/uppmax.html#create-an-account-in-supr.",
    "href": "other/uppmax.html#create-an-account-in-supr.",
    "title": "UPPMAX Account Guide",
    "section": "1 ​Create an account in SUPR.",
    "text": "1 ​Create an account in SUPR.\n​If you already have a SUPR account, please continue to the next step.\n​Go to​ https://supr.naiss.se/​ and click Register New Person at the bottom of the first page. Complete the registration process, preferably using SWAMID, and login. If you for some reason can’t use SWAMID to login, you will have to send physical (not electronic) copy of your ID to a place in Gothenburg for manual approval. Do this as ​soon as possible​, as this process can take ​more than 2 weeks.\n\n\n\nSUPR login screen"
  },
  {
    "objectID": "other/uppmax.html#apply-for-membership",
    "href": "other/uppmax.html#apply-for-membership",
    "title": "UPPMAX Account Guide",
    "section": "2 ​Apply for membership",
    "text": "2 ​Apply for membership\n​Log in using your SUPR account. ​Under the Projects heading, go to Request Membership in Project. ​Search for the following project IDs:\n\n\nnaiss2023-22-1345, naiss2023-23-648\n\n\nRequest membership to both projects. The first project is to run computations and the second project is for storage.\n\n\n\nRequest to join a project in SUPR"
  },
  {
    "objectID": "other/uppmax.html#accept-naiss-user-agreement",
    "href": "other/uppmax.html#accept-naiss-user-agreement",
    "title": "UPPMAX Account Guide",
    "section": "3 ​Accept NAISS User Agreement",
    "text": "3 ​Accept NAISS User Agreement\n​In SUPR, click on the link Personal Information in the left sidebar. You will have to accept the NAISS User Agreement to be able to get an UPPMAX account."
  },
  {
    "objectID": "other/uppmax.html#apply-for-uppmax-account",
    "href": "other/uppmax.html#apply-for-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "4 Apply for UPPMAX account",
    "text": "4 Apply for UPPMAX account\n​In SUPR, click on the link Accounts in the left sidebar and apply for an UPPMAX account under the heading Account Requests."
  },
  {
    "objectID": "other/uppmax.html#uppmax-account-details",
    "href": "other/uppmax.html#uppmax-account-details",
    "title": "UPPMAX Account Guide",
    "section": "5 UPPMAX account details",
    "text": "5 UPPMAX account details\n​Within about 2 working days you should get an email with instructions. ​Please, follow these instructions carefully. ​A while later you will get an email with your user name, and another email with a link to your password.\n\n\n\n\n\n\nCaution\n\n\n\nThe link is only valid for ​1​ visit or 7 days​, so if you click the link you better save the password, because you will not be able to use the link again. Do this before 7 days have passed, otherwise the link will no longer be valid."
  },
  {
    "objectID": "other/uppmax.html#login-with-new-uppmax-account",
    "href": "other/uppmax.html#login-with-new-uppmax-account",
    "title": "UPPMAX Account Guide",
    "section": "6 Login with new UPPMAX account",
    "text": "6 Login with new UPPMAX account\n​Open your terminal program (Terminal in OSX and Linux, otherwise download MobaXterm​ (portable edition) if you have Windows).\n​Type this command in your terminal program: ssh username@rackham.uppmax.uu.se ​You will be asked for your password now, and you will not see any response in the terminal while typing your password. This is to hide the length of your password, i.e. normal. Just press enter when you have typed it in and you should log in.\n​If it is the first time you log in, it will ask you to change your LDAP password (the password you just typed). It will directly ask you for your password again, so type it once more. After that it will ask you for your new password, so make up a new one and press enter. After that it will ask you to confirm the new password. When the password change is completed you will be disconnected and you will have to connect again, using your new password to log in this time."
  },
  {
    "objectID": "other/uppmax.html#create-a-folder",
    "href": "other/uppmax.html#create-a-folder",
    "title": "UPPMAX Account Guide",
    "section": "7 ​Create a folder",
    "text": "7 ​Create a folder\n\n\n\n\n\n\nCaution\n\n\n\n​After having received information that your membership is approved, ​wait 24 h before continuing, as it takes up to 24 h for SUPR to sync with UPPMAX. Else, you might get the message Permission denied when writing files or folders.\n\n\nCreate a directory for you to work in. Replace &lt;username&gt; with your actual user name.\n\n\n\n\nbash\n\nmkdir /proj/​naiss2023-23-648/nobackup/&lt;username&gt;\n\n\n\n​Unless you got some kind of error message. you should now be finished. To make sure the folder was created you can type\n\n\n\n\nbash\n\nls /proj/​naiss2023-23-648/nobackup/\n\n\n\n​It should list all directories along with the one you created. ​If you get an error message, contact us in Slack."
  },
  {
    "objectID": "home_contents.html",
    "href": "home_contents.html",
    "title": "Contents",
    "section": "",
    "text": "Note\n\n\n\nThe 2026 version of the workshop is under construction. Please check the archive for previous offerings."
  },
  {
    "objectID": "home_info.html",
    "href": "home_info.html",
    "title": "Practical Info",
    "section": "",
    "text": "Online\n\n\nOnline meeting links are sent to participants by email."
  },
  {
    "objectID": "home_precourse.html",
    "href": "home_precourse.html",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Quarto/Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_schedule.html",
    "href": "home_schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Note\n\n\n\nThe 2026 version of the workshop is under construction. Please check the archive for previous offerings."
  },
  {
    "objectID": "home_syllabus.html",
    "href": "home_syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "SyllabusWho can apply?Entry requirements\n\n\nThis workshop will cover the basic steps in single cell RNAseq (scRNAseq) processing and data analysis, with lectures and practical exercises.\nTopics covered will include:\n\nOverview of the current scRNAseq technologies\nRaw reads into expression values\nQuality control of scRNAseq data\nDimensionality reduction and clustering techniques\nData normalization\nDifferential gene expression for scRNAseq data\nCelltype prediction\nTrajectory analysis\nComparison of sc analysis toolkits: Seurat, Bioconductor and Scanpy\n\n\n\n\nThis is a national workshop open for PhD students, postdocs, group leaders and core facility staff within all Swedish universities. We do accept application from other countries, but priority is given to applicants from Swedish universities prior to applicants from industry and academics from other countries.\n\nPlease note that NBIS training events do not provide any formal university credits. The training content is estimated to correspond to a certain number of credits, however the estimated credits are just guidelines. If formal credits are crucial, the student needs to confer with the home department before submitting a workshop application in order to establish whether the workshop is valid for formal credits or not.\n\nWe cannot invoice private individuals, therefore an affiliation is required.\n\n\n\nPractical exercises can be performed using R or Python, so we only accept students with previous experience in one of those programming languages.\n\nBasic knowledge in R/Python and command line (bash).\nBe able to use your own computer with R or Python installed for the practical computational exercises. Instructions on installation will be sent by email to accepted participants.\nProgramming/scripting experience is required (in R or python).\nBasic understanding of NGS technologies and RNA-sequencing data.\nDesirable: Previous experience with RNA-seq analysis and/or participation in NGS/RNA-seq workshop is an advantage.\n\nDue to limited space the workshop can accommodate maximum of 25 participants. If we receive more applications, participants will be selected based on several criteria. Selection criteria include correct entry requirements, motivation to attend the workshop as well as gender and geographical balance."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Note\n\n\n\nThe 2026 version of the workshop is under construction. Please check the archive for previous offerings.\n\n\n\n\n\n\n\n\n\nOverview of scRNAseq technologies\nQC, normalization and transformation\nDimensionality reduction and clustering\nDifferential gene expression\nCelltype prediction\nTrajectory analysis\nSeurat, Bioconductor and Scanpy toolkits\n\n\n\nUpdated: 08-01-2026 at 20:02:58."
  },
  {
    "objectID": "index.html#single-cell-rna-seq-analysis",
    "href": "index.html#single-cell-rna-seq-analysis",
    "title": "",
    "section": "",
    "text": "Overview of scRNAseq technologies\nQC, normalization and transformation\nDimensionality reduction and clustering\nDifferential gene expression\nCelltype prediction\nTrajectory analysis\nSeurat, Bioconductor and Scanpy toolkits\n\n\n\nUpdated: 08-01-2026 at 20:02:58."
  },
  {
    "objectID": "home_info.html#location",
    "href": "home_info.html#location",
    "title": "Practical Info",
    "section": "",
    "text": "Online\n\n\nOnline meeting links are sent to participants by email."
  },
  {
    "objectID": "home_info.html#contact",
    "href": "home_info.html#contact",
    "title": "Practical Info",
    "section": "Contact",
    "text": "Contact\nThis workshop is run by the National Bioinformatics Infrastructure Sweden (NBIS). NBIS is a platform at SciLifeLab (Science For Life Laboratory) and the Swedish node of Elixir.\nIf you would like to get in touch with us regarding this workshop, please contact us at edu.sc [at] nbis.se."
  },
  {
    "objectID": "home_precourse.html#fa-book-coding",
    "href": "home_precourse.html#fa-book-coding",
    "title": "Precourse",
    "section": "",
    "text": "We strongly recommend for those not yet familiar with UNIX and/or R/Python to take this opportunity and take these online tutorials, since those are requirements for the workshop. This will help you to develop your programming skills and we can always learn a few tricks here and there, even if you are already experienced.\n\nUNIX: Part 1, Part 2\nR: Part 1, Part 2\nPython: Part 1, Part 2\n\nAfter taking those courses (or any other equivalent course in programming in bash and R or Python), you should be familiar with\n\nFile structure and manipulation in bash\nLoading, handling and manipulating vectors, matrices, factors and lists\nCreating for-loops\nUsing Quarto/Rmarkdown/Jupyter for reports\nEditing and writing files in the command line\nAnd much more …"
  },
  {
    "objectID": "home_precourse.html#fa-brands-slack-slack",
    "href": "home_precourse.html#fa-brands-slack-slack",
    "title": "Precourse",
    "section": " Slack",
    "text": "Slack\nWe will use Slack for communication, troubleshooting and group discussions. Please install Slack. All accepted students will receive an invitation link via email to join the course workspace. Please add this workspace to your Slack application on your desktop rather than using it in the browser.\nOnce you are in the workspace, please join the following channels:\n\n#general for general questions about the workshop\n#precourse for questions related to precourse preparation\n\n\n\n\n\n\n\nNote\n\n\n\nPlease post your question in the channel and NOT directly to the teacher. Any participant that knows the answer to any problem is encouraged to help too."
  },
  {
    "objectID": "home_precourse.html#fa-server-scilifelab-serve",
    "href": "home_precourse.html#fa-server-scilifelab-serve",
    "title": "Precourse",
    "section": " Scilifelab Serve",
    "text": "Scilifelab Serve\nWe will use the Scilifelab Serve compute resources for the workshop. You will need to create an account if you don’t already have one. See instructions here."
  },
  {
    "objectID": "home_precourse.html#fa-brands-docker-docker",
    "href": "home_precourse.html#fa-brands-docker-docker",
    "title": "Precourse",
    "section": " Docker",
    "text": "Docker\nIn addition to ScilifeLab Serve, the lab environments are available as Docker images. These will be useful as backups in case Serve does not work, and will be necessary for the BYOD session. For this, you will need to install Docker: Instructions are here."
  },
  {
    "objectID": "home_precourse.html#fa-circle-question-faq",
    "href": "home_precourse.html#fa-circle-question-faq",
    "title": "Precourse",
    "section": " FAQ",
    "text": "FAQ\nPlease refer to the FAQ for troubleshooting common issues."
  }
]